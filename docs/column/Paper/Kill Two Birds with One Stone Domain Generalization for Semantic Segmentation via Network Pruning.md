# Kill Two Birds with One Stone Domain Generalization for Semantic Segmentation via Network Pruning

<div>
<ArticleMetadata/>
</div>

> **æµ™æ±Ÿå¤§å­¦ã€å†…åè¾¾å¤§å­¦**

## æ‘˜è¦

**Deep model**s are notoriously known to perform poorly when encountering new domains with different statistics. To alleviate this issue, we present a new domain generalization method based on network pruning, dubbed NPDG. Our core idea is to prune the filters or attention heads that are more sensitive to domain shift while preserving those domain-invariant ones. To this end, we propose a new pruning policy tailored to improve generalization ability, which identifies the filter and head sensibility of domain shift by judging its activation variance among different domains (unary manner) and its correlation to other filter (binary manner). To better reveal those potentially sensitive filters and heads, we present a differentiable style perturbation scheme to imitate the domain variance dynamically. NPDG is trained on a single source domain and can be applied to both CNN- and Transformer-based backbones. To our knowledge, we are among the pioneers in tackling domain generalization in segmentation via network pruning. NPDG not only improves the generalization ability of a segmentation model but also decreases its computation cost. Extensive experiments demonstrate the state-of-the-art generalization performance of NPDG with a lighter-weight structure.

## ç¿»è¯‘

ä¼—æ‰€å‘¨çŸ¥ï¼Œæ·±åº¦æ¨¡å‹åœ¨é‡åˆ°å…·æœ‰ä¸åŒç»Ÿè®¡æ•°æ®çš„æ–°é¢†åŸŸæ—¶è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº**ç½‘ç»œå‰ªæ**çš„åŸŸæ³›åŒ–æ–¹æ³•ï¼Œç§°ä¸ºNPDGã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯å‰ªæè¿‡æ»¤å™¨æˆ–æ³¨æ„å¤´ï¼Œæ›´æ•æ„Ÿçš„é¢†åŸŸè½¬ç§»ï¼ŒåŒæ—¶ä¿ç•™é‚£äº›é¢†åŸŸä¸å˜çš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å‰ªæç­–ç•¥æ¥æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œè¯¥ç­–ç•¥é€šè¿‡åˆ¤æ–­ä¸åŒåŸŸä¹‹é—´çš„æ¿€æ´»æ–¹å·®(ä¸€å…ƒæ–¹å¼)å’Œä¸å…¶ä»–æ»¤æ³¢å™¨çš„ç›¸å…³æ€§(äºŒå€¼æ–¹å¼)æ¥è¯†åˆ«æ»¤æ³¢å™¨å’ŒåŸŸæ¼‚ç§»çš„å¤´éƒ¨æ•æ„Ÿæ€§ã€‚ä¸ºäº†æ›´å¥½åœ°æ­ç¤ºé‚£äº›æ½œåœ¨çš„æ•æ„Ÿæ»¤æ³¢å™¨å’Œå¤´éƒ¨ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯å¾®é£æ ¼çš„æ‘„åŠ¨æ–¹æ¡ˆæ¥åŠ¨æ€åœ°æ¨¡æ‹ŸåŸŸæ–¹å·®ã€‚NPDGåœ¨å•ä¸€æºåŸŸä¸Šè®­ç»ƒï¼Œå¯ä»¥åº”ç”¨äºåŸºäºCNNå’Œtransformerçš„ä¸»å¹²ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯é€šè¿‡ç½‘ç»œå‰ªæå¤„ç†åˆ†å‰²é¢†åŸŸæ³›åŒ–çš„å…ˆé©±ä¹‹ä¸€ã€‚NPDGä¸ä»…æé«˜äº†åˆ†å‰²æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œè€Œä¸”é™ä½äº†åˆ†å‰²æ¨¡å‹çš„è®¡ç®—é‡ã€‚å¤§é‡çš„å®éªŒè¯æ˜äº†å…·æœ‰è¾ƒè½»é‡é‡ç»“æ„çš„NPDGå…·æœ‰æœ€å…ˆè¿›çš„æ³›åŒ–æ€§èƒ½ã€‚

## ç ”ç©¶èƒŒæ™¯

â€

â€

â€

â€

â€

â€

â€

â€

â€

## ç ”ç©¶ç°çŠ¶

â€

â€

â€

â€

â€

â€

â€

â€

â€

â€

â€

## æå‡ºçš„æ¨¡å‹

â€

â€

â€

â€

â€

â€

â€

â€

â€

â€

â€

## å®éªŒï¼ˆCompared with SOTAï¼‰

â€

â€

â€

â€

â€

â€

â€

â€

â€

## å®éªŒï¼ˆAblation Experimentsï¼‰ğŸ¥‡

â€

â€

â€

â€

â€

â€

â€

â€

## ç»“è®º
