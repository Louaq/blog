 # HWDæ›¿æ¢ä¼ ç»Ÿä¸‹é‡‡æ ·

ä¸€ã€æœ¬æ–‡ä»‹ç»
------

æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯**Haar å°æ³¢çš„ä¸‹é‡‡æ ·HWDæ›¿æ¢ä¼ ç»Ÿä¸‹é‡‡æ ·**ï¼ˆæ”¹å˜YOLOä¼ ç»Ÿçš„Convä¸‹é‡‡æ ·ï¼‰åœ¨å°æ³¢å˜æ¢ä¸­ï¼ŒHaarå°æ³¢ä½œä¸ºä¸€ç§åŸºæœ¬çš„å°æ³¢å‡½æ•°ï¼Œç”¨äºå°†å›¾åƒæ•°æ®åˆ†è§£ä¸ºå¤šä¸ªå±‚æ¬¡çš„è¿‘ä¼¼å’Œç»†èŠ‚ä¿¡æ¯ï¼Œè¿™æ˜¯ä¸€ç§å¤šåˆ†è¾¨ç‡çš„åˆ†ææ–¹æ³•ã€‚æˆ‘å°†å…¶ç”¨åœ¨YOLOv8ä¸Šå…¶æ˜æ˜¾é™ä½å‚æ•°å’ŒGFLOPsåœ¨**V8n**ä¸Šä½¿ç”¨è¯¥æœºåˆ¶åå‚æ•°é‡ä¸º**270Wï¼Œè®¡ç®—é‡GFLOPsä¸º7.5**ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/d7511038388748779bf324d87cd88719.png)

äºŒã€åŸç†ä»‹ç»
------

**å®˜æ–¹è®ºæ–‡åœ°å€ï¼š**[å®˜æ–¹è®ºæ–‡åœ°å€ç‚¹å‡»æ­¤å¤„å³å¯è·³è½¬ï¼ˆè®ºæ–‡éœ€è¦èŠ±é’±æ­¤è®ºæ–‡ï¼‰](https://www.sciencedirect.com/science/article/abs/pii/S0031320323005174 "å®˜æ–¹è®ºæ–‡åœ°å€ç‚¹å‡»æ­¤å¤„å³å¯è·³è½¬ï¼ˆè®ºæ–‡éœ€è¦èŠ±é’±æ­¤è®ºæ–‡ï¼‰")

**å®˜æ–¹ä»£ç åœ°å€ï¼š[å®˜æ–¹ä»£ç åœ°å€ç‚¹å‡»æ­¤å¤„å³å¯è·³è½¬](https://github.com/apple1986/HWD/blob/main/HWD.py "å®˜æ–¹ä»£ç åœ°å€ç‚¹å‡»æ­¤å¤„å³å¯è·³è½¬")**

* * *

è®ºæ–‡ä»‹ç»äº†ä¸€ç§åŸºäºHaarå°æ³¢å˜æ¢çš„å›¾åƒå‹ç¼©æ–¹æ³•åŠå…¶å‹ç¼©å›¾åƒè´¨é‡çš„è¯„ä¼°æ–¹æ³•ã€‚ä¸‹é¢æ˜¯å¯¹è®ºæ–‡å†…å®¹çš„è¯¦ç»†åˆ†æï¼š

**ä¸»è¦å†…å®¹å’Œæ–¹æ³•**

**1\. Haarå°æ³¢å˜æ¢çš„ä»‹ç»ï¼š**

*   Â  Â Haarå°æ³¢æ˜¯æœ€ç®€å•çš„å°æ³¢å½¢å¼ä¹‹ä¸€ï¼Œå…·æœ‰æ˜“äºè®¡ç®—å’Œå®ç°çš„ä¼˜ç‚¹ã€‚
*   Â  Â æ–‡ç« ä¸­åº”ç”¨äº†äºŒç»´ç¦»æ•£å°æ³¢å˜æ¢ï¼ˆ2D DWTï¼‰ï¼Œå°†å›¾åƒä¿¡æ¯çŸ©é˜µåˆ†è§£ä¸ºç»†èŠ‚çŸ©é˜µå’Œä¿¡æ¯çŸ©é˜µã€‚
*   Â  Â é‡æ„å›¾åƒä½¿ç”¨è¿™äº›çŸ©é˜µå’Œå°æ³¢å˜æ¢çš„ä¿¡æ¯å®Œæˆã€‚

**2\. å›¾åƒå‹ç¼©æŠ€æœ¯ï¼š**

*   Â  Â å‹ç¼©æŠ€æœ¯é€šè¿‡ä½¿ç”¨Haarå°æ³¢ä½œä¸ºåŸºå‡½æ•°ï¼Œå‡å°‘å›¾åƒæ–‡ä»¶å¤§å°ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿æŒå›¾åƒè´¨é‡ã€‚
*   Â  Â å‹ç¼©è¿‡ç¨‹åŒ…æ‹¬å°†å›¾åƒä¿¡æ¯è½¬æ¢ä¸ºæ›´æ˜“äºç¼–ç çš„æ ¼å¼ï¼Œè¿™é€šå¸¸æ¶‰åŠè½¬æ¢ã€é‡åŒ–å’Œç†µç¼–ç ã€‚

> **ç»“è®º**ï¼šè®ºæ–‡è¯æ˜äº†Haarå°æ³¢å˜æ¢æ˜¯ä¸€ç§æœ‰æ•ˆçš„å›¾åƒå‹ç¼©å·¥å…·ï¼Œå°¤å…¶é€‚åˆéœ€è¦é«˜å‹ç¼©æ¯”è€Œåˆä¸å¸Œæœ›å›¾åƒè´¨é‡ä¸‹é™å¤ªå¤šçš„åº”ç”¨åœºæ™¯ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¯¹æ¯”ä¼ ç»Ÿçš„DCTå’Œæœ€æ–°çš„å°æ³¢å˜æ¢æ–¹æ³•ï¼Œä½œè€…æŒ‡å‡ºHaarå°æ³¢åœ¨å¤„ç†å›¾åƒè¾¹ç¼˜å’Œç»†èŠ‚æ–¹é¢å…·æœ‰ä¸€å®šçš„ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨å‹ç¼©é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ã€‚

* * *

ä¸‰ã€æ ¸å¿ƒä»£ç Â 
-------

```python
import torch
import torch.nn as nn
try:
    from pytorch_wavelets import DWTForward # æŒ‰ç…§è¿™ä¸ªç¬¬ä¸‰æ–¹åº“éœ€è¦å®‰è£…pip install pytorch_wavelets==1.3.0
                                            # å¦‚æœæç¤ºç¼ºå°‘pywtåº“åˆ™å®‰è£… pip install PyWavelets
except:
    pass
 
class Down_wt(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(Down_wt, self).__init__()
        self.wt = DWTForward(J=1, mode='zero', wave='haar')
        self.conv_bn_relu = nn.Sequential(
                                    nn.Conv2d(in_ch*4, out_ch, kernel_size=1, stride=1),
                                    nn.BatchNorm2d(out_ch),
                                    nn.ReLU(inplace=True),
                                    )
    def forward(self, x):
        yL, yH = self.wt(x)
        y_HL = yH[0][:,:,0,::]
        y_LH = yH[0][:,:,1,::]
        y_HH = yH[0][:,:,2,::]
        x = torch.cat([yL, y_HL, y_LH, y_HH], dim=1)
        x = self.conv_bn_relu(x)
        return x
 
if __name__ == "__main__":
    # Generating Sample image
    image_size = (1, 64, 224, 224)
    image = torch.rand(*image_size)
 
    # Model
    model = Down_wt(64, 32)
 
    out = model(image)
    print(out.size())
```

* * *

å››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ HWDæœºåˆ¶
--------------

### 4.1 ä¿®æ”¹ä¸€

ç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nnæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯'Addmodules'æ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f3b27ee4c6ba43f6a72f55c821411c16.png)





* * *

### 4.2 ä¿®æ”¹äºŒÂ 

ç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º'\_\_init\_\_.py'ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/81de6420f73d40369a3e2e8835e69c1a.png)

* * *

### 4.3 ä¿®æ”¹ä¸‰Â 

ç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/nn/tasks.py'è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/67b28bda87e44d3285f0241acd165256.png)â€‹

* * *

### 4.4 ä¿®æ”¹å››Â 

æŒ‰ç…§æˆ‘çš„æ·»åŠ åœ¨parse\_modelé‡Œæ·»åŠ å³å¯ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8fd1f1cd6e8d402ab6ede68ecc925d43.png)

**åˆ°æ­¤å°±ä¿®æ”¹å®Œæˆäº†ï¼Œå¤§å®¶å¯ä»¥å¤åˆ¶ä¸‹é¢çš„yamlæ–‡ä»¶è¿è¡Œã€‚**

* * *

äº”ã€HWDçš„yamlæ–‡ä»¶å’Œè¿è¡Œè®°å½•
-----------------

**PS:æ³¨æ„æœ¬æ–‡çš„æ”¹è¿›æœºåˆ¶éœ€è¦å…³é—­AMPè¿è¡Œå¦åˆ™ä¼šæŠ¥ç²¾åº¦é”™è¯¯ï¼**

**PS:æ³¨æ„æœ¬æ–‡çš„æ”¹è¿›æœºåˆ¶éœ€è¦å…³é—­AMPè¿è¡Œå¦åˆ™ä¼šæŠ¥ç²¾åº¦é”™è¯¯ï¼**

### 5.1 HWDçš„yamlæ–‡ä»¶1

**ä¸»å¹²å’ŒNeckå…¨éƒ¨ç”¨ä¸Šè¯¥å·ç§¯è½»é‡åŒ–åˆ°æœºåˆ¶çš„yamlæ–‡ä»¶ã€‚**

```python
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
 
# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOP
 
# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Down_wt, [128]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Down_wt, [256]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Down_wt, [512]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Down_wt, [1024]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
 
# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12
 
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)
 
 
  - [-1, 1, Down_wt, [256]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)
 
 
  - [-1, 1, Down_wt, [512]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)
 
  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```

* * *

### 5.2 HWDçš„yamlæ–‡ä»¶2

**åˆ›æ–°C2fçš„yamlæ–‡ä»¶2**ï¼Œ**PS:æ³¨æ„æœ¬æ–‡çš„æ”¹è¿›æœºåˆ¶éœ€è¦å…³é—­AMPè¿è¡Œå¦åˆ™ä¼šæŠ¥ç²¾åº¦é”™è¯¯ï¼**

```python
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
 
# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOP
 
# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Down_wt, [128]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Down_wt, [256]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Down_wt, [512]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Down_wt, [1024]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
 
# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12
 
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)
 
 
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)
 
 
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)
 
  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```



* * *

### 5.3 è®­ç»ƒä»£ç Â 

å¤§å®¶å¯ä»¥åˆ›å»ºä¸€ä¸ªpyæ–‡ä»¶å°†æˆ‘ç»™çš„ä»£ç å¤åˆ¶ç²˜è´´è¿›å»ï¼Œé…ç½®å¥½è‡ªå·±çš„æ–‡ä»¶è·¯å¾„å³å¯è¿è¡Œã€‚

**PS:æ³¨æ„æœ¬æ–‡çš„æ”¹è¿›æœºåˆ¶éœ€è¦å…³é—­AMPè¿è¡Œå¦åˆ™ä¼šæŠ¥ç²¾åº¦é”™è¯¯ï¼**

```python
import warnings
warnings.filterwarnings('ignore')
from ultralytics import YOLO
 
if __name__ == '__main__':
    model = YOLO('ultralytics/cfg/models/v8/yolov8-C2f-FasterBlock.yaml')
    # model.load('yolov8n.pt') # loading pretrain weights
    model.train(data=r'æ›¿æ¢æ•°æ®é›†yamlæ–‡ä»¶åœ°å€',
                # å¦‚æœå¤§å®¶ä»»åŠ¡æ˜¯å…¶å®ƒçš„'ultralytics/cfg/default.yaml'æ‰¾åˆ°è¿™é‡Œä¿®æ”¹taskå¯ä»¥æ”¹æˆdetect, segment, classify, pose
                cache=False,
                imgsz=640,
                epochs=150,
                single_cls=False,  # æ˜¯å¦æ˜¯å•ç±»åˆ«æ£€æµ‹
                batch=4,
                close_mosaic=10,
                workers=0,
                device='0',
                optimizer='SGD', # using SGD
                # resume='', # å¦‚è¿‡æƒ³ç»­è®­å°±è®¾ç½®last.ptçš„åœ°å€
                amp=False,  # å¦‚æœå‡ºç°è®­ç»ƒæŸå¤±ä¸ºNanå¯ä»¥å…³é—­amp
                project='runs/train',
                name='exp',
                )
```

 

* * *

### 5.4 HWDçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾Â 

**PS:æ³¨æ„æœ¬æ–‡çš„æ”¹è¿›æœºåˆ¶éœ€è¦å…³é—­AMPè¿è¡Œå¦åˆ™ä¼šæŠ¥ç²¾åº¦é”™è¯¯ï¼**

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/97d87b48083242c98b275b6de6dabb99.png)



