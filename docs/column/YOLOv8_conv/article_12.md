 # SAC

ä¸€ã€æœ¬æ–‡ä»‹ç»
------

æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯**å¯åˆ‡æ¢çš„ç©ºæ´å·ç§¯**ï¼ˆSwitchable Atrous Convolution, **SAC**ï¼‰æ˜¯ä¸€ç§åˆ›æ–°çš„å·ç§¯ç½‘ç»œæœºåˆ¶ï¼Œä¸“ä¸ºå¢å¼ºç‰©ä½“æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡ä¸­çš„ç‰¹å¾æå–è€Œè®¾è®¡ã€‚SACçš„**æ ¸å¿ƒæ€æƒ³**æ˜¯åœ¨ç›¸åŒçš„è¾“å…¥ç‰¹å¾ä¸Šåº”ç”¨ä¸åŒçš„ç©ºæ´ç‡è¿›è¡Œå·ç§¯ï¼Œå¹¶é€šè¿‡ç‰¹åˆ«è®¾è®¡çš„å¼€å…³å‡½æ•°æ¥èåˆè¿™äº›ä¸åŒå·ç§¯çš„ç»“æœã€‚è¿™ç§æ–¹æ³•ä½¿å¾—ç½‘ç»œèƒ½å¤Ÿæ›´çµæ´»åœ°é€‚åº”ä¸åŒå°ºåº¦çš„ç‰¹å¾ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯†åˆ«å’Œåˆ†å‰²å›¾åƒä¸­çš„ç‰©ä½“ã€‚Â **é€šè¿‡æœ¬æ–‡ä½ èƒ½å¤Ÿäº†è§£åˆ°**ï¼šå¯åˆ‡æ¢çš„ç©ºæ´å·ç§¯çš„åŸºæœ¬åŸç†å’Œæ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ä½ è‡ªå·±çš„ç½‘ç»œç»“æ„ä¸­è¿›è¡Œæ·»åŠ (**å€¼å¾—ä¸€æçš„æ˜¯ä¸€ä¸ªSAConvå¤§æ¦‚å¯ä»¥é™ä½0.3GFLOPs**)ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f0691a08e44c4509bf82049900d76053.png)

äºŒã€SAConvçš„æœºåˆ¶åŸç†ä»‹ç»
---------------

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/cb811ce9d34b4e31ade9e8e28b5645b5.png)

Â **è®ºæ–‡åœ°å€ï¼š**[å®˜æ–¹è®ºæ–‡åœ°å€](https://ar5iv.labs.arxiv.org/html/2006.02334 "å®˜æ–¹è®ºæ–‡åœ°å€")

**ä»£ç åœ°å€ï¼š**[å®˜æ–¹ä»£ç åœ°å€](https://github.com/joe-siyuan-qiao/DetectoRS/tree/master "å®˜æ–¹ä»£ç åœ°å€")

Â ![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e672a6fad00a4c33b2ce0752bf35c16b.png)

**å¯åˆ‡æ¢çš„ç©ºæ´å·ç§¯**ï¼ˆ**Switchable Atrous Convolutionï¼Œç®€ç§°SAC**ï¼‰æ˜¯ä¸€ç§é«˜çº§çš„å·ç§¯æœºåˆ¶ï¼Œç”¨äºåœ¨ç‰©ä½“æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡ä¸­å¢å¼ºç‰¹å¾æå–ã€‚ä»¥ä¸‹æ˜¯SACçš„ä¸»è¦åŸç†å’Œæœºåˆ¶ï¼š

**1\. ä¸åŒç©ºæ´ç‡çš„åº”ç”¨:** SACçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¯¹ç›¸åŒçš„è¾“å…¥ç‰¹å¾åº”ç”¨ä¸åŒçš„ç©ºæ´ç‡è¿›è¡Œå·ç§¯ã€‚**ç©ºæ´å·ç§¯**é€šè¿‡åœ¨å·ç§¯æ ¸ä¸­å¼•å…¥é¢å¤–çš„ç©ºé—´ï¼ˆå³ç©ºæ´ï¼‰ï¼Œæ‰©å¤§äº†æ„Ÿå—é‡ï¼Œè€Œä¸å¢åŠ å‚æ•°æ•°é‡æˆ–è®¡ç®—é‡ã€‚SACåˆ©ç”¨è¿™ä¸€ç‚¹æ¥æ•è·ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚

**2\. å¼€å…³å‡½æ•°çš„ä½¿ç”¨:** SACçš„å¦ä¸€ä¸ªå…³é”®ç‰¹ç‚¹æ˜¯ä½¿ç”¨å¼€å…³å‡½æ•°æ¥ç»„åˆä¸åŒç©ºæ´ç‡å·ç§¯çš„ç»“æœã€‚è¿™äº›å¼€å…³å‡½æ•°æ˜¯ç©ºé—´ä¾èµ–çš„ï¼Œæ„å‘³ç€ç‰¹å¾å›¾çš„æ¯ä¸ªä½ç½®å¯èƒ½æœ‰ä¸åŒçš„å¼€å…³æ¥æ§åˆ¶SACçš„è¾“å‡ºï¼Œä»è€Œä½¿ç½‘ç»œå¯¹äºç‰¹å¾çš„å¤§å°å’Œå°ºåº¦æ›´åŠ çµæ´»ã€‚

**3\. è½¬æ¢æœºåˆ¶:** SACèƒ½å¤Ÿå°†ä¼ ç»Ÿçš„å·ç§¯å±‚è½¬æ¢ä¸ºSACå±‚ã€‚è¿™æ˜¯é€šè¿‡åœ¨ä¸åŒç©ºæ´ç‡çš„å·ç§¯æ“ä½œä¸­ä½¿ç”¨ç›¸åŒçš„æƒé‡ï¼ˆé™¤äº†ä¸€ä¸ªå¯è®­ç»ƒçš„å·®å¼‚ï¼‰æ¥å®ç°çš„ã€‚è¿™ç§è½¬æ¢æœºåˆ¶åŒ…æ‹¬ä¸€ä¸ªå¹³å‡æ± åŒ–å±‚å’Œä¸€ä¸ª1x1å·ç§¯å±‚ï¼Œä»¥å®ç°å¼€å…³åŠŸèƒ½ã€‚

**4\. ç»“æ„è®¾è®¡:** SACçš„æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼šä¸¤ä¸ªå…¨å±€ä¸Šä¸‹æ–‡æ¨¡å—åˆ†åˆ«ä½äºSACç»„ä»¶çš„å‰åã€‚è¿™äº›æ¨¡å—æœ‰åŠ©äºæ›´å…¨é¢åœ°ç†è§£å›¾åƒå†…å®¹ï¼Œä½¿SACç»„ä»¶èƒ½å¤Ÿåœ¨æ›´å®½æ³›çš„ä¸Šä¸‹æ–‡ä¸­æœ‰æ•ˆåœ°å·¥ä½œã€‚

> **æ€»ç»“**ï¼šSACé€šè¿‡è¿™äº›åˆ›æ–°çš„è®¾è®¡å’Œæœºåˆ¶ï¼Œæé«˜äº†ç½‘ç»œåœ¨å¤„ç†ä¸åŒå°ºåº¦å’Œå¤æ‚åº¦çš„ç‰¹å¾æ—¶çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ï¼Œä»è€Œåœ¨ç‰©ä½“æ£€æµ‹å’Œåˆ†å‰²é¢†åŸŸæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0a091a3eab014a6ab0e821350107163c.png)

Â ä¸Šå›¾æˆ‘ä»¬èƒ½çœ‹åˆ°å…¶ä¸­çš„å…³é”®ç‚¹å¦‚ä¸‹->

*   **åŒé‡è§‚å¯Ÿæœºåˆ¶**: SACç‰¹åˆ«è®¾è®¡äº†ä¸€ç§æœºåˆ¶ï¼Œå®ƒèƒ½å¤Ÿå¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œä¸¤æ¬¡è§‚å¯Ÿï¼Œä½†æ¯æ¬¡ä½¿ç”¨ä¸åŒçš„ç©ºæ´ç‡ã€‚è¿™æ„å‘³ç€ï¼ŒåŒä¸€ç»„è¾“å…¥ç‰¹å¾ä¼šè¢«ä¸¤ç§ä¸åŒé…ç½®çš„å·ç§¯æ ¸å¤„ç†ï¼Œå…¶ä¸­æ¯ç§é…ç½®å¯¹åº”ä¸€ç§ç‰¹å®šçš„ç©ºæ´ç‡ã€‚è¿™æ ·åšå¯ä»¥æ•è·ä¸åŒå°ºåº¦çš„ç‰¹å¾ä¿¡æ¯ï¼Œä»è€Œæ›´å…¨é¢åœ°ç†è§£å’Œåˆ†æè¾“å…¥æ•°æ®ã€‚
    
*   **å¼€å…³å‡½æ•°çš„åº”ç”¨**: ä¸åŒç©ºæ´ç‡å¾—åˆ°çš„è¾“å‡ºç»“æœéšåé€šè¿‡å¼€å…³å‡½æ•°ç»“åˆåœ¨ä¸€èµ·ã€‚è¿™äº›å¼€å…³å†³å®šäº†å¦‚ä½•ä»ä¸¤æ¬¡å·ç§¯ä¸­é€‰æ‹©æˆ–èåˆä¿¡æ¯ï¼Œä»è€Œç”Ÿæˆæœ€ç»ˆçš„è¾“å‡ºç‰¹å¾ã€‚å¼€å…³çš„è¿ä½œæ–¹å¼å¯èƒ½ä¾èµ–äºç‰¹å¾æœ¬èº«çš„ç‰¹æ€§ï¼Œå¦‚å…¶ç©ºé—´ä½ç½®ç­‰ã€‚

> **æ€»ç»“**ï¼šSACé€šè¿‡è¿™ç§â€œåŒé‡è§‚å¯Ÿå¹¶ç»“åˆâ€çš„ç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å¤æ‚çš„ç‰¹å¾æ¨¡å¼ï¼Œç‰¹åˆ«æ˜¯åœ¨å°ºåº¦å˜åŒ–è¾ƒå¤§çš„æƒ…å†µä¸‹ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†ç‰¹å¾æå–çš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œè€Œä¸”è¿˜æå‡äº†ç‰©ä½“æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

![](https://img-blog.csdnimg.cn/9020ea11215443e9ab28a7908839e329.png)

åœ¨ä¸Šå›¾ä¸­å±•ç¤ºäº†å¯åˆ‡æ¢çš„ç©ºæ´å·ç§¯ï¼ˆSwitchable Atrous Convolution, SACï¼‰çš„å…·ä½“å®ç°æ–¹å¼ã€‚è¿™é‡Œçš„å…³é”®ç‚¹åŒ…æ‹¬ï¼š

1.  **è½¬æ¢ä¼ ç»Ÿå·ç§¯å±‚ä¸ºSAC**: ä»–ä»¬å°†éª¨å¹²ç½‘ç»œResNetä¸­çš„æ¯ä¸€ä¸ª3x3å·ç§¯å±‚éƒ½è½¬æ¢ä¸ºSACã€‚è¿™ç§è½¬æ¢ä½¿å¾—å·ç§¯è®¡ç®—å¯ä»¥åœ¨ä¸åŒçš„ç©ºæ´ç‡ä¹‹é—´è½¯åˆ‡æ¢ã€‚
    
2.  **æƒé‡å…±äº«ä¸è®­ç»ƒå·®å¼‚**: é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œå°½ç®¡SACåœ¨ä¸åŒçš„ç©ºæ´ç‡é—´è¿›è¡Œåˆ‡æ¢ï¼Œä½†æ‰€æœ‰è¿™äº›æ“ä½œå…±äº«ç›¸åŒçš„æƒé‡ï¼Œåªæœ‰ä¸€ä¸ªå¯è®­ç»ƒçš„å·®å¼‚ã€‚è¿™ç§è®¾è®¡å‡å°‘äº†æ¨¡å‹å¤æ‚æ€§ï¼ŒåŒæ—¶ä¿æŒäº†çµæ´»æ€§ã€‚
    
3.  **å…¨å±€ä¸Šä¸‹æ–‡æ¨¡å—**: SACç»“æ„è¿˜åŒ…æ‹¬ä¸¤ä¸ªå…¨å±€ä¸Šä¸‹æ–‡æ¨¡å—ï¼Œè¿™äº›æ¨¡å—ä¸ºç‰¹å¾æ·»åŠ äº†å›¾åƒçº§çš„ä¿¡æ¯ã€‚å…¨å±€ä¸Šä¸‹æ–‡æ¨¡å—æœ‰åŠ©äºç½‘ç»œæ›´å¥½åœ°ç†è§£å’Œå¤„ç†å›¾åƒçš„æ•´ä½“å†…å®¹ï¼Œä»è€Œæé«˜ç‰¹å¾æå–çš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚
    

> **æ€»ç»“**ï¼šSACé€šè¿‡è¿™äº›æœºåˆ¶ï¼Œå…è®¸ç½‘ç»œåœ¨ä¸åŒçš„ç©ºæ´ç‡ä¹‹é—´çµæ´»åˆ‡æ¢ï¼ŒåŒæ—¶é€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡æ¨¡å—å’Œå…±äº«æƒé‡çš„ç­–ç•¥ï¼Œæœ‰æ•ˆåœ°æå‡äº†ç‰¹å¾çš„æå–å’Œå¤„ç†èƒ½åŠ›ã€‚è¿™äº›ç‰¹æ€§ä½¿å¾—SACåœ¨ç‰©ä½“æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

**ä¸‹é¢æ˜¯éƒ¨åˆ†çš„æ£€æµ‹æ•ˆæœå›¾->**Â 

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/397e3e386358406687b6d1771f99cdf8.png)

* * *

ä¸‰ã€SAConvä»£ç å¤ç°Â 
-------------

```python
import torch
import torch.nn as nn
from ultralytics.nn.modules.conv import autopad, Conv
 
__all__ = ['SAConv2d', 'C2f_SAConv']
 
class ConvAWS2d(nn.Conv2d):
    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size,
                 stride=1,
                 padding=0,
                 dilation=1,
                 groups=1,
                 bias=True):
        super().__init__(
            in_channels,
            out_channels,
            kernel_size,
            stride=stride,
            padding=padding,
            dilation=dilation,
            groups=groups,
            bias=bias)
        self.register_buffer('weight_gamma', torch.ones(self.out_channels, 1, 1, 1))
        self.register_buffer('weight_beta', torch.zeros(self.out_channels, 1, 1, 1))
 
    def _get_weight(self, weight):
        weight_mean = weight.mean(dim=1, keepdim=True).mean(dim=2,
                                                            keepdim=True).mean(dim=3, keepdim=True)
        weight = weight - weight_mean
        std = torch.sqrt(weight.view(weight.size(0), -1).var(dim=1) + 1e-5).view(-1, 1, 1, 1)
        weight = weight / std
        weight = self.weight_gamma * weight + self.weight_beta
        return weight
 
    def forward(self, x):
        weight = self._get_weight(self.weight)
        return super()._conv_forward(x, weight, None)
 
    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,
                              missing_keys, unexpected_keys, error_msgs):
        self.weight_gamma.data.fill_(-1)
        super()._load_from_state_dict(state_dict, prefix, local_metadata, strict,
                                      missing_keys, unexpected_keys, error_msgs)
        if self.weight_gamma.data.mean() > 0:
            return
        weight = self.weight.data
        weight_mean = weight.data.mean(dim=1, keepdim=True).mean(dim=2,
                                                                 keepdim=True).mean(dim=3, keepdim=True)
        self.weight_beta.data.copy_(weight_mean)
        std = torch.sqrt(weight.view(weight.size(0), -1).var(dim=1) + 1e-5).view(-1, 1, 1, 1)
        self.weight_gamma.data.copy_(std)
 
 
class SAConv2d(ConvAWS2d):
    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size,
                 s=1,
                 p=None,
                 g=1,
                 d=1,
                 act=True,
                 bias=True):
        super().__init__(
            in_channels,
            out_channels,
            kernel_size,
            stride=s,
            padding=autopad(kernel_size, p, d),
            dilation=d,
            groups=g,
            bias=bias)
        self.switch = torch.nn.Conv2d(
            self.in_channels,
            1,
            kernel_size=1,
            stride=s,
            bias=True)
        self.switch.weight.data.fill_(0)
        self.switch.bias.data.fill_(1)
        self.weight_diff = torch.nn.Parameter(torch.Tensor(self.weight.size()))
        self.weight_diff.data.zero_()
        self.pre_context = torch.nn.Conv2d(
            self.in_channels,
            self.in_channels,
            kernel_size=1,
            bias=True)
        self.pre_context.weight.data.fill_(0)
        self.pre_context.bias.data.fill_(0)
        self.post_context = torch.nn.Conv2d(
            self.out_channels,
            self.out_channels,
            kernel_size=1,
            bias=True)
        self.post_context.weight.data.fill_(0)
        self.post_context.bias.data.fill_(0)
 
        self.bn = nn.BatchNorm2d(out_channels)
        self.act = Conv.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()
 
    def forward(self, x):
        # pre-context
        avg_x = torch.nn.functional.adaptive_avg_pool2d(x, output_size=1)
        avg_x = self.pre_context(avg_x)
        avg_x = avg_x.expand_as(x)
        x = x + avg_x
        # switch
        avg_x = torch.nn.functional.pad(x, pad=(2, 2, 2, 2), mode="reflect")
        avg_x = torch.nn.functional.avg_pool2d(avg_x, kernel_size=5, stride=1, padding=0)
        switch = self.switch(avg_x)
        # sac
        weight = self._get_weight(self.weight)
        out_s = super()._conv_forward(x, weight, None)
        ori_p = self.padding
        ori_d = self.dilation
        self.padding = tuple(3 * p for p in self.padding)
        self.dilation = tuple(3 * d for d in self.dilation)
        weight = weight + self.weight_diff
        out_l = super()._conv_forward(x, weight, None)
        out = switch * out_s + (1 - switch) * out_l
        self.padding = ori_p
        self.dilation = ori_d
        # post-context
        avg_x = torch.nn.functional.adaptive_avg_pool2d(out, output_size=1)
        avg_x = self.post_context(avg_x)
        avg_x = avg_x.expand_as(out)
        out = out + avg_x
        return self.act(self.bn(out))
 
 
class Bottleneck_SAConv(nn.Module):
    """Standard bottleneck."""
 
    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5):
        """Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and
        expansion.
        """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, k[0], 1)
        self.cv2 = SAConv2d(c_, c2, k[1], 1, g=g)
        self.add = shortcut and c1 == c2
 
    def forward(self, x):
        """'forward()' applies the YOLO FPN to input data."""
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
 
 
class C2f_SAConv(nn.Module):
    """Faster Implementation of CSP Bottleneck with 2 convolutions."""
 
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        """Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,
        expansion.
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.ModuleList(
            Bottleneck_SAConv(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))
 
    def forward(self, x):
        """Forward pass through C2f layer."""
        x = self.cv1(x)
        x = x.chunk(2, 1)
        y = list(x)
        # y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))
 
    def forward_split(self, x):
        """Forward pass using split() instead of chunk()."""
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))
```

* * *

å››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ SAConvÂ 
----------------

### 4.1Â SAConvçš„æ·»åŠ æ•™ç¨‹

#### 4.1.1Â ä¿®æ”¹ä¸€

ç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nnæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯'Addmodules'æ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c119d0726c94484e88d3f61eeec03265.png)



* * *

#### 4.1.2 ä¿®æ”¹äºŒÂ 

ç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º'\_\_init\_\_.py'ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

* * *

#### 4.1.3 ä¿®æ”¹ä¸‰Â 

ç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/nn/tasks.py'è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/67b28bda87e44d3285f0241acd165256.png)â€‹

* * *

#### 4.1.4 ä¿®æ”¹å››Â 

æŒ‰ç…§æˆ‘çš„æ·»åŠ åœ¨parse\_modelé‡Œæ·»åŠ å³å¯ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/cce195e39f8c4538847905dda7c0128f.png)

**åˆ°æ­¤å°±ä¿®æ”¹å®Œæˆäº†ï¼Œå¤§å®¶å¯ä»¥å¤åˆ¶ä¸‹é¢çš„yamlæ–‡ä»¶è¿è¡Œã€‚**

### 4.2Â SAConvçš„yamlæ–‡ä»¶å’Œè®­ç»ƒæˆªå›¾

#### 5.2.1 SAConvçš„yamlæ–‡ä»¶

```python
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
 
# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs
 
# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f_SAConv, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f_SAConv, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f_SAConv, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f_SAConv, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
 
# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12
 
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)
 
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)
 
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)
 
  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```

#### 5.2.2 SAConvçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾Â 

> **ä¸‹é¢æ˜¯æ·»åŠ äº†**SAConv**çš„è®­ç»ƒæˆªå›¾ã€‚**
> 
> **ä¸‹é¢çš„æ˜¯å°†**SAConv**æœºåˆ¶æ·»åŠ åˆ°äº†C2få’ŒBottleneckã€‚**

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c390bfa52b3b4fc1b42af2dd43a1bb58.png)

* * *

äº”ã€SAConvå¯æ·»åŠ çš„ä½ç½®
--------------

### 5.1 æ¨èSAConvå¯æ·»åŠ çš„ä½ç½®Â 

SAConv**å¯ä»¥æ˜¯ä¸€ç§å³æ’å³ç”¨çš„å·ç§¯**ï¼Œå…¶å¯ä»¥æ·»åŠ çš„ä½ç½®æœ‰å¾ˆå¤šï¼Œæ·»åŠ çš„ä½ç½®ä¸åŒæ•ˆæœä¹Ÿä¸åŒï¼Œæ‰€ä»¥æˆ‘ä¸‹é¢æ¨èå‡ ä¸ªæ·»åŠ çš„ä½ï¼Œç½®å¤§å®¶å¯ä»¥è¿›è¡Œå‚è€ƒï¼Œå½“ç„¶ä¸ä¸€å®šè¦æŒ‰ç…§æˆ‘æ¨èçš„åœ°æ–¹æ·»åŠ ã€‚

> 1.  **æ®‹å·®è¿æ¥ä¸­**ï¼šåœ¨æ®‹å·®ç½‘ç»œçš„æ®‹å·®è¿æ¥ä¸­åŠ å…¥SAConv
>     
> 2.  **Neckéƒ¨åˆ†**ï¼šYOLOv8çš„Neckéƒ¨åˆ†è´Ÿè´£ç‰¹å¾èåˆï¼Œè¿™é‡Œæ·»åŠ ä¿®æ”¹åçš„C2få’ŒSAConvå¯ä»¥å¸®åŠ©æ¨¡å‹æ›´æœ‰æ•ˆåœ°èåˆä¸åŒå±‚æ¬¡çš„ç‰¹å¾ã€‚
>     
> 3.  **æ£€æµ‹å¤´ä¸­çš„å·ç§¯**ï¼šåœ¨æœ€ç»ˆçš„è¾“å‡ºå±‚å‰åŠ å…¥SAConvå¯ä»¥ä½¿æ¨¡å‹åœ¨åšå‡ºæœ€ç»ˆé¢„æµ‹ä¹‹å‰ï¼Œæ›´åŠ é›†ä¸­æ³¨æ„åŠ›äºæœ€å…³é”®çš„ç‰¹å¾ã€‚
>     

**æ–‡å­—å¤§å®¶å¯èƒ½çœ‹æˆ‘æè¿°ä¸å¤ªæ‡‚ï¼Œå¤§å®¶å¯ä»¥çœ‹ä¸‹é¢çš„ç½‘ç»œç»“æ„å›¾ä¸­æˆ‘è¿›è¡Œäº†æ ‡æ³¨ã€‚**

### **5.2å›¾ç¤º**LSKAttention**å¯æ·»åŠ çš„ä½ç½®**Â 

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2949694815404620bdfb5875286c8e73.png)
