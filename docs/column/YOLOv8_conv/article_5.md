 # DBB

ä¸€ã€æœ¬æ–‡ä»‹ç»
------

æœ¬æ–‡å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯YOLOv8æ¨¡åž‹ä¸Ž**å¤šå…ƒåˆ†æ”¯æ¨¡å—** **ï¼ˆDiverse Branch Blockï¼‰**çš„ç»“åˆï¼ŒDiverse Branch Block (DBB) æ˜¯ä¸€ç§ç”¨äºŽ**å¢žå¼ºå·ç§¯ç¥žç»ç½‘ç»œæ€§èƒ½çš„ç»“æž„é‡æ–°å‚æ•°åŒ–æŠ€æœ¯**ã€‚è¿™ç§æŠ€æœ¯çš„æ ¸å¿ƒåœ¨äºŽç»“åˆå¤šæ ·åŒ–çš„åˆ†æ”¯ï¼Œè¿™äº›åˆ†æ”¯å…·æœ‰ä¸åŒçš„å°ºåº¦å’Œå¤æ‚åº¦ï¼Œä»Žè€Œä¸°å¯Œç‰¹å¾ç©ºé—´ã€‚**æˆ‘å°†å…¶æ”¾åœ¨äº†YOLOv8çš„ä¸åŒä½ç½®ä¸Šå‡æœ‰ä¸€å®šçš„æ¶¨ç‚¹å¹…åº¦**ï¼ŒåŒæ—¶è¿™ä¸ªDBBæ¨¡å—çš„å‚æ•°é‡å¹¶ä¸ä¼šä¸Šæ¶¨å¤ªå¤šï¼Œæˆ‘æ·»åŠ ä¸‰ä¸ªè¯¥æœºåˆ¶åˆ°æ¨¡åž‹ä¸­ï¼Œ**GFLOPsä¸Šæ¶¨äº†0.4ã€‚**

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0398b80d43394f8988c7c0264dcc8036.png)

* * *

äºŒã€Diverse Branch BlockåŽŸç†
------------------------

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/d6976fa876a54a798ed5049bdc7c6f60.png)

**è®ºæ–‡åœ°å€ï¼š**[è®ºæ–‡å®˜æ–¹åœ°å€](https://arxiv.org/pdf/2103.13425.pdf "è®ºæ–‡å®˜æ–¹åœ°å€")

**ä»£ç åœ°å€ï¼š[å®˜æ–¹ä»£ç åœ°å€](https://github.com/DingXiaoH/DiverseBranchBlock "å®˜æ–¹ä»£ç åœ°å€")**

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ed1c3dc3061a470c89c43dc1f37068b2.png)

* * *

### 2.1Â Diverse Branch Blockçš„åŸºæœ¬åŽŸç†

Diverse Branch Blockï¼ˆDBBï¼‰çš„åŸºæœ¬åŽŸç†æ˜¯åœ¨è®­ç»ƒé˜¶æ®µå¢žåŠ å·ç§¯å±‚çš„å¤æ‚æ€§ï¼Œé€šè¿‡**å¼•å…¥ä¸åŒå°ºå¯¸å’Œç»“æž„çš„å·ç§¯åˆ†æ”¯**æ¥ä¸°å¯Œç½‘ç»œçš„ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ã€‚æˆ‘ä»¬å¯ä»¥å°†åŸºæœ¬åŽŸç†å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š

**1\. å¤šæ ·åŒ–åˆ†æ”¯ç»“æž„**ï¼šDBB ç»“åˆäº†ä¸åŒå°ºåº¦å’Œå¤æ‚åº¦çš„åˆ†æ”¯ï¼Œå¦‚ä¸åŒå¤§å°çš„å·ç§¯æ ¸å’Œå¹³å‡æ± åŒ–ï¼Œä»¥å¢žåŠ å•ä¸ªå·ç§¯çš„ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚  
**2\. è®­ç»ƒä¸ŽæŽ¨ç†åˆ†ç¦»**ï¼šåœ¨è®­ç»ƒé˜¶æ®µï¼ŒDBB é‡‡ç”¨å¤æ‚çš„åˆ†æ”¯ç»“æž„ï¼Œè€Œåœ¨æŽ¨ç†é˜¶æ®µï¼Œè¿™äº›åˆ†æ”¯å¯ä»¥è¢«ç­‰æ•ˆåœ°è½¬æ¢ä¸ºå•ä¸ªå·ç§¯å±‚ï¼Œä»¥ä¿æŒé«˜æ•ˆæŽ¨ç†ã€‚  
**3\. å®è§‚æž¶æž„ä¸å˜**ï¼šDBB å…è®¸åœ¨ä¸æ”¹å˜æ•´ä½“ç½‘ç»œæž¶æž„çš„æƒ…å†µä¸‹ï¼Œä½œä¸ºå¸¸è§„å·ç§¯å±‚çš„æ›¿ä»£å“æ’å…¥åˆ°çŽ°æœ‰ç½‘ç»œä¸­ã€‚

ä¸‹é¢æˆ‘å°†ä¸ºå¤§å®¶å±•ç¤ºDiverse Branch Blockï¼ˆDBBï¼‰çš„**è®¾è®¡ç¤ºä¾‹**ï¼š

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bfe8fdeaf340471193a52c0a316087c7.png)

åœ¨è®­ç»ƒæ—¶ï¼ˆå·¦ä¾§ï¼‰ï¼ŒDBBç”±ä¸åŒå¤§å°çš„å·ç§¯å±‚å’Œå¹³å‡æ± åŒ–å±‚ç»„æˆï¼Œè¿™äº›å±‚ä»¥ä¸€ç§å¤æ‚çš„æ–¹å¼å¹¶è¡ŒæŽ’åˆ—ï¼Œå¹¶æœ€ç»ˆåˆå¹¶è¾“å‡ºã€‚è®­ç»ƒå®ŒæˆåŽï¼Œè¿™äº›å¤æ‚çš„ç»“æž„ä¼š**è½¬æ¢æˆå•ä¸ªå·ç§¯å±‚**ï¼Œç”¨äºŽæ¨¡åž‹çš„æŽ¨ç†é˜¶æ®µï¼ˆå³ä¾§ï¼‰ï¼Œä»¥æ­¤ä¿æŒæŽ¨ç†æ—¶çš„æ•ˆçŽ‡ã€‚è¿™ç§è½¬æ¢å…è®¸DBBåœ¨**ä¿æŒå®è§‚æž¶æž„ä¸å˜**çš„åŒæ—¶ï¼Œå¢žåŠ è®­ç»ƒæ—¶çš„å¾®è§‚ç»“æž„å¤æ‚æ€§ã€‚

* * *

### **2.2Â å¤šæ ·åŒ–åˆ†æ”¯ç»“æž„**

å¤šæ ·åŒ–åˆ†æ”¯ç»“æž„æ˜¯åœ¨å·ç§¯ç¥žç»ç½‘ç»œä¸­å¼•å…¥çš„ä¸€ç§ç»“æž„ï¼Œæ—¨åœ¨é€šè¿‡**å¤šæ ·åŒ–çš„åˆ†æ”¯æ¥å¢žå¼ºæ¨¡åž‹çš„ç‰¹å¾æå–èƒ½åŠ›**ã€‚è¿™äº›åˆ†æ”¯åŒ…å«ä¸åŒå°ºå¯¸çš„å·ç§¯å±‚å’Œæ± åŒ–å±‚ï¼Œä»¥åŠå…¶ä»–æ½œåœ¨çš„æ“ä½œï¼Œå®ƒä»¬å¹¶è¡Œå·¥ä½œä»¥æ•èŽ·ä¸åŒçš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨è®­ç»ƒå®ŒæˆåŽï¼Œè¿™äº›å¤æ‚çš„ç»“æž„å¯ä»¥åˆå¹¶å¹¶ç®€åŒ–ä¸ºå•ä¸ªçš„å·ç§¯å±‚ï¼Œä»¥ä¾¿åœ¨æŽ¨ç†æ—¶ä¸å¢žåŠ é¢å¤–çš„è®¡ç®—è´Ÿæ‹…ã€‚è¿™ç§è®¾è®¡ä½¿å¾—DBBå¯ä»¥ä½œä¸ºçŽ°æœ‰å·ç§¯å±‚çš„**ç›´æŽ¥æ›¿æ¢**ï¼Œå¢žå¼ºäº†çŽ°æœ‰ç½‘ç»œæž¶æž„çš„æ€§èƒ½ï¼Œè€Œ**ä¸éœ€è¦ä¿®æ”¹æ•´ä½“æž¶æž„**ã€‚

ä¸‹é¢æˆ‘è¯¦ç»†å±•ç¤ºäº†å¦‚ä½•é€šè¿‡å…­ç§è½¬æ¢æ–¹æ³•å°†è®­ç»ƒæ—¶çš„Diverse Branch Blockï¼ˆDBBï¼‰è½¬æ¢ä¸ºæŽ¨ç†æ—¶çš„å¸¸è§„å·ç§¯å±‚ï¼Œæ¯ä¸€ç§è½¬æ¢å¯¹åº”äºŽä¸€ç§ç‰¹å®šçš„æ“ä½œï¼š

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0b9d1491300641dc890837e8ca5d8423.png)

**1\. Transform I**ï¼šå°†å…·æœ‰æ‰¹é‡è§„èŒƒåŒ–ï¼ˆbatch normï¼‰çš„å·ç§¯å±‚èžåˆã€‚  
**2\. Transform II**ï¼šåˆå¹¶å…·æœ‰ç›¸åŒé…ç½®çš„å·ç§¯å±‚çš„è¾“å‡ºã€‚  
**3\. Transform III**ï¼šåˆå¹¶åºåˆ—å·ç§¯å±‚ã€‚  
**4\. Transform IV**ï¼šé€šè¿‡æ·±åº¦ä¸²è”ï¼ˆconcatï¼‰æ¥åˆå¹¶å·ç§¯å±‚ã€‚  
**5\. Transform V**ï¼šå°†å¹³å‡æ± åŒ–ï¼ˆAVGï¼‰æ“ä½œèžå…¥å·ç§¯æ“ä½œä¸­ã€‚  
**6\. Transform VI**ï¼šç»“åˆä¸åŒå°ºåº¦çš„å·ç§¯å±‚ã€‚

å¯ä»¥çœ‹åˆ°å³ä¾§çš„æ¡†æ˜¾ç¤ºäº†ç»è¿‡è¿™äº›è½¬æ¢åŽï¼Œå¯ä»¥å®žçŽ°çš„æŽ¨ç†æ—¶DBBï¼Œå…¶ä¸­åŒ…å«äº†å¸¸è§„å·ç§¯ã€å¹³å‡æ± åŒ–å’Œæ‰¹é‡è§„èŒƒåŒ–æ“ä½œã€‚è¿™äº›è½¬æ¢ç¡®ä¿äº†åœ¨ä¸å¢žåŠ æŽ¨ç†æ—¶è´Ÿæ‹…çš„åŒæ—¶ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒæ—¶åˆ©ç”¨DBBçš„å¤šæ ·åŒ–ç‰¹å¾æå–èƒ½åŠ›ã€‚

* * *

### Â 2.3Â **è®­ç»ƒä¸ŽæŽ¨ç†åˆ†ç¦»**

è®­ç»ƒä¸ŽæŽ¨ç†åˆ†ç¦»çš„æ¦‚å¿µæ˜¯æŒ‡åœ¨æ¨¡åž‹**è®­ç»ƒé˜¶æ®µä½¿ç”¨å¤æ‚çš„DBBç»“æž„**ï¼Œè€Œåœ¨**æ¨¡åž‹æŽ¨ç†é˜¶æ®µåˆ™è½¬æ¢ä¸ºç®€åŒ–çš„å·ç§¯ç»“æž„**ã€‚è¿™ç§è®¾è®¡å…è®¸æ¨¡åž‹åœ¨è®­ç»ƒæ—¶åˆ©ç”¨DBBçš„å¤šæ ·æ€§æ¥å¢žå¼ºç‰¹å¾æå–å’Œå­¦ä¹ èƒ½åŠ›ï¼Œè€Œåœ¨å®žé™…åº”ç”¨ä¸­ï¼Œå³æŽ¨ç†æ—¶ï¼Œé€šè¿‡å‡å°‘è®¡ç®—é‡æ¥ä¿æŒé«˜æ•ˆã€‚è¿™æ ·ï¼Œæ¨¡åž‹åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œä¹Ÿä¿è¯äº†è¿è¡Œé€Ÿåº¦å’Œèµ„æºæ•ˆçŽ‡ã€‚

ä¸Šé¢æˆ‘å°†å±•ç¤ºåœ¨è®­ç»ƒé˜¶æ®µå¦‚ä½•é€šè¿‡ä¸åŒçš„å·ç§¯ç»„åˆï¼ˆå¦‚å›¾ä¸­çš„1x1å’ŒKxKå·ç§¯ï¼‰ï¼Œä»¥åŠåœ¨æŽ¨ç†é˜¶æ®µå¦‚ä½•å°†è¿™äº›ç»„åˆè½¬æ¢æˆä¸€ä¸ªç®€åŒ–çš„ç»“æž„ï¼ˆå¦‚å›¾ä¸­çš„è½¬æ¢IVæ‰€ç¤ºçš„æ‹¼æŽ¥æ“ä½œï¼‰ï¼š

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0f824a980ba043db91a80159a38f04b4.png)

ç»è¿‡åˆ†æžï¼Œæˆ‘ä»¬å¯ä»¥å‘çŽ°å®ƒè¯´æ˜Žäº†**ä¸‰ç§ä¸åŒçš„æƒ…å†µ**ï¼š

Aï¼‰ç»„å·ç§¯ï¼ˆGroupwise convï¼‰ï¼šå°†è¾“å…¥åˆ†æˆå¤šä¸ªç»„ï¼Œæ¯ä¸ªç»„ä½¿ç”¨ä¸åŒçš„å·ç§¯æ ¸ã€‚  
Bï¼‰è®­ç»ƒæ—¶çš„1x1-KxKç»“æž„ï¼šé¦–å…ˆåº”ç”¨1x1çš„å·ç§¯ï¼ˆå‡å°‘ç‰¹å¾ç»´åº¦ï¼‰ï¼Œç„¶åŽæ˜¯åˆ†ç»„çš„KxKå·ç§¯ã€‚  
Cï¼‰ä»Žè½¬æ¢IVçš„è§’åº¦çœ‹ï¼šè¿™æ˜¯å°†å¤šä¸ªåˆ†ç»„çš„å·ç§¯è¾“å‡ºåˆå¹¶çš„è§†è§’ã€‚è¿™é‡Œï¼Œç»„å†…å·ç§¯åŽçš„ç‰¹å¾å›¾å…ˆåˆ†åˆ«é€šè¿‡1x1å·ç§¯å¤„ç†ï¼Œç„¶åŽå†è¿›è¡Œæ‹¼æŽ¥ï¼ˆconcatï¼‰ã€‚

* * *

### 2.4Â **å®è§‚æž¶æž„ä¸å˜**

å®è§‚æž¶æž„ä¸å˜æŒ‡çš„æ˜¯DBBåœ¨è®¾è®¡æ—¶**è€ƒè™‘åˆ°äº†ä¸ŽçŽ°æœ‰çš„ç½‘ç»œæž¶æž„å…¼å®¹æ€§**ï¼Œç¡®ä¿å¯ä»¥åœ¨ä¸æ”¹å˜æ•´ä½“ç½‘ç»œæž¶æž„ï¼ˆå¦‚ResNetç­‰æµè¡Œæž¶æž„ï¼‰çš„å‰æä¸‹ï¼Œå°†DBBä½œä¸ºä¸€ä¸ªæ¨¡å—åµŒå…¥ã€‚è¿™æ„å‘³ç€DBBå¢žå¼ºäº†ç½‘ç»œçš„ç‰¹å¾æå–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†åŽŸæœ‰ç½‘ç»œç»“æž„çš„å¸ƒå±€ï¼Œç¡®ä¿äº†æŽ¨ç†æ—¶çš„æ•ˆçŽ‡å’Œæ€§èƒ½ã€‚è¿™æ ·çš„è®¾è®¡å…è®¸ç ”ç©¶è€…å’Œå¼€å‘è€…å°†DBBç›´æŽ¥åº”ç”¨åˆ°çŽ°æœ‰çš„æ·±åº¦å­¦ä¹ æ¨¡åž‹ä¸­ï¼Œè€Œæ— éœ€è¿›è¡Œå¤§è§„æ¨¡çš„æž¶æž„è°ƒæ•´ã€‚

* * *

ä¸‰ã€Diverse Branch Blockçš„æ ¸å¿ƒä»£ç 
---------------------------

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
 
 
__all__ = ['DiverseBranchBlock', 'C2f_DBB']
 
def autopad(k, p=None, d=1):  # kernel, padding, dilation
    """Pad to 'same' shape outputs."""
    if d > 1:
        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p
 
 
class Conv(nn.Module):
    """Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)."""
    default_act = nn.SiLU()  # default activation
 
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        """Initialize Conv layer with given arguments including activation."""
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()
 
    def forward(self, x):
        """Apply convolution, batch normalization and activation to input tensor."""
        return self.act(self.bn(self.conv(x)))
 
    def forward_fuse(self, x):
        """Perform transposed convolution of 2D data."""
        return self.act(self.conv(x))
 
def transI_fusebn(kernel, bn):
    gamma = bn.weight
    std = (bn.running_var + bn.eps).sqrt()
    return kernel * ((gamma / std).reshape(-1, 1, 1, 1)), bn.bias - bn.running_mean * gamma / std
 
 
def transII_addbranch(kernels, biases):
    return sum(kernels), sum(biases)
 
 
def transIII_1x1_kxk(k1, b1, k2, b2, groups):
    if groups == 1:
        k = F.conv2d(k2, k1.permute(1, 0, 2, 3))  #
        b_hat = (k2 * b1.reshape(1, -1, 1, 1)).sum((1, 2, 3))
    else:
        k_slices = []
        b_slices = []
        k1_T = k1.permute(1, 0, 2, 3)
        k1_group_width = k1.size(0) // groups
        k2_group_width = k2.size(0) // groups
        for g in range(groups):
            k1_T_slice = k1_T[:, g * k1_group_width:(g + 1) * k1_group_width, :, :]
            k2_slice = k2[g * k2_group_width:(g + 1) * k2_group_width, :, :, :]
            k_slices.append(F.conv2d(k2_slice, k1_T_slice))
            b_slices.append(
                (k2_slice * b1[g * k1_group_width:(g + 1) * k1_group_width].reshape(1, -1, 1, 1)).sum((1, 2, 3)))
        k, b_hat = transIV_depthconcat(k_slices, b_slices)
    return k, b_hat + b2
 
 
def transIV_depthconcat(kernels, biases):
    return torch.cat(kernels, dim=0), torch.cat(biases)
 
 
def transV_avg(channels, kernel_size, groups):
    input_dim = channels // groups
    k = torch.zeros((channels, input_dim, kernel_size, kernel_size))
    k[np.arange(channels), np.tile(np.arange(input_dim), groups), :, :] = 1.0 / kernel_size ** 2
    return k
 
 
#   This has not been tested with non-square kernels (kernel.size(2) != kernel.size(3)) nor even-size kernels
def transVI_multiscale(kernel, target_kernel_size):
    H_pixels_to_pad = (target_kernel_size - kernel.size(2)) // 2
    W_pixels_to_pad = (target_kernel_size - kernel.size(3)) // 2
    return F.pad(kernel, [H_pixels_to_pad, H_pixels_to_pad, W_pixels_to_pad, W_pixels_to_pad])
 
 
def conv_bn(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1,
            padding_mode='zeros'):
    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                           stride=stride, padding=padding, dilation=dilation, groups=groups,
                           bias=False, padding_mode=padding_mode)
    bn_layer = nn.BatchNorm2d(num_features=out_channels, affine=True)
    se = nn.Sequential()
    se.add_module('conv', conv_layer)
    se.add_module('bn', bn_layer)
    return se
 
 
class IdentityBasedConv1x1(nn.Conv2d):
    def __init__(self, channels, groups=1):
        super(IdentityBasedConv1x1, self).__init__(in_channels=channels, out_channels=channels, kernel_size=1, stride=1,
                                                   padding=0, groups=groups, bias=False)
 
        assert channels % groups == 0
        input_dim = channels // groups
        id_value = np.zeros((channels, input_dim, 1, 1))
        for i in range(channels):
            id_value[i, i % input_dim, 0, 0] = 1
        self.id_tensor = torch.from_numpy(id_value).type_as(self.weight)
        nn.init.zeros_(self.weight)
 
    def forward(self, input):
        kernel = self.weight + self.id_tensor.to(self.weight.device).type_as(self.weight)
        result = F.conv2d(input, kernel, None, stride=1, padding=0, dilation=self.dilation, groups=self.groups)
        return result
 
    def get_actual_kernel(self):
        return self.weight + self.id_tensor.to(self.weight.device)
 
 
class BNAndPadLayer(nn.Module):
    def __init__(self,
                 pad_pixels,
                 num_features,
                 eps=1e-5,
                 momentum=0.1,
                 affine=True,
                 track_running_stats=True):
        super(BNAndPadLayer, self).__init__()
        self.bn = nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats)
        self.pad_pixels = pad_pixels
 
    def forward(self, input):
        output = self.bn(input)
        if self.pad_pixels > 0:
            if self.bn.affine:
                pad_values = self.bn.bias.detach() - self.bn.running_mean * self.bn.weight.detach() / torch.sqrt(
                    self.bn.running_var + self.bn.eps)
            else:
                pad_values = - self.bn.running_mean / torch.sqrt(self.bn.running_var + self.bn.eps)
            output = F.pad(output, [self.pad_pixels] * 4)
            pad_values = pad_values.view(1, -1, 1, 1)
            output[:, :, 0:self.pad_pixels, :] = pad_values
            output[:, :, -self.pad_pixels:, :] = pad_values
            output[:, :, :, 0:self.pad_pixels] = pad_values
            output[:, :, :, -self.pad_pixels:] = pad_values
        return output
 
    @property
    def weight(self):
        return self.bn.weight
 
    @property
    def bias(self):
        return self.bn.bias
 
    @property
    def running_mean(self):
        return self.bn.running_mean
 
    @property
    def running_var(self):
        return self.bn.running_var
 
    @property
    def eps(self):
        return self.bn.eps
 
 
class DiverseBranchBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size,
                 stride=1, padding=None, dilation=1, groups=1,
                 internal_channels_1x1_3x3=None,
                 deploy=False, single_init=False):
        super(DiverseBranchBlock, self).__init__()
        self.deploy = deploy
 
        self.nonlinear = Conv.default_act
 
        self.kernel_size = kernel_size
        self.out_channels = out_channels
        self.groups = groups
 
        if padding is None:
            padding = autopad(kernel_size, padding, dilation)
        assert padding == kernel_size // 2
 
        if deploy:
            self.dbb_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                                         stride=stride,
                                         padding=padding, dilation=dilation, groups=groups, bias=True)
 
        else:
 
            self.dbb_origin = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                                      stride=stride, padding=padding, dilation=dilation, groups=groups)
 
            self.dbb_avg = nn.Sequential()
            if groups < out_channels:
                self.dbb_avg.add_module('conv',
                                        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1,
                                                  stride=1, padding=0, groups=groups, bias=False))
                self.dbb_avg.add_module('bn', BNAndPadLayer(pad_pixels=padding, num_features=out_channels))
                self.dbb_avg.add_module('avg', nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=0))
                self.dbb_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride,
                                       padding=0, groups=groups)
            else:
                self.dbb_avg.add_module('avg', nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=padding))
 
            self.dbb_avg.add_module('avgbn', nn.BatchNorm2d(out_channels))
 
            if internal_channels_1x1_3x3 is None:
                internal_channels_1x1_3x3 = in_channels if groups < out_channels else 2 * in_channels  # For mobilenet, it is better to have 2X internal channels
 
            self.dbb_1x1_kxk = nn.Sequential()
            if internal_channels_1x1_3x3 == in_channels:
                self.dbb_1x1_kxk.add_module('idconv1', IdentityBasedConv1x1(channels=in_channels, groups=groups))
            else:
                self.dbb_1x1_kxk.add_module('conv1',
                                            nn.Conv2d(in_channels=in_channels, out_channels=internal_channels_1x1_3x3,
                                                      kernel_size=1, stride=1, padding=0, groups=groups, bias=False))
            self.dbb_1x1_kxk.add_module('bn1', BNAndPadLayer(pad_pixels=padding, num_features=internal_channels_1x1_3x3,
                                                             affine=True))
            self.dbb_1x1_kxk.add_module('conv2',
                                        nn.Conv2d(in_channels=internal_channels_1x1_3x3, out_channels=out_channels,
                                                  kernel_size=kernel_size, stride=stride, padding=0, groups=groups,
                                                  bias=False))
            self.dbb_1x1_kxk.add_module('bn2', nn.BatchNorm2d(out_channels))
 
        #   The experiments reported in the paper used the default initialization of bn.weight (all as 1). But changing the initialization may be useful in some cases.
        if single_init:
            #   Initialize the bn.weight of dbb_origin as 1 and others as 0. This is not the default setting.
            self.single_init()
 
    def get_equivalent_kernel_bias(self):
        k_origin, b_origin = transI_fusebn(self.dbb_origin.conv.weight, self.dbb_origin.bn)
 
        if hasattr(self, 'dbb_1x1'):
            k_1x1, b_1x1 = transI_fusebn(self.dbb_1x1.conv.weight, self.dbb_1x1.bn)
            k_1x1 = transVI_multiscale(k_1x1, self.kernel_size)
        else:
            k_1x1, b_1x1 = 0, 0
 
        if hasattr(self.dbb_1x1_kxk, 'idconv1'):
            k_1x1_kxk_first = self.dbb_1x1_kxk.idconv1.get_actual_kernel()
        else:
            k_1x1_kxk_first = self.dbb_1x1_kxk.conv1.weight
        k_1x1_kxk_first, b_1x1_kxk_first = transI_fusebn(k_1x1_kxk_first, self.dbb_1x1_kxk.bn1)
        k_1x1_kxk_second, b_1x1_kxk_second = transI_fusebn(self.dbb_1x1_kxk.conv2.weight, self.dbb_1x1_kxk.bn2)
        k_1x1_kxk_merged, b_1x1_kxk_merged = transIII_1x1_kxk(k_1x1_kxk_first, b_1x1_kxk_first, k_1x1_kxk_second,
                                                              b_1x1_kxk_second, groups=self.groups)
 
        k_avg = transV_avg(self.out_channels, self.kernel_size, self.groups)
        k_1x1_avg_second, b_1x1_avg_second = transI_fusebn(k_avg.to(self.dbb_avg.avgbn.weight.device),
                                                           self.dbb_avg.avgbn)
        if hasattr(self.dbb_avg, 'conv'):
            k_1x1_avg_first, b_1x1_avg_first = transI_fusebn(self.dbb_avg.conv.weight, self.dbb_avg.bn)
            k_1x1_avg_merged, b_1x1_avg_merged = transIII_1x1_kxk(k_1x1_avg_first, b_1x1_avg_first, k_1x1_avg_second,
                                                                  b_1x1_avg_second, groups=self.groups)
        else:
            k_1x1_avg_merged, b_1x1_avg_merged = k_1x1_avg_second, b_1x1_avg_second
 
        return transII_addbranch((k_origin, k_1x1, k_1x1_kxk_merged, k_1x1_avg_merged),
                                 (b_origin, b_1x1, b_1x1_kxk_merged, b_1x1_avg_merged))
 
    def switch_to_deploy(self):
        if hasattr(self, 'dbb_reparam'):
            return
        kernel, bias = self.get_equivalent_kernel_bias()
        self.dbb_reparam = nn.Conv2d(in_channels=self.dbb_origin.conv.in_channels,
                                     out_channels=self.dbb_origin.conv.out_channels,
                                     kernel_size=self.dbb_origin.conv.kernel_size, stride=self.dbb_origin.conv.stride,
                                     padding=self.dbb_origin.conv.padding, dilation=self.dbb_origin.conv.dilation,
                                     groups=self.dbb_origin.conv.groups, bias=True)
        self.dbb_reparam.weight.data = kernel
        self.dbb_reparam.bias.data = bias
        for para in self.parameters():
            para.detach_()
        self.__delattr__('dbb_origin')
        self.__delattr__('dbb_avg')
        if hasattr(self, 'dbb_1x1'):
            self.__delattr__('dbb_1x1')
        self.__delattr__('dbb_1x1_kxk')
 
    def forward(self, inputs):
        if hasattr(self, 'dbb_reparam'):
            return self.nonlinear(self.dbb_reparam(inputs))
 
        out = self.dbb_origin(inputs)
        if hasattr(self, 'dbb_1x1'):
            out += self.dbb_1x1(inputs)
        out += self.dbb_avg(inputs)
        out += self.dbb_1x1_kxk(inputs)
        return self.nonlinear(out)
 
    def init_gamma(self, gamma_value):
        if hasattr(self, "dbb_origin"):
            torch.nn.init.constant_(self.dbb_origin.bn.weight, gamma_value)
        if hasattr(self, "dbb_1x1"):
            torch.nn.init.constant_(self.dbb_1x1.bn.weight, gamma_value)
        if hasattr(self, "dbb_avg"):
            torch.nn.init.constant_(self.dbb_avg.avgbn.weight, gamma_value)
        if hasattr(self, "dbb_1x1_kxk"):
            torch.nn.init.constant_(self.dbb_1x1_kxk.bn2.weight, gamma_value)
 
    def single_init(self):
        self.init_gamma(0.0)
        if hasattr(self, "dbb_origin"):
            torch.nn.init.constant_(self.dbb_origin.bn.weight, 1.0)
 
 
class Bottleneck_DBB(nn.Module):
    """Standard bottleneck."""
 
    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5):
        """Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and
        expansion.
        """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, k[0], 1)
        self.cv2 = DiverseBranchBlock(c_, c2, k[1], 1, g)
        self.add = shortcut and c1 == c2
 
    def forward(self, x):
        """'forward()' applies the YOLO FPN to input data."""
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
 
 
class C2f_DBB(nn.Module):
    """Faster Implementation of CSP Bottleneck with 2 convolutions."""
 
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        """Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,
        expansion.
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.ModuleList(Bottleneck_DBB(self.c, self.c, shortcut, g, k=(3, 3), e=1.0) for _ in range(n))
 
    def forward(self, x):
        """Forward pass through C2f layer."""
        x = self.cv1(x)
        x = x.chunk(2, 1)
        y = list(x)
        # y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))
 
    def forward_split(self, x):
        """Forward pass using split() instead of chunk()."""
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))
```

* * *

å››ã€æ‰‹æŠŠæ‰‹æ•™ä½ æ·»åŠ Diverse Branch Blockæœºåˆ¶
-------------------------------

### 4.1Â Diverse Branch Blockçš„æ·»åŠ æ•™ç¨‹

è¿™ä¸ªæ·»åŠ æ–¹å¼å’Œä¹‹å‰çš„å˜äº†ä¸€ä¸‹ï¼Œä»¥åŽçš„æ·»åŠ æ–¹æ³•éƒ½æŒ‰ç…§è¿™ä¸ªæ¥äº†ï¼Œæ˜¯ä¸ºäº†å’Œç¾¤å†…çš„æ–‡ä»¶é€‚é…ã€‚

* * *

#### 4.1.1 ä¿®æ”¹ä¸€

ç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nn/modulesæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯'Addmodules'æ–‡ä»¶å¤¹(**ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)**ï¼ç„¶åŽåœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›åŽ»å³å¯ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/159f576d4fc34df6b5bee4e3f46ee937.png)

* * *

#### 4.1.2 ä¿®æ”¹äºŒÂ 

ç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º'\_\_init\_\_.py'(**ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€æ–°å»º)**ï¼Œç„¶åŽåœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/48ff0dd547cd4e1aa7ee72bf9cd451b3.png)

* * *

#### 4.1.3 ä¿®æ”¹ä¸‰Â 

ç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/nn/tasks.py'è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—(**ç”¨ç¾¤å†…çš„æ–‡ä»¶çš„è¯å·²ç»æœ‰äº†æ— éœ€é‡æ–°å¯¼å…¥ç›´æŽ¥å¼€å§‹ç¬¬å››æ­¥å³å¯)**ï¼

**ä»Žä»Šå¤©å¼€å§‹ä»¥åŽçš„æ•™ç¨‹å°±éƒ½ç»Ÿä¸€æˆè¿™ä¸ªæ ·å­äº†ï¼Œå› ä¸ºæˆ‘é»˜è®¤å¤§å®¶ç”¨äº†æˆ‘ç¾¤å†…çš„æ–‡ä»¶æ¥è¿›è¡Œä¿®æ”¹ï¼ï¼**

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/67b28bda87e44d3285f0241acd165256.png)

* * *

#### 4.1.4 ä¿®æ”¹å››Â 

æŒ‰ç…§æˆ‘çš„æ·»åŠ åœ¨parse\_modelé‡Œæ·»åŠ å³å¯ã€‚

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5d25d42a991347f9aaaf2a755ab70464.png)

**åˆ°æ­¤å°±ä¿®æ”¹å®Œæˆäº†ï¼Œå¤§å®¶å¯ä»¥å¤åˆ¶ä¸‹é¢çš„yamlæ–‡ä»¶è¿è¡Œã€‚**

* * *

### 4.2 Diverse Branch Blockçš„yamlæ–‡ä»¶å’Œè®­ç»ƒæˆªå›¾

**ä¸‹é¢æŽ¨èå‡ ä¸ªç‰ˆæœ¬çš„yamlæ–‡ä»¶ç»™å¤§å®¶ï¼Œå¤§å®¶å¯ä»¥å¤åˆ¶è¿›è¡Œè®­ç»ƒï¼Œä½†æ˜¯ç»„åˆç”¨å¾ˆå¤šå…·ä½“é‚£ç§æœ€æœ‰æ•ˆæžœéƒ½ä¸ä¸€å®šï¼Œé’ˆå¯¹ä¸åŒçš„æ•°æ®é›†æ•ˆæžœä¹Ÿä¸ä¸€æ ·ï¼Œæˆ‘ä¸å¯æ¯ä¸€ç§éƒ½åšå®žéªŒï¼Œæ‰€ä»¥æˆ‘ä¸‹é¢æŽ¨èäº†ä¸‰ç§æˆ‘è‡ªå·±è®¤ä¸ºå¯èƒ½æœ‰æ•ˆæžœçš„é…åˆæ–¹å¼ï¼Œä½ ä¹Ÿå¯ä»¥è‡ªå·±è¿›è¡Œç»„åˆã€‚**

* * *

#### 4.2.1 Diverse Branch Blockçš„yamlç‰ˆæœ¬ä¸€(æŽ¨è)

**ä¸‹é¢çš„é…ç½®æ–‡ä»¶ä¸ºæˆ‘ä¿®æ”¹çš„C2f-DBB****çš„ä½ç½®(æˆ‘çš„å¯¹æ¯”å®žéªŒæ˜¯ç”¨è¿™ä¸ªç‰ˆæœ¬è·‘å‡ºæ¥çš„)ã€‚**

```python
# Ultralytics YOLO ðŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
 
# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs
 
# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
 
# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12
 
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f_DBB, [256]]  # 15 (P3/8-small)
 
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f_DBB, [512]]  # 18 (P4/16-medium)
 
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f_DBB, [1024]]  # 21 (P5/32-large)
 
  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```

* * *

#### 4.2.2 Diverse Branch Blockçš„yamlç‰ˆæœ¬äºŒ

**æ·»åŠ çš„ç‰ˆæœ¬äºŒå…·ä½“é‚£ç§é€‚åˆä½ éœ€è¦å¤§å®¶è‡ªå·±å¤šåšå®žéªŒæ¥å°è¯•ã€‚**

```python
# Ultralytics YOLO ðŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
 
# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs
 
# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
 
# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12
 
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f_DBB, [256]]  # 15 (P3/8-small)
 
  - [-1, 1, DiverseBranchBlock, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f_DBB, [512]]  # 18 (P4/16-medium)
 
  - [-1, 1, DiverseBranchBlock, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f_DBB, [1024]]  # 21 (P5/32-large)
 
  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```

* * *

#### 4.2.3Diverse Branch Blockçš„yamlç‰ˆæœ¬ä¸‰

```python
# Ultralytics YOLO ðŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
 
# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs
 
# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, DiverseBranchBlock, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, DiverseBranchBlock, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, DiverseBranchBlock, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, DiverseBranchBlock, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
 
# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12
 
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)
 
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)
 
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)
 
  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```

* * *

#### 4.2.2 Diverse Branch Blockçš„è®­ç»ƒè¿‡ç¨‹æˆªå›¾Â 

**ä¸‹é¢æ˜¯æ·»åŠ äº†**Diverse Branch Block**çš„è®­ç»ƒæˆªå›¾ã€‚**

![](https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f785340ec82740adb9bfc16b984ec934.png)â€‹â€‹â€‹â€‹â€‹â€‹

* * *

äº”ã€Diverse Branch Blockå¯æ·»åŠ çš„ä½ç½®
----------------------------

### 5.1 æŽ¨èDiverse Branch Blockå¯æ·»åŠ çš„ä½ç½®Â 

**Diverse Branch Blockæ˜¯ä¸€ç§å³æ’å³ç”¨çš„å¯æ›¿æ¢å·ç§¯çš„æ¨¡å—**ï¼Œå…¶å¯ä»¥æ·»åŠ çš„ä½ç½®æœ‰å¾ˆå¤šï¼Œæ·»åŠ çš„ä½ç½®ä¸åŒæ•ˆæžœä¹Ÿä¸åŒï¼Œæ‰€ä»¥æˆ‘ä¸‹é¢æŽ¨èå‡ ä¸ªæ·»åŠ çš„ä½ï¼Œç½®å¤§å®¶å¯ä»¥è¿›è¡Œå‚è€ƒï¼Œå½“ç„¶ä¸ä¸€å®šè¦æŒ‰ç…§æˆ‘æŽ¨èçš„åœ°æ–¹æ·»åŠ ã€‚

> 1.  **æ®‹å·®è¿žæŽ¥ä¸­**ï¼šåœ¨æ®‹å·®ç½‘ç»œçš„æ®‹å·®è¿žæŽ¥ä¸­åŠ å…¥**Diverse Branch Block(yamlæ–‡ä»¶ä¸€)ã€‚**
>     
> 2.  **Neckéƒ¨åˆ†**ï¼šYOLOv8çš„Neckéƒ¨åˆ†è´Ÿè´£ç‰¹å¾èžåˆï¼Œè¿™é‡Œæ·»åŠ ä¿®æ”¹åŽçš„C2f\_DBBå¯ä»¥å¸®åŠ©æ¨¡åž‹æ›´æœ‰æ•ˆåœ°èžåˆä¸åŒå±‚æ¬¡çš„ç‰¹å¾ï¼ˆ**yamlæ–‡ä»¶äºŒ**ï¼‰
>     
> 3.  **Backbone**ï¼šå¯ä»¥æ›¿æ¢ä¸­å¹²ç½‘ç»œä¸­çš„å·ç§¯éƒ¨åˆ†(**yamlæ–‡ä»¶ä¸‰**)ã€‚
>     

