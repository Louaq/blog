# 语义分割概述
<ArticleMetadata/>
## 1.什么是语义分割

> 所谓的分割，就是从像素层面上对图像进行描述，即某一个像素属于哪一类物体

![Snipaste_2025-02-24_14-03-50](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-02-24_14-03-50.png)

分类：**图片级**，比如区分一张图片是猫还是狗

检测：**区域级**，比如检测一个区域是猫还是狗

分割：**像素级**，比如区分一个像素是猫还是狗







![Snipaste_2025-02-24_14-09-11](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-02-24_14-09-11.png)



**语义分割**：也称为全像素语义分割，它是将每个像素分类为属于对象类的过程。

**实例分割**：是语义分割或全像素语义分割的子类型，它将每个像素分类为属于对象类以及该类的实体 ID。
简单的说，语义分割只需要对像素进行分类就行了，而实例分割不仅要对像素进行分类，同一类的不同物体也要进行分割。

**全景分割**： 是语义分割和实例分割的结合，即要对所有目标都检测出来，又要区分出同个类别中的不同实例。





## 2.模型的输入和输出

> 我们先要对模型有一个大的了解。模型的输入是什么？很显然，是一张张的图片；那么输出是什么呢？

我们假设模型的分类数量为 `n`，输入的图像大小为$W\times H$的 `RGB` 三通道的图像，那么实际上模型的输出为$W\times D \times n$，这要我们就可以把每一个像素的预测看成是一个分类任务，回顾一下之前的全连接网络的分类模型，对于 `n` 分类模型，输出节点数为 `n`。



所以，在语义分割而言，可以看成是$W\times H$个分类任务，每个像素的分类类别均为 `n`，所以得到的输出 `shape` 为$W\times D \times n$。事实上，输出也可能会比实际输入更大或者更小一些，因为网络的设计未必那么完美，这时候需要对边缘进行裁切或者补零





## 3.常见的分割模型

语义分割模型：FCN，RetinaNet，RefineNet，Deeplab 等等

实例分割模型：Mask RCNN，DeepMask等等





## 4.语义分割的思路



![Snipaste_2025-02-24_14-23-53](https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-02-24_14-23-53.png)



滑动窗口的思路可以概括如下：

1. 将图像分割成一个个小的区域；
2. 遍历一些小区域；
3. 对这些小区域做分类。

但是这个思想一个很重要的问题就是效率低，重叠区域的特征反复计算



## 5.评价指标

一般来说，分割的指标主要有两个：像素分类精度（`accuracy`）和区域的交并比（`IoU`），下面给出具体的计算公式。

说明：

- $n_{ij}$表示像素点属于分类$i$被预测为分类$j$的像素点数量，
- $t_i=\sum_{j}n_{ij}$表示标签中所有分类为$i$的像素点数量
- 总共有$n_{cl}$个不同的分类。



- 像素分类准确率 (`pixel accurarcy`)

$$
pacc=\frac{\sum_{i}n_{ii}}{\sum_{i}t_{i}}
$$

该指标表示所有像素中分类正确的比例





- 平均准确率 (`mean accuracy`)：
  $$
  macc=\frac1{n_{c1}}\sum_{i}\frac{n_{ii}}{t_{i}}
  $$
  计算每一类分类正确的像素点数和该类的所有像素点数的比例然后求平均

- 平均交并比 (`mean IoU`)：
  $$
  mIoU=\frac{1}{n_{cl}}\sum_{i}\frac{n_{ii}}{(t_{i}+\sum_{j}n_{ji}-n_{ii})}
  $$
  其中 IoU 的概念与目标检测中的 IoU 概念一致，表示两个区域的交并比，只不过相比较目标检测的矩形框，在分割任务中，区域为不规则的物体边界。





