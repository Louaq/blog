<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>WeakCLIP: Adapting CLIP for Weakly-Supervised Semantic Segmentation | lab blog</title>
    <meta name="description" content="A VitePress Site">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/blog/assets/style.aP5EKgV3.css" as="style">
    <link rel="preload stylesheet" href="/blog/vp-icons.css" as="style">
    
    <script type="module" src="/blog/assets/app.BwL1vjh2.js"></script>
    <link rel="preload" href="/blog/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/blog/assets/chunks/theme.C5e9yPYk.js">
    <link rel="modulepreload" href="/blog/assets/chunks/framework.Bw1ez5nK.js">
    <link rel="modulepreload" href="/blog/assets/column_Paper_WeakCLIP Adapting CLIP for Weakly-Supervised Semantic.md.DXzQMqhZ.lean.js">
    <link rel="icon" href="/blog/icon.png">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <script id="register-sw">"serviceWorker"in navigator&&navigator.serviceWorker.register("/sw.js");</script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
    <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
    <script>typeof LA<"u"&&LA.init({id:"3LPXyA1ZitpV3O1s",ck:"3LPXyA1ZitpV3O1s",autoTrack:!0,hashMode:!0});</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-9bcec609><!--[--><!--]--><!--[--><span tabindex="-1" data-v-b775d67b></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-b775d67b>Skip to content</a><!--]--><!----><header class="VPNav" data-v-9bcec609 data-v-389f03b4><div class="VPNavBar" data-v-389f03b4 data-v-f2c85656><div class="wrapper" data-v-f2c85656><div class="container" data-v-f2c85656><div class="title" data-v-f2c85656><div class="VPNavBarTitle has-sidebar" data-v-f2c85656 data-v-02609f48><a class="title" href="/blog/" data-v-02609f48><!--[--><!--]--><!--[--><img class="VPImage logo" src="/blog/b.jpg" alt data-v-52246203><!--]--><span data-v-02609f48>lab blog</span><!--[--><!--]--></a></div></div><div class="content" data-v-f2c85656><div class="content-body" data-v-f2c85656><!--[--><!--]--><div class="VPNavBarSearch search" data-v-f2c85656><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-f2c85656 data-v-33ef0f58><span id="main-nav-aria-label" class="visually-hidden" data-v-33ef0f58> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/" tabindex="0" data-v-33ef0f58 data-v-297ea667><!--[--><span data-v-297ea667>é¦–é¡µ</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/column/Paper/" tabindex="0" data-v-33ef0f58 data-v-297ea667><!--[--><span data-v-297ea667>è®ºæ–‡é˜…è¯»ç¬”è®°</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/column/Puruse/" tabindex="0" data-v-33ef0f58 data-v-297ea667><!--[--><span data-v-297ea667>è®ºæ–‡ç²¾è¯»ç¬”è®°</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/column/image_segmentation.html" tabindex="0" data-v-33ef0f58 data-v-297ea667><!--[--><span data-v-297ea667>å›¾åƒåˆ†å‰²</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-f2c85656 data-v-b431cf34><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b431cf34 data-v-614ada65 data-v-46c8899f><span class="check" data-v-46c8899f><span class="icon" data-v-46c8899f><!--[--><span class="vpi-sun sun" data-v-614ada65></span><span class="vpi-moon moon" data-v-614ada65></span><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-f2c85656 data-v-661149a6 data-v-965a88c0><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-965a88c0><span class="vpi-more-horizontal icon" data-v-965a88c0></span></button><div class="menu" data-v-965a88c0><div class="VPMenu" data-v-965a88c0 data-v-979bc427><!----><!--[--><!--[--><!----><div class="group" data-v-661149a6><div class="item appearance" data-v-661149a6><p class="label" data-v-661149a6>æ·±æµ…æ¨¡å¼</p><div class="appearance-action" data-v-661149a6><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-661149a6 data-v-614ada65 data-v-46c8899f><span class="check" data-v-46c8899f><span class="icon" data-v-46c8899f><!--[--><span class="vpi-sun sun" data-v-614ada65></span><span class="vpi-moon moon" data-v-614ada65></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-f2c85656 data-v-057c9ada><span class="container" data-v-057c9ada><span class="top" data-v-057c9ada></span><span class="middle" data-v-057c9ada></span><span class="bottom" data-v-057c9ada></span></span></button></div></div></div></div><div class="divider" data-v-f2c85656><div class="divider-line" data-v-f2c85656></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-9bcec609 data-v-bb57d500><div class="container" data-v-bb57d500><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-bb57d500><span class="vpi-align-left menu-icon" data-v-bb57d500></span><span class="menu-text" data-v-bb57d500>ç›®å½•</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-bb57d500 data-v-600f5a1a><button data-v-600f5a1a>è¿”å›é¡¶éƒ¨</button><!----></div></div></div><aside class="VPSidebar" data-v-9bcec609 data-v-ff6a08f7><div class="curtain" data-v-ff6a08f7></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-ff6a08f7><span class="visually-hidden" id="sidebar-aria-label" data-v-ff6a08f7> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-941144ff><section class="VPSidebarItem level-0 collapsible collapsed" data-v-941144ff data-v-b9329948><div class="item" role="button" tabindex="0" data-v-b9329948><div class="indicator" data-v-b9329948></div><h2 class="text" data-v-b9329948>è®ºæ–‡é˜…è¯»</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b9329948><span class="vpi-chevron-right caret-icon" data-v-b9329948></span></div></div><div class="items" data-v-b9329948><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Visual%20Studio%20Code%20latex.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>latexç¯å¢ƒé…ç½®</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Segment%20Anything.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>Segment Anything</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/DGSS.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/SED.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºåˆ†å±‚ç¼–ç å™¨çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/High_Quality_Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>è¶…é«˜åˆ†è¾¨ç‡åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Night-time_Semantic_Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>å¤œé—´åœºæ™¯è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/PAT.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>æç¤ºè¯è¿ç§»çš„å°‘æ ·æœ¬åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>å¤šæ¨¡æ€å›¾åƒåˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/A%20Transformer-basedAdaptivePrototypeMatchingNetwork.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºTransformerçš„è‡ªé€‚åº”åŸå‹åŒ¹é…ç½‘ç»œ</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Cross-Domain%20Few-Shot%20Semantic%20Segmentation%20via%20Doubly%20Matching%20Transformation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>è·¨é¢†åŸŸå°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Relevant%20Intrinsic%20Feature%20Enhancement%20Network%20for%20Few-Shot%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>ç›¸å…³å†…åœ¨ç‰¹å¾å¢å¼ºçš„å°‘æ ·æœ¬ä¸æ„ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Scribble-Supervised%20Semantic%20Segmentation%20with%20Prototype-based%20Feature%20Augmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºæ¶‚é¸¦çš„æ— ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Progressive%20Feature%20Self-Reinforcement%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„æ¸è¿›å¼ç‰¹å¾è‡ªå¢å¼º</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Self-supervised_ViT.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºè‡ªç›‘ç£Vitçš„è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/LearningGeneralizedMedicalImageSegmentationfromDecoupledFeatureQueries.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŒ»å­¦å›¾åƒåˆ†å‰²ï¼šåŸºäºè§£è€¦ç‰¹å¾æŸ¥è¯¢</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Scaling_UpMulti-domain_Semantic_Segmentation_with_Sentence.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºè¯­å¥åµŒå…¥çš„å¤šé¢†åŸŸè¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Scribbl_Hides_Class_Promoting_Scribble-Based_Weakly-Supervised_Semantic_Segmentation_with%20Its%20Class%20Label.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºæ¶‚é¸¦çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-941144ff><section class="VPSidebarItem level-0 collapsible has-active" data-v-941144ff data-v-b9329948><div class="item" role="button" tabindex="0" data-v-b9329948><div class="indicator" data-v-b9329948></div><h2 class="text" data-v-b9329948>è¯­ä¹‰åˆ†å‰²è®ºæ–‡é˜…è¯»</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b9329948><span class="vpi-chevron-right caret-icon" data-v-b9329948></span></div></div><div class="items" data-v-b9329948><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/CC4S%20Encouraging%20Certainty%20and%20Consistency%20in%20Scribble-Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>æ¶‚é¸¦ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç¡®å®šæ€§å’Œä¸€è‡´æ€§(CC4S)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/CorrMatch%20Label%20Propagation%20via%20Correlation%20Matching%20for%20Semi-Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºå…³è”åŒ¹é…çš„æ ‡ç­¾ä¼ æ’­åŠç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/LLMFormer%20Large%20LanguageModel%20for%20Open-Vocabulary%20Semantic.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºLLMçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Towards%20Open-Vocabulary%20Semantic%20Segmentation%20Without%20Semantic%20Labels.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>æ— éœ€è¯­ä¹‰æ ‡ç­¾çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²(æ–‡ç« æ™¦æ¶©ï¼Œä¸å»ºè®®é˜…è¯»)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/USE%20Universal%20Segment%20Embeddings%20for%20Open-Vocabulary%20Image%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>é¢å‘å¼€æ”¾è¯æ±‡å›¾åƒåˆ†å‰²çš„é€šç”¨ç‰‡æ®µåµŒå…¥</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Class%20Tokens%20Infusion%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç±»åˆ«æ ‡è®°æ³¨å…¥</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/LGAD%20Local%20and%20Global%20Attention%20Distillation%20for%20Efficient%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºå…¨å±€å’Œå±€éƒ¨æ³¨æ„åŠ›è’¸é¦çš„é«˜æ•ˆè¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/DSMF-Net%20Dual%20Semantic%20Metric%20Learning%20Fusion%20Network%20for%20Few-Shot%20Aerial%20Image%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºåŒé‡è¯­ä¹‰åº¦é‡å­¦ä¹ çš„å°‘æ ·æœ¬èˆªæ‹å›¾åƒè¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Kill%20Two%20Birds%20with%20One%20Stone%20Domain%20Generalization%20for%20Semantic%20Segmentation%20via%20Network%20Pruning.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºå‰ªæçš„é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/All-pairs%20Consistency%20Learning%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºå…¨å¯¹ä¸€è‡´æ€§å­¦ä¹ çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/WeakCLIP%20Adapting%20CLIP%20for%20Weakly-Supervised%20Semantic.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>weakCLIP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/SFC%20Shared%20Feature%20Calibration%20in%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ä¸­çš„å…±äº«æƒé‡æ ¡å‡†</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Knowledge%20Transfer%20with%20Simulated%20Inter-Image%20Erasing%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºæ¨¡æ‹Ÿå›¾åƒé—´æ“¦é™¤çŸ¥è¯†è¿ç§»çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Pixel-Wise%20Reclassification%20with%20Prototypes%20for%20Enhancing%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŸºäºåŸå‹çš„åƒç´ çº§å†åˆ†ç±»æé«˜å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/C-CAM%20Causal%20CAM%20for%20Weakly%20Supervised%20Semantic%20Segmentation%20on%20Medical%20Image.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>C-CAM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b9329948 data-v-b9329948><div class="item" data-v-b9329948><div class="indicator" data-v-b9329948></div><a class="VPLink link link" href="/blog/column/Paper/Rolling-Unet%20Revitalizing%20MLP%20Ability%20to%20Efficiently%20Extract%20Long-Distance%20Dependencies%20for%20Medical%20Image%20Segmentation.html" data-v-b9329948><!--[--><p class="text" data-v-b9329948>åŒ»å­¦å›¾åƒåˆ†å‰²ï¼šRolling-Net</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-9bcec609 data-v-b233c28d><div class="VPDoc has-sidebar has-aside" data-v-b233c28d data-v-4e3ca6fa><!--[--><!--]--><div class="container" data-v-4e3ca6fa><div class="aside" data-v-4e3ca6fa><div class="aside-curtain" data-v-4e3ca6fa></div><div class="aside-container" data-v-4e3ca6fa><div class="aside-content" data-v-4e3ca6fa><div class="VPDocAside" data-v-4e3ca6fa data-v-99a4d02b><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-99a4d02b data-v-6eb44d9d><div class="content" data-v-6eb44d9d><div class="outline-marker" data-v-6eb44d9d></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-6eb44d9d>å½“å‰å¤§çº²</div><ul class="VPDocOutlineItem root" data-v-6eb44d9d data-v-da2b5471><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-99a4d02b></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-4e3ca6fa><div class="content-container" data-v-4e3ca6fa><!--[--><!--]--><main class="main" data-v-4e3ca6fa><div style="position:relative;" class="vp-doc _blog_column_Paper_WeakCLIP%20Adapting%20CLIP%20for%20Weakly-Supervised%20Semantic" data-v-4e3ca6fa><div><h1 id="weakclip-adapting-clip-for-weakly-supervised-semantic-segmentation" tabindex="-1">WeakCLIP: Adapting CLIP for Weakly-Supervised Semantic Segmentation <a class="header-anchor" href="#weakclip-adapting-clip-for-weakly-supervised-semantic-segmentation" aria-label="Permalink to &quot;WeakCLIP: Adapting CLIP for Weakly-Supervised Semantic Segmentation&quot;">â€‹</a></h1><p>åä¸­ç§‘æŠ€å¤§å­¦ã€è¥¿åŒ—å·¥ä¸šå¤§å­¦</p><div class="word"><p><svg t="1724572866572" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="18131" width="16" height="16"><path d="M168.021333 504.192A343.253333 343.253333 0 0 1 268.629333 268.8a342.229333 342.229333 0 0 1 243.285334-100.778667A341.504 341.504 0 0 1 755.029333 268.8c9.856 9.898667 19.2 20.394667 27.733334 31.402667l-60.16 46.976a8.021333 8.021333 0 0 0 2.986666 14.122666l175.701334 43.008a8.021333 8.021333 0 0 0 9.898666-7.68l0.810667-180.906666a7.936 7.936 0 0 0-12.885333-6.314667L842.666667 253.44a418.858667 418.858667 0 0 0-330.922667-161.493333c-229.12 0-415.488 183.594667-419.797333 411.818666a8.021333 8.021333 0 0 0 8.021333 8.192H160a7.978667 7.978667 0 0 0 8.021333-7.808zM923.946667 512H864a7.978667 7.978667 0 0 0-8.021333 7.808 341.632 341.632 0 0 1-26.88 125.994667 342.186667 342.186667 0 0 1-73.685334 109.397333 342.442667 342.442667 0 0 1-243.328 100.821333 342.229333 342.229333 0 0 1-270.976-132.224l60.16-46.976a8.021333 8.021333 0 0 0-2.986666-14.122666l-175.701334-43.008a8.021333 8.021333 0 0 0-9.898666 7.68l-0.682667 181.034666c0 6.698667 7.68 10.496 12.885333 6.314667L181.333333 770.56a419.072 419.072 0 0 0 330.922667 161.408c229.205333 0 415.488-183.722667 419.797333-411.818667a8.021333 8.021333 0 0 0-8.021333-8.192z" fill="#8a8a8a" p-id="18132"></path></svg> æ›´æ–°: 4/30/2025 <svg t="1724571760788" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6125" width="16" height="16"><path d="M204.8 0h477.866667l273.066666 273.066667v614.4c0 75.093333-61.44 136.533333-136.533333 136.533333H204.8c-75.093333 0-136.533333-61.44-136.533333-136.533333V136.533333C68.266667 61.44 129.706667 0 204.8 0z m307.2 607.573333l68.266667 191.146667c13.653333 27.306667 54.613333 27.306667 61.44 0l102.4-273.066667c6.826667-20.48 0-34.133333-20.48-40.96s-34.133333 0-40.96 13.653334l-68.266667 191.146666-68.266667-191.146666c-13.653333-27.306667-54.613333-27.306667-68.266666 0l-68.266667 191.146666-68.266667-191.146666c-6.826667-13.653333-27.306667-27.306667-47.786666-20.48s-27.306667 27.306667-20.48 47.786666l102.4 273.066667c13.653333 27.306667 54.613333 27.306667 61.44 0l75.093333-191.146667z" fill="#777777" p-id="6126"></path><path d="M682.666667 0l273.066666 273.066667h-204.8c-40.96 0-68.266667-27.306667-68.266666-68.266667V0z" fill="#E0E0E0" opacity=".619" p-id="6127"></path></svg> å­—æ•°: 0 å­— <svg t="1724572797268" class="icon" viewBox="0 0 1060 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15031" width="16" height="16"><path d="M556.726857 0.256A493.933714 493.933714 0 0 0 121.929143 258.998857L0 135.021714v350.390857h344.649143L196.205714 334.482286a406.820571 406.820571 0 1 1-15.908571 312.649143H68.937143A505.819429 505.819429 0 1 0 556.726857 0.256z m-79.542857 269.531429v274.907428l249.197714 150.966857 42.422857-70.070857-212.114285-129.389714V269.787429h-79.542857z" fill="#8a8a8a" p-id="15032"></path></svg> æ—¶é•¿: 0 åˆ†é’Ÿ </p></div><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>CLIPã€å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p></div><h2 id="æ‘˜è¦" tabindex="-1">æ‘˜è¦ <a class="header-anchor" href="#æ‘˜è¦" aria-label="Permalink to &quot;æ‘˜è¦&quot;">â€‹</a></h2><p>Contrastive language and image pre-training (CLIP) achieves great success in various computer vision tasks and also presents an opportune avenue for enhancing weakly-supervised image understanding with its large-scale pre-trained knowledge. As an effective way to reduce the reliance on pixel-level human-annotated labels, weakly-supervised semantic segmentation (WSSS) aims to refine the class activation map (CAM) and produce high-quality pseudo masks. Weakly-supervised semantic segmentation (WSSS)aims to refine the class activationmap(CAM)as pseudo masks, but heavily relies on inductive biases like hand-crafted priors and digital image processing methods. For the vision-language pre-trained model, i.e. CLIP, we propose a novel text-to-pixel matching paradigm forWSSS.However, directly applying CLIP toWSSS is challenging due to three critical problems: (1) the task gap between contrastive pre-training and WSSS CAM refinement, (2) lacking text-to-pixel modeling to fully utilize the pre-trained knowledge, and (3) the insufficient details owning to the 1/16 down-sampling resolution ofViT. Thus, we proposeWeakCLIP to address the problems and leverage the pre-trained knowledge from CLIP toWSSS. Specifically, we first address the task gap by proposing a pyramid adapter and learnable prompts to extract WSSS-specific representation. We then design a co-attention matching module to model text-to-pixel relationships. Finally, the pyramid adapter and text-guided decoder are introduced to gather multi-level information and integrate it with text guidance hierarchically.WeakCLIP provides an effective and parameter-efficient way to transfer CLIP knowledge to refine CAM. Extensive experiments demonstrate that WeakCLIP achieves the state-of-the-art WSSS performance on standard benchmarks, i.e., 74.0% mIoU on the val set of PASCAL VOC 2012 and 46.1% mIoU on the val set of COCO 2014. The source code and model checkpoints are released at <a href="https://github.com/hustvl/WeakCLIP" target="_blank" rel="noreferrer">https://github.com/hustvl/WeakCLIP</a>.</p><h2 id="ç¿»è¯‘" tabindex="-1">ç¿»è¯‘ <a class="header-anchor" href="#ç¿»è¯‘" aria-label="Permalink to &quot;ç¿»è¯‘&quot;">â€‹</a></h2><p>å¯¹æ¯”è¯­è¨€å’Œå›¾åƒé¢„è®­ç»ƒ(CLIP)åœ¨å„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­å–å¾—äº†å·¨å¤§çš„æˆåŠŸï¼Œå¹¶ä¸”åˆ©ç”¨å…¶å¤§è§„æ¨¡çš„é¢„è®­ç»ƒçŸ¥è¯†ä¸ºå¢å¼ºå¼±ç›‘ç£å›¾åƒç†è§£æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„é€”å¾„ã€‚å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²(WSSS)æ˜¯ä¸€ç§å‡å°‘å¯¹åƒç´ çº§äººå·¥æ ‡æ³¨æ ‡ç­¾ä¾èµ–çš„æœ‰æ•ˆæ–¹æ³•ï¼Œå…¶ç›®çš„æ˜¯ç»†åŒ–ç±»æ¿€æ´»å›¾(CAM)å¹¶ç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ©è†œã€‚å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²(WSSS)æ—¨åœ¨å°†ç±»æ¿€æ´»å›¾(CAM)ç»†åŒ–ä¸ºä¼ªæ©è†œï¼Œä½†ä¸¥é‡ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œå…ˆéªŒå’Œæ•°å­—å›¾åƒå¤„ç†æ–¹æ³•ç­‰å½’çº³åå·®ã€‚å¯¹äºè§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹ï¼Œå³CLIPï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°åƒç´ çš„wsssåŒ¹é…èŒƒå¼ã€‚ç„¶è€Œï¼Œç›´æ¥åº”ç”¨CLIP toWSSSæ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå› ä¸ºå­˜åœ¨ä¸‰ä¸ªå…³é”®é—®é¢˜:(1)å¯¹æ¯”é¢„è®­ç»ƒä¸WSSSCAMç»†åŒ–ä¹‹é—´çš„ä»»åŠ¡å·®è·;(2)ç¼ºä¹æ–‡æœ¬åˆ°åƒç´ çš„å»ºæ¨¡ä»¥å……åˆ†åˆ©ç”¨é¢„è®­ç»ƒçš„çŸ¥è¯†;(3)ç”±äºvitçš„ä¸‹é‡‡æ ·åˆ†è¾¨ç‡ä¸º1 16ï¼Œç»†èŠ‚ä¸è¶³ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†weakclipæ¥è§£å†³é—®é¢˜ï¼Œå¹¶åˆ©ç”¨CLIP toWSSSçš„é¢„è®­ç»ƒçŸ¥è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡æå‡ºé‡‘å­—å¡”é€‚é…å™¨å’Œå¯å­¦ä¹ çš„æç¤ºè¯ç¬¦æ¥æå–ç‰¹å®šäºwssçš„è¡¨ç¤ºæ¥è§£å†³ä»»åŠ¡å·®è·ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå…±åŒå…³æ³¨åŒ¹é…æ¨¡å—æ¥æ¨¡æ‹Ÿæ–‡æœ¬åˆ°åƒç´ çš„å…³ç³»ã€‚æœ€åï¼Œå¼•å…¥é‡‘å­—å¡”é€‚é…å™¨å’Œæ–‡æœ¬å¼•å¯¼è§£ç å™¨ï¼Œå®ç°å¤šçº§ä¿¡æ¯é‡‡é›†ï¼Œå¹¶ä¸æ–‡æœ¬å¼•å¯¼åˆ†å±‚é›†æˆã€‚WeakCLIPæä¾›äº†ä¸€ç§æœ‰æ•ˆçš„ã€å‚æ•°é«˜æ•ˆçš„æ–¹æ³•æ¥ä¼ é€’CLIPçŸ¥è¯†ä»¥æ”¹è¿›CAMã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒWeakCLIPåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„WSSSæ€§èƒ½ï¼Œå³åœ¨PASCAL VOC 2012çš„valé›†ä¸Šè¾¾åˆ°äº†74.0%çš„mIoUï¼Œåœ¨COCO 2014çš„valé›†ä¸Šè¾¾åˆ°äº†46.1%çš„mIoUã€‚æºä»£ç å’Œæ¨¡å‹æ£€æŸ¥ç‚¹åœ¨<a href="https://github.com/hustvl/WeakCLIP%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82" target="_blank" rel="noreferrer">https://github.com/hustvl/WeakCLIPä¸Šå‘å¸ƒã€‚</a></p><h2 id="ç ”ç©¶èƒŒæ™¯" tabindex="-1">ç ”ç©¶èƒŒæ™¯ <a class="header-anchor" href="#ç ”ç©¶èƒŒæ™¯" aria-label="Permalink to &quot;ç ”ç©¶èƒŒæ™¯&quot;">â€‹</a></h2><p>æœ¬æ–‡èšç„¦äºå¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰ä»»åŠ¡ï¼Œæ—¨åœ¨è§£å†³å½“å‰æ–¹æ³•åœ¨å¤„ç†ç±»æ¿€æ´»å›¾ï¼ˆCAMï¼‰ç§å­æ—¶é¢ä¸´çš„é—®é¢˜ï¼Œå…·ä½“ç ”ç©¶èƒŒæ™¯å¦‚ä¸‹ï¼š</p><ul><li><strong>WSSSçš„é‡è¦æ€§ä¸æŒ‘æˆ˜</strong>ï¼šè¯­ä¹‰åˆ†å‰²ä¸­åƒç´ çº§æ ‡æ³¨è€—æ—¶è´¹åŠ›ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚WSSSåˆ©ç”¨å¼±ç›‘ç£ä¿¡æ¯ç”Ÿæˆä¼ªåƒç´ çº§åˆ†å‰²ï¼Œå¯å‡è½»æ ‡æ³¨è´Ÿæ‹…ï¼Œä½†ä»…ä½¿ç”¨å›¾åƒçº§æ ‡ç­¾çš„WSSSæ˜¯è¯¥é¢†åŸŸæœ€å…·æŒ‘æˆ˜æ€§çš„æ–¹å‘ã€‚</li><li><strong>ç°æœ‰CAMç»†åŒ–æ–¹æ³•çš„å±€é™æ€§</strong>ï¼šç°æœ‰æ–¹æ³•å¤šä¾èµ–æ‰‹å·¥å…ˆéªŒå’Œæ”¹è¿›çš„æ•°å­—å›¾åƒå¤„ç†ç®—æ³•æ¥ç»†åŒ–CAMï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨å½’çº³åå·®ï¼Œé™åˆ¶äº†æ€§èƒ½å’Œé²æ£’æ€§ã€‚</li><li><strong>CLIPçš„æ½œåŠ›ä¸åº”ç”¨æŒ‘æˆ˜</strong>ï¼šCLIPåœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä¸ºWSSSå¸¦æ¥äº†æ–°çš„æœºé‡ã€‚ç„¶è€Œï¼Œç›´æ¥å°†CLIPåº”ç”¨äºWSSSå­˜åœ¨ä»»åŠ¡å·®è·ã€ç¼ºä¹æ–‡æœ¬åˆ°åƒç´ å»ºæ¨¡ä»¥åŠç»†èŠ‚ä¸è¶³ç­‰é—®é¢˜ã€‚ åŸºäºä»¥ä¸ŠèƒŒæ™¯ï¼Œä½œè€…æå‡ºäº†WeakCLIPæ–¹æ³•ï¼Œæ—¨åœ¨åˆ©ç”¨CLIPçš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œé€šè¿‡æ–‡æœ¬åˆ°åƒç´ åŒ¹é…èŒƒå¼è§£å†³WSSSä¸­çš„å…³é”®é—®é¢˜ï¼Œæé«˜ä¼ªæ©ç çš„è´¨é‡ï¼Œä»è€Œæ¨åŠ¨WSSSçš„å‘å±•ã€‚</li></ul><h2 id="ç ”ç©¶ç°çŠ¶" tabindex="-1">ç ”ç©¶ç°çŠ¶ <a class="header-anchor" href="#ç ”ç©¶ç°çŠ¶" aria-label="Permalink to &quot;ç ”ç©¶ç°çŠ¶&quot;">â€‹</a></h2><ul><li><strong>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰</strong>ï¼šä¸ºå‡è½»åƒç´ çº§æ ‡æ³¨è´Ÿæ‹…ï¼Œå‡ºç°å¤šç§åŸºäºä¸åŒå¼±ç›‘ç£ä¿¡æ¯ï¼ˆå¦‚<strong>è¾¹ç•Œæ¡†ã€æ¶‚é¸¦ã€ç‚¹ã€å›¾åƒçº§æ ‡ç­¾</strong>ï¼‰çš„ç®—æ³•ã€‚å…¶ä¸­ï¼ŒåŸºäº<strong>å›¾åƒçº§æ ‡ç­¾</strong>çš„WSSSæœ€å…·æŒ‘æˆ˜æ€§ï¼Œå¸¸ä½¿ç”¨ç±»æ¿€æ´»å›¾ï¼ˆCAMï¼‰å®šä½ç›®æ ‡ï¼Œä½†åŸå§‹CAMå™ªå£°å¤§ã€æ˜“å‡ºé”™ï¼Œå·²æœ‰å¤šç§æ–¹æ³•å¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚</li><li><strong>å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹</strong>ï¼šå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹åœ¨å„é¢†åŸŸå¹¿æ³›åº”ç”¨ï¼Œå¦‚CLIPé€šè¿‡å¯¹æ¯”å­¦ä¹ åœ¨å¤§é‡å›¾åƒ-æ–‡æœ¬å¯¹ä¸Šé¢„è®­ç»ƒï¼Œå±•ç°å‡ºå¼ºå¤§çš„çŸ¥è¯†è¿ç§»èƒ½åŠ›ã€‚å·²æœ‰ç ”ç©¶å°è¯•å°†CLIPåº”ç”¨äºWSSSï¼Œå¦‚CLIMSå¼•å…¥è¾…åŠ©æŸå¤±ï¼ŒCLIP - ESåˆ©ç”¨æ–‡æœ¬æç¤ºå’ŒGradCAMæå‡CAMè´¨é‡ã€‚</li></ul><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-09_08-44-06.png" alt="Snipaste_2025-04-09_08-44-06" loading="lazy"></p><h2 id="æå‡ºçš„æ¨¡å‹" tabindex="-1">æå‡ºçš„æ¨¡å‹ <a class="header-anchor" href="#æå‡ºçš„æ¨¡å‹" aria-label="Permalink to &quot;æå‡ºçš„æ¨¡å‹&quot;">â€‹</a></h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º<strong>WeakCLIPçš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰æ–¹æ³•</strong>ï¼Œæ—¨åœ¨åˆ©ç”¨é¢„è®­ç»ƒçš„CLIPæ¨¡å‹çŸ¥è¯†æ¥æ”¹è¿›WSSSç½‘ç»œçš„ç±»æ¿€æ´»å›¾ï¼ˆCAMï¼‰ç»†åŒ–è¿‡ç¨‹ã€‚ä»¥ä¸‹æ˜¯WeakCLIPæ¨¡å‹çš„è¯¦ç»†ä»‹ç»ï¼š</p><ol><li><p><strong>æ–‡æœ¬åˆ°åƒç´ åŒ¹é…èŒƒå¼</strong>ï¼šä¸ä»¥å¾€åŸºäºCLIPçš„WSSSæ–¹æ³•ä¸åŒï¼ŒWeakCLIPæå‡ºäº†<strong>æ–‡æœ¬åˆ°åƒç´ åŒ¹é…</strong>èŒƒå¼ï¼Œä»¥åœ¨åƒç´ çº§åˆ«æŸ¥è¯¢ç›¸ä¼¼åº¦ã€‚å…·ä½“è€Œè¨€ï¼Œè¾“å…¥å›¾åƒé€šè¿‡CLIPé¢„è®­ç»ƒçš„ViT - Bç½‘ç»œæå–å¤šå±‚ç‰¹å¾å›¾ï¼Œç»è¿‡æŠ•å½±å±‚åï¼Œå®šä¹‰æ–‡æœ¬åˆ°åƒç´ åŒ¹é…æ“ä½œï¼Œå¾—åˆ°æ–‡æœ¬åˆ°åƒç´ åŒ¹é…çš„åµŒå…¥ã€‚</p></li><li><p><strong>WeakCLIPæ¡†æ¶</strong></p><ul><li><strong>å¯å­¦ä¹ æç¤ºï¼ˆLearnable Promptï¼‰</strong>ï¼šå—CoOpå’ŒCLIP - Adapterå¯å‘ï¼Œæå‡ºå¯å­¦ä¹ åµŒå…¥ä½œä¸ºè‡ªé€‚åº”æç¤ºã€‚å°†ç±»æ–‡æœ¬æ ‡è®°å¹¶åµŒå…¥ä¸ºç±»æ–‡æœ¬åµŒå…¥ï¼Œä¸éšæœºåˆå§‹åŒ–çš„å¯å­¦ä¹ åµŒå…¥æ‹¼æ¥ï¼Œä½œä¸ºæ–‡æœ¬ç¼–ç å™¨çš„è¾“å…¥ï¼Œæœ€ç»ˆæŠ•å½±å¾—åˆ°æ–‡æœ¬åµŒå…¥ã€‚</li><li><strong>é‡‘å­—å¡”é€‚é…å™¨ï¼ˆPyramid Adapterï¼‰</strong>ï¼šä¸ºè§£å†³CLIPè§†è§‰ç¼–ç å™¨ä¸“æ³¨äºæ•´ä½“å›¾åƒå†…å®¹ä»¥åŠä½åˆ†è¾¨ç‡é—®é¢˜ï¼Œæå‡ºé‡‘å­—å¡”é€‚é…å™¨ã€‚å®ƒç‹¬ç«‹äºCLIPå›¾åƒç¼–ç å™¨ï¼Œå¯¹ä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾å›¾è¿›è¡Œå¤„ç†ï¼Œé€šè¿‡ä¸Šé‡‡æ ·å’Œä¸‹é‡‡æ ·æ“ä½œï¼Œç”Ÿæˆä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾ï¼Œæœ‰æ•ˆèåˆä½çº§ç»†èŠ‚å’Œé«˜çº§è¡¨ç¤ºã€‚</li><li><strong>ååŒæ³¨æ„åŠ›åŒ¹é…æ¨¡å—ï¼ˆCo - attention Matchingï¼‰</strong>ï¼šä¸ºå……åˆ†åˆ©ç”¨CLIPé¢„è®­ç»ƒçŸ¥è¯†ï¼Œæå‡ºååŒæ³¨æ„åŠ›åŒ¹é…æ¨¡å—ï¼Œç”¨äºå»ºæ¨¡åŒå‘æ–‡æœ¬åˆ°åƒç´ åŒ¹é…ã€‚è¯¥æ¨¡å—ä½¿ç”¨ä¸¤ä¸ªäº¤å‰æ³¨æ„åŠ›æ¨¡å—åˆ†åˆ«å»ºæ¨¡æ–‡æœ¬åˆ°åƒç´ å’Œåƒç´ åˆ°æ–‡æœ¬çš„å…³ç³»ï¼Œå¹¶é€šè¿‡æ®‹å·®è¿æ¥æ›´æ–°æ–‡æœ¬å’Œå›¾åƒåµŒå…¥ï¼Œæœ€åè¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒåŒ¹é…å¾—åˆ°ååŒæ³¨æ„åŠ›åŒ¹é…çš„åµŒå…¥ã€‚</li><li><strong>æ–‡æœ¬å¼•å¯¼è§£ç å™¨ï¼ˆText - Guided Decoderï¼‰</strong>ï¼šä¸ºè§£å†³CLIP ViT - Bçš„åˆ†è¾¨ç‡é™åˆ¶é—®é¢˜ï¼Œå¼•å…¥æ–‡æœ¬å¼•å¯¼è§£ç å™¨ã€‚å°†ååŒæ³¨æ„åŠ›åŒ¹é…çš„åµŒå…¥æ’å€¼åˆ°ä¸é€‚é…å™¨è¾“å‡ºç‰¹å¾å¯¹åº”çš„å¤§å°ï¼Œä¸é€‚é…å™¨è¾“å‡ºç‰¹å¾æ‹¼æ¥åè¿›è¡Œè§£ç ï¼Œå¾—åˆ°åˆ†å‰²é¢„æµ‹ã€‚</li><li><strong>WSSSæŸå¤±ï¼ˆWSSS Lossesï¼‰</strong>ï¼šé‡‡ç”¨DSRGä¸­ä½¿ç”¨çš„WSSSæŸå¤±ï¼ŒåŒ…æ‹¬å¹³è¡¡ç§å­æŸå¤±å’Œè¾¹ç•ŒæŸå¤±ã€‚å¹³è¡¡ç§å­æŸå¤±è®¡ç®—åˆ†å‰²é¢„æµ‹ä¸CAMç§å­ä¹‹é—´çš„åŠ æƒäº¤å‰ç†µæŸå¤±ï¼›è¾¹ç•ŒæŸå¤±å…ˆä½¿ç”¨æ¡ä»¶éšæœºåœºï¼ˆCRFï¼‰å¤„ç†åˆ†å‰²é¢„æµ‹ä»¥ç»†åŒ–å¯¹è±¡è¾¹ç•Œï¼Œç„¶åè®¡ç®—CRFç»†åŒ–ç»“æœä¸åˆ†å‰²é¢„æµ‹ä¹‹é—´çš„Kullback - Leibleræ•£åº¦æŸå¤±ã€‚</li></ul></li><li><p><strong>ä¼ªæ©ç ç”Ÿæˆå’Œå†è®­ç»ƒ</strong>ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„WeakCLIPç½‘ç»œç”Ÿæˆé«˜è´¨é‡çš„ä¼ªæ©ç ã€‚å½“æ¨ç†ç»“æœä¸­çš„ç±»åˆ«ä¸åœ¨å›¾åƒçº§æ ‡ç­¾ä¸­æ—¶ï¼Œå°†å…¶æ ‡è®°ä¸ºæœªçŸ¥æ ‡ç­¾ã€‚æœ€åï¼Œä½¿ç”¨ç”Ÿæˆçš„ä¼ªæ©ç è¿›è¡Œå…¨ç›‘ç£åˆ†å‰²ï¼Œé‡‡ç”¨DeepLabv1ç½‘ç»œæ¶æ„ï¼Œå¹¶å°è¯•ä½¿ç”¨æ›´å…ˆè¿›çš„åŸºäºViTçš„åˆ†å‰²æ–¹æ³•è¿›è¡Œå†è®­ç»ƒã€‚ å®éªŒç»“æœè¡¨æ˜ï¼ŒWeakCLIPåœ¨PASCAL VOC 2012å’ŒCOCO 2014æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜äºä»¥å¾€WSSSæ–¹æ³•çš„ç»“æœï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚</p></li></ol><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-09_08-49-54.png" alt="Snipaste_2025-04-09_08-49-54" loading="lazy"></p><h2 id="å®éªŒ-compared-with-sota" tabindex="-1">å®éªŒï¼ˆCompared with SOTAï¼‰ <a class="header-anchor" href="#å®éªŒ-compared-with-sota" aria-label="Permalink to &quot;å®éªŒï¼ˆCompared with SOTAï¼‰&quot;">â€‹</a></h2><p>æ•°æ®é›†ï¼š<strong>PASCAL VOC 2012ã€COCO 2014</strong></p><ul><li><strong>ASCAL VOC 2012</strong>ï¼šåœ¨CAMç›‘ç£æ–¹é¢ï¼ŒWeakCLIPä¸MCTformerç›¸åŒï¼Œä½†ä½äºViT - PCMï¼›åœ¨ä¼ªæ©ç è´¨é‡ä¸Šï¼Œæ¯”åŸºçº¿MCTformeræé«˜äº†8.1%ï¼Œæ¯”AMNæé«˜äº†5.0%ã€‚ä½¿ç”¨ç²¾ç‚¼åçš„ä¼ªæ©ç è®­ç»ƒDeepLabV1ç½‘ç»œï¼ŒWeakCLIPåœ¨éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸Šçš„mIoUåˆ†åˆ«è¾¾åˆ°74.0%å’Œ73.8%ï¼Œä¼˜äºå…¶ä»–ä»…ä½¿ç”¨å›¾åƒçº§ç›‘ç£çš„æ–¹æ³•ï¼Œä»¥åŠéƒ¨åˆ†ä½¿ç”¨é¢å¤–æ˜¾è‘—å›¾ç›‘ç£æˆ–è¾¹ç•Œæ¡†ç›‘ç£çš„æ–¹æ³•ã€‚ä½¿ç”¨åŸºäºViTçš„å†è®­ç»ƒåŸºå‡†ï¼ˆSegmenterå’ŒSegFormerï¼‰å¯è¿›ä¸€æ­¥æå‡åˆ†å‰²ç»“æœï¼Œæ··åˆViTå†è®­ç»ƒçš„WeakCLIPè¡¨ç°æœ€ä½³ã€‚</li><li><strong>COCO 2014</strong>ï¼šWeakCLIPåœ¨éªŒè¯é›†ä¸Šçš„mIoUè¾¾åˆ°46.1%ï¼Œæ¯”åŸºçº¿MCTformeræé«˜äº†4.1%ï¼Œä¼˜äºå…¶ä»–ä»…ä½¿ç”¨å›¾åƒçº§ç›‘ç£çš„æ–¹æ³•ã€‚ä½¿ç”¨SegFormerå’ŒMiT - B2éª¨å¹²è¿›è¡Œå†è®­ç»ƒï¼ŒWeakCLIPåœ¨COCO 2014éªŒè¯é›†ä¸Šå–å¾—æœ€ä½³æ€§èƒ½ã€‚</li></ul><h2 id="å®éªŒ-ablation-experiments" tabindex="-1">å®éªŒï¼ˆAblation Experimentsï¼‰ğŸ¥‡ <a class="header-anchor" href="#å®éªŒ-ablation-experiments" aria-label="Permalink to &quot;å®éªŒï¼ˆAblation Experimentsï¼‰:1st_place_medal:&quot;">â€‹</a></h2><ol><li><ul><li><strong>ç»„ä»¶æ”¹è¿›</strong>ï¼šååŒæ³¨æ„åŠ›åŒ¹é…æ¨¡å—å°†éªŒè¯é›†mIoUæé«˜åˆ°67.4%ï¼›å¯å­¦ä¹ æç¤ºå°†å…¶æé«˜åˆ°68.9%ï¼›é‡‘å­—å¡”é€‚é…å™¨å°†æ€§èƒ½æå‡åˆ°70.3%ï¼›æ–‡æœ¬å¼•å¯¼è§£ç å™¨å°†éªŒè¯é›†mIoUè¿›ä¸€æ­¥æå‡åˆ°72.6%ã€‚</li><li><strong>å¯å­¦ä¹ åµŒå…¥æ•°é‡</strong>ï¼šå¯å­¦ä¹ åµŒå…¥æ•°é‡ä¸º8æ—¶æ€§èƒ½æœ€ä½³ã€‚</li><li><strong>å¯å­¦ä¹ æ¸©åº¦åˆå§‹å€¼</strong>ï¼šååŒæ³¨æ„åŠ›åŒ¹é…ä¸­å¯å­¦ä¹ æ¸©åº¦åˆå§‹å€¼ä¸º1e - 1æ—¶æ€§èƒ½æœ€ä½³ã€‚</li></ul></li></ol><h2 id="å…¶ä»–å®éªŒ-other-experiments" tabindex="-1">å…¶ä»–å®éªŒï¼ˆOther Experimentsï¼‰ğŸ¥‡ <a class="header-anchor" href="#å…¶ä»–å®éªŒ-other-experiments" aria-label="Permalink to &quot;å…¶ä»–å®éªŒï¼ˆOther Experimentsï¼‰:1st_place_medal:&quot;">â€‹</a></h2><ol><li><strong>é€ç±»è¯­ä¹‰åˆ†å‰²ç»“æœ</strong>ï¼šåœ¨PASCAL VOC 2012çš„éªŒè¯é›†å’Œæµ‹è¯•é›†ä»¥åŠCOCO 2014çš„éªŒè¯é›†ä¸Šï¼Œå°†WeakCLIPä¸åŸºçº¿MCTformerè¿›è¡Œé€ç±»åˆ†å‰²ç»“æœæ¯”è¾ƒï¼ŒWeakCLIPåœ¨å¤§å¤šæ•°ç±»åˆ«ä¸­è¡¨ç°æ›´ä¼˜ã€‚</li><li><strong>å¯è§†åŒ–åˆ†æ</strong><ul><li>æ¯”è¾ƒMCTformerå’ŒWeakCLIPç”Ÿæˆçš„ä¼ªæ©ç ï¼ŒWeakCLIPç”Ÿæˆçš„è¯­ä¹‰ä¿¡æ¯æ›´å‡†ç¡®ã€ç²¾ç¡®ï¼Œèƒ½è¯†åˆ«å‡ºMCTformeré—æ¼æˆ–è¯†åˆ«ä¸å‡†ç¡®çš„å¯¹è±¡ä½ç½®ã€‚</li><li>åœ¨PASCAL VOC 2012éªŒè¯é›†ä¸Šå†è®­ç»ƒåçš„åˆ†å‰²ç»“æœå¯è§†åŒ–æ˜¾ç¤ºï¼ŒWeakCLIPå¯¹å®¤å†…å’Œå®¤å¤–åœºæ™¯éƒ½èƒ½å®ç°å‡†ç¡®åˆ†å‰²ã€‚</li></ul></li><li><strong>å‚æ•°æ•ˆç‡åˆ†æ</strong>ï¼šä¸MCTformerç›¸æ¯”ï¼ŒWeakCLIPä»…è®­ç»ƒ12.4%çš„å‚æ•°ï¼Œè®­ç»ƒå¸§ç‡ï¼ˆFPSï¼‰å¿«4.3å€ï¼ŒèŠ‚çœ68.4%çš„GPUå†…å­˜ã€‚</li><li><strong>ä¸åŒCLIPéª¨å¹²å®éªŒ</strong>ï¼šä½¿ç”¨ä¸åŒCLIPéª¨å¹²è¿›è¡Œå®éªŒï¼Œç»“æœè¡¨æ˜WeakCLIP - ResNet101æ€§èƒ½ä¼˜äºWeakCLIP - ResNet50ï¼ŒWeakCLIP - ViT - Bè¡¨ç°æœ€ä½³ã€‚</li></ol><h2 id="ç»“è®º" tabindex="-1">ç»“è®º <a class="header-anchor" href="#ç»“è®º" aria-label="Permalink to &quot;ç»“è®º&quot;">â€‹</a></h2><p>ä½œè€…æå‡ºäº†åä¸º<strong>WeakCLIP</strong>çš„æ–°æ–¹æ¡ˆï¼Œæ—¨åœ¨åˆ©ç”¨é¢„è®­ç»ƒCLIPæ¨¡å‹çš„çŸ¥è¯†æ¥å¢å¼ºå¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰ç½‘ç»œçš„**ç±»æ¿€æ´»å›¾ï¼ˆCAMï¼‰**ç»†åŒ–è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†æ–°çš„æ–‡æœ¬åˆ°åƒç´ åŒ¹é…èŒƒå¼ï¼Œæœ‰æ•ˆè§£å†³äº†å°†CLIPé›†æˆåˆ°WSSSä¸­å­˜åœ¨çš„ä¸‰ä¸ªå…³é”®é—®é¢˜ã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„PASCAL VOC 2012å’ŒCOCO 2014æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä»¥å¾€çš„WSSSæ–¹æ³•ç›¸æ¯”ï¼ŒWeakCLIPå–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚å¼•å…¥åˆ©ç”¨å¤§è§„æ¨¡è§†è§‰è¯­è¨€é¢„è®­ç»ƒçš„WeakCLIPèŒƒå¼ï¼Œæœ‰æœ›æ¨åŠ¨WSSSé—®é¢˜çš„è§£å†³ã€‚æœªæ¥ï¼Œä½œè€…è®¡åˆ’æ¢ç´¢æ›´å…ˆè¿›çš„å¤§è§„æ¨¡CLIPï¼Œä»¥æå‡WSSSçš„åƒç´ çº§ç†è§£èƒ½åŠ›ã€‚</p></div></div></main><footer class="VPDocFooter" data-v-4e3ca6fa data-v-92f5315a><!--[--><!--[--><!--[--><!--[--><div style="" class="vitepress-backTop-main" title="è¿”å›é¡¶éƒ¨" data-v-16856a25><svg t="1720595052079" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4279" width="200" height="200" data-v-16856a25><path d="M752.736 431.063C757.159 140.575 520.41 8.97 504.518 0.41V0l-0.45 0.205-0.41-0.205v0.41c-15.934 8.56-252.723 140.165-248.259 430.653-48.21 31.457-98.713 87.368-90.685 184.074 8.028 96.666 101.007 160.768 136.601 157.287 35.595-3.482 25.232-30.31 25.232-30.31l12.206-50.095s52.47 80.569 69.304 80.528c15.114-1.23 87-0.123 95.6 0h0.82c8.602-0.123 80.486-1.23 95.6 0 16.794 0 69.305-80.528 69.305-80.528l12.165 50.094s-10.322 26.83 25.272 30.31c35.595 3.482 128.574-60.62 136.602-157.286 8.028-96.665-42.475-152.617-90.685-184.074z m-248.669-4.26c-6.758-0.123-94.781-3.359-102.891-107.192 2.95-98.714 95.97-107.438 102.891-107.93 6.964 0.492 99.943 9.216 102.892 107.93-8.11 103.833-96.174 107.07-102.892 107.192z m-52.019 500.531c0 11.838-9.42 21.382-21.012 21.382a21.217 21.217 0 0 1-21.054-21.34V821.74c0-11.797 9.421-21.382 21.054-21.382 11.591 0 21.012 9.585 21.012 21.382v105.635z m77.333 57.222a21.504 21.504 0 0 1-21.34 21.626 21.504 21.504 0 0 1-21.34-21.626V827.474c0-11.96 9.543-21.668 21.299-21.668 11.796 0 21.38 9.708 21.38 21.668v157.082z m71.147-82.043c0 11.796-9.42 21.34-21.053 21.34a21.217 21.217 0 0 1-21.013-21.34v-75.367c0-11.755 9.421-21.299 21.013-21.299 11.632 0 21.053 9.544 21.053 21.3v75.366z" fill="#FFF" p-id="4280" data-v-16856a25></path></svg></div><!--]--><!--]--><!--]--><!--]--><div class="edit-info" data-v-92f5315a><div class="edit-link" data-v-92f5315a><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/Louaq/blog/tree/main/docs/column/Paper/WeakCLIP Adapting CLIP for Weakly-Supervised Semantic.md" target="_blank" rel="noreferrer" data-v-92f5315a><!--[--><span class="vpi-square-pen edit-link-icon" data-v-92f5315a></span> åœ¨githubä¸Šç¼–è¾‘æ­¤é¡µé¢<!--]--></a></div><div class="last-updated" data-v-92f5315a><p class="VPLastUpdated" data-v-92f5315a data-v-8bddb0e8>æœ€åæ›´æ–°äº: <time datetime="2025-04-30T14:43:39.000Z" data-v-8bddb0e8></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-92f5315a><span class="visually-hidden" id="doc-footer-aria-label" data-v-92f5315a>Pager</span><div class="pager" data-v-92f5315a><a class="VPLink link pager-link prev" href="/blog/column/Paper/All-pairs%20Consistency%20Learning%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-92f5315a><!--[--><span class="desc" data-v-92f5315a>ä¸Šä¸€é¡µ</span><span class="title" data-v-92f5315a>åŸºäºå…¨å¯¹ä¸€è‡´æ€§å­¦ä¹ çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</span><!--]--></a></div><div class="pager" data-v-92f5315a><a class="VPLink link pager-link next" href="/blog/column/Paper/SFC%20Shared%20Feature%20Calibration%20in%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-92f5315a><!--[--><span class="desc" data-v-92f5315a>ä¸‹ä¸€é¡µ</span><span class="title" data-v-92f5315a>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ä¸­çš„å…±äº«æƒé‡æ ¡å‡†</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-9bcec609 data-v-93274d57><div class="container" data-v-93274d57><p class="message" data-v-93274d57>Released under the <a href="https://mit-license.org/">MIT License.</a> | 
    æœ¬ç«™è®¿å®¢æ•° <span id="busuanzi_value_site_uv"></span> äººæ¬¡</p><p class="copyright" data-v-93274d57>Copyright Â© 2024-2025</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"CM58dPIy\",\"column_image_segmentation_20250224-è¯­ä¹‰åˆ†å‰²æ¦‚è¿°.md\":\"DJ9aYSe4\",\"column_image_segmentation_20250312-pytorchæ•™ç¨‹.md\":\"D5CxUCg-\",\"column_image_segmentation_220250224-è¯­ä¹‰åˆ†å‰²ä¸Šé‡‡æ ·.md\":\"D5oc3w1y\",\"column_image_segmentation_fcnæ¨¡å‹è®²è§£.md\":\"BZLPVhhI\",\"column_image_segmentation_index.md\":\"Cnnp9LXF\",\"column_image_segmentation_segment algrothm.md\":\"DaRLgJ0n\",\"column_image_segmentation_å›¾åƒåˆ†å‰²åŸºç¡€.md\":\"BmgyYd22\",\"column_image_segmentation_è¯­ä¹‰åˆ†å‰²åŸºç¡€æ¨¡å‹.md\":\"DUH2PxjJ\",\"column_paper_a transformer-basedadaptiveprototypematchingnetwork.md\":\"DcrK4Xvz\",\"column_paper_all-pairs consistency learning for weakly supervised semantic segmentation.md\":\"DvX7x9-E\",\"column_paper_c-cam causal cam for weakly supervised semantic segmentation on medical image.md\":\"D1Kx1tOx\",\"column_paper_cc4s encouraging certainty and consistency in scribble-supervised semantic segmentation.md\":\"B893K9ex\",\"column_paper_class tokens infusion for weakly supervised semantic segmentation.md\":\"IrpndHQH\",\"column_paper_corrmatch label propagation via correlation matching for semi-supervised semantic segmentation.md\":\"ZdGVBa6V\",\"column_paper_cross-domain few-shot semantic segmentation via doubly matching transformation.md\":\"a-y9d-aH\",\"column_paper_dgss.md\":\"DYlWMCsg\",\"column_paper_dsmf-net dual semantic metric learning fusion network for few-shot aerial image semantic segmentation.md\":\"Kehsl8wn\",\"column_paper_high_quality_segmentation.md\":\"BczNX3CC\",\"column_paper_index.md\":\"CePKwe5R\",\"column_paper_kill two birds with one stone domain generalization for semantic segmentation via network pruning.md\":\"DtChIPkY\",\"column_paper_knowledge transfer with simulated inter-image erasing for weakly supervised semantic segmentation.md\":\"FSl71yox\",\"column_paper_learninggeneralizedmedicalimagesegmentationfromdecoupledfeaturequeries.md\":\"KVKYo0G7\",\"column_paper_lgad local and global attention distillation for efficient semantic segmentation.md\":\"CmDI8avq\",\"column_paper_llmformer large languagemodel for open-vocabulary semantic.md\":\"B4Vd7yMW\",\"column_paper_night-time_semantic_segmentation.md\":\"B2lCfwcj\",\"column_paper_pat.md\":\"pcvVhIb3\",\"column_paper_pixel-wise reclassification with prototypes for enhancing weakly supervised semantic segmentation.md\":\"CczNRG9p\",\"column_paper_progressive feature self-reinforcement for weakly supervised semantic segmentation.md\":\"69bdYjZh\",\"column_paper_prompting_multi-moda_segmetation.md\":\"B7LyZ28Z\",\"column_paper_relevant intrinsic feature enhancement network for few-shot semantic segmentation.md\":\"bwcHQVPD\",\"column_paper_rolling-unet revitalizing mlp ability to efficiently extract long-distance dependencies for medical image segmentation.md\":\"C0yqKavn\",\"column_paper_scaling_upmulti-domain_semantic_segmentation_with_sentence.md\":\"DjJdi5nt\",\"column_paper_scribbl_hides_class_promoting_scribble-based_weakly-supervised_semantic_segmentation_with its class label.md\":\"CetPxX_K\",\"column_paper_scribble-supervised semantic segmentation with prototype-based feature augmentation.md\":\"SEmaCmIS\",\"column_paper_sed.md\":\"AGJR-cvQ\",\"column_paper_segment anything.md\":\"JUOxZkd-\",\"column_paper_self-supervised_vit.md\":\"CuqUnHnx\",\"column_paper_sfc shared feature calibration in weakly supervised semantic segmentation.md\":\"0ZmwNJcO\",\"column_paper_towards open-vocabulary semantic segmentation without semantic labels.md\":\"itszMl-0\",\"column_paper_use universal segment embeddings for open-vocabulary image segmentation.md\":\"BrQcgEAg\",\"column_paper_visual studio code latex.md\":\"Crcgltrd\",\"column_paper_weakclip adapting clip for weakly-supervised semantic.md\":\"DXzQMqhZ\",\"column_puruse_index.md\":\"CgK5aykD\",\"column_puruse_template.md\":\"BDhSDpKE\",\"index.md\":\"Cv44Amku\",\"markdown-examples.md\":\"CfpMxZtF\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"lab blog\",\"description\":\"A VitePress Site\",\"base\":\"/blog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"darkModeSwitchLabel\":\"æ·±æµ…æ¨¡å¼\",\"logo\":\"/b.jpg\",\"nav\":[{\"text\":\"é¦–é¡µ\",\"link\":\"/\"},{\"text\":\"è®ºæ–‡é˜…è¯»ç¬”è®°\",\"link\":\"/column/Paper/\"},{\"text\":\"è®ºæ–‡ç²¾è¯»ç¬”è®°\",\"link\":\"/column/Puruse/\"},{\"text\":\"å›¾åƒåˆ†å‰²\",\"link\":\"/column/image_segmentation\"}],\"sidebarMenuLabel\":\"ç›®å½•\",\"returnToTopLabel\":\"è¿”å›é¡¶éƒ¨\",\"sidebar\":{\"/column/Paper/\":[{\"text\":\"è®ºæ–‡é˜…è¯»\",\"collapsed\":true,\"items\":[{\"text\":\"latexç¯å¢ƒé…ç½®\",\"link\":\"/column/Paper/Visual Studio Code latex\"},{\"text\":\"Segment Anything\",\"link\":\"/column/Paper/Segment Anything\"},{\"text\":\"é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/DGSS\"},{\"text\":\"åŸºäºåˆ†å±‚ç¼–ç å™¨çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/SED\"},{\"text\":\"è¶…é«˜åˆ†è¾¨ç‡åˆ†å‰²\",\"link\":\"/column/Paper/High_Quality_Segmentation\"},{\"text\":\"å¤œé—´åœºæ™¯è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Night-time_Semantic_Segmentation\"},{\"text\":\"æç¤ºè¯è¿ç§»çš„å°‘æ ·æœ¬åˆ†å‰²\",\"link\":\"/column/Paper/PAT\"},{\"text\":\"å¤šæ¨¡æ€å›¾åƒåˆ†å‰²\",\"link\":\"/column/Paper/Prompting_Multi-Moda_Segmetation\"},{\"text\":\"åŸºäºTransformerçš„è‡ªé€‚åº”åŸå‹åŒ¹é…ç½‘ç»œ\",\"link\":\"/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork\"},{\"text\":\"è·¨é¢†åŸŸå°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Cross-Domain Few-Shot Semantic Segmentation via Doubly Matching Transformation\"},{\"text\":\"ç›¸å…³å†…åœ¨ç‰¹å¾å¢å¼ºçš„å°‘æ ·æœ¬ä¸æ„ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic Segmentation\"},{\"text\":\"åŸºäºæ¶‚é¸¦çš„æ— ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Scribble-Supervised Semantic Segmentation with Prototype-based Feature Augmentation\"},{\"text\":\"é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„æ¸è¿›å¼ç‰¹å¾è‡ªå¢å¼º\",\"link\":\"/column/Paper/Progressive Feature Self-Reinforcement for Weakly Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºè‡ªç›‘ç£Vitçš„è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Self-supervised_ViT\"},{\"text\":\"åŒ»å­¦å›¾åƒåˆ†å‰²ï¼šåŸºäºè§£è€¦ç‰¹å¾æŸ¥è¯¢\",\"link\":\"/column/Paper/LearningGeneralizedMedicalImageSegmentationfromDecoupledFeatureQueries\"},{\"text\":\"åŸºäºè¯­å¥åµŒå…¥çš„å¤šé¢†åŸŸè¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Scaling_UpMulti-domain_Semantic_Segmentation_with_Sentence\"},{\"text\":\"åŸºäºæ¶‚é¸¦çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Scribbl_Hides_Class_Promoting_Scribble-Based_Weakly-Supervised_Semantic_Segmentation_with Its Class Label\"}]},{\"text\":\"è¯­ä¹‰åˆ†å‰²è®ºæ–‡é˜…è¯»\",\"collapsed\":false,\"items\":[{\"text\":\"æ¶‚é¸¦ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç¡®å®šæ€§å’Œä¸€è‡´æ€§(CC4S)\",\"link\":\"/column/Paper/CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºå…³è”åŒ¹é…çš„æ ‡ç­¾ä¼ æ’­åŠç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"column/Paper/CorrMatch Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºLLMçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/LLMFormer Large LanguageModel for Open-Vocabulary Semantic\"},{\"text\":\"æ— éœ€è¯­ä¹‰æ ‡ç­¾çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²(æ–‡ç« æ™¦æ¶©ï¼Œä¸å»ºè®®é˜…è¯»)\",\"link\":\"/column/Paper/Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels\"},{\"text\":\"é¢å‘å¼€æ”¾è¯æ±‡å›¾åƒåˆ†å‰²çš„é€šç”¨ç‰‡æ®µåµŒå…¥\",\"link\":\"/column/Paper/USE Universal Segment Embeddings for Open-Vocabulary Image Segmentation\"},{\"text\":\"é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç±»åˆ«æ ‡è®°æ³¨å…¥\",\"link\":\"/column/Paper/Class Tokens Infusion for Weakly Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºå…¨å±€å’Œå±€éƒ¨æ³¨æ„åŠ›è’¸é¦çš„é«˜æ•ˆè¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/LGAD Local and Global Attention Distillation for Efficient Semantic Segmentation\"},{\"text\":\"åŸºäºåŒé‡è¯­ä¹‰åº¦é‡å­¦ä¹ çš„å°‘æ ·æœ¬èˆªæ‹å›¾åƒè¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/DSMF-Net Dual Semantic Metric Learning Fusion Network for Few-Shot Aerial Image Semantic Segmentation\"},{\"text\":\"åŸºäºå‰ªæçš„é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Kill Two Birds with One Stone Domain Generalization for Semantic Segmentation via Network Pruning\"},{\"text\":\"åŸºäºå…¨å¯¹ä¸€è‡´æ€§å­¦ä¹ çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/All-pairs Consistency Learning for Weakly Supervised Semantic Segmentation\"},{\"text\":\"weakCLIP\",\"link\":\"/column/Paper/WeakCLIP Adapting CLIP for Weakly-Supervised Semantic\"},{\"text\":\"å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ä¸­çš„å…±äº«æƒé‡æ ¡å‡†\",\"link\":\"/column/Paper/SFC Shared Feature Calibration in Weakly Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºæ¨¡æ‹Ÿå›¾åƒé—´æ“¦é™¤çŸ¥è¯†è¿ç§»çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Knowledge Transfer with Simulated Inter-Image Erasing for Weakly Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºåŸå‹çš„åƒç´ çº§å†åˆ†ç±»æé«˜å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Pixel-Wise Reclassification with Prototypes for Enhancing Weakly Supervised Semantic Segmentation\"},{\"text\":\"C-CAM\",\"link\":\"/column/Paper/C-CAM Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image\"},{\"text\":\"åŒ»å­¦å›¾åƒåˆ†å‰²ï¼šRolling-Net\",\"link\":\"/column/Paper/Rolling-Unet Revitalizing MLP Ability to Efficiently Extract Long-Distance Dependencies for Medical Image Segmentation\"}]}],\"/column/image_segmentation/\":[{\"text\":\"å›¾åƒåˆ†å‰²åŸç†åŠæ¦‚å¿µ\",\"collapsed\":false,\"items\":[{\"text\":\"è¯­ä¹‰åˆ†å‰²æ¦‚è¿°\",\"link\":\"/column/image_segmentation/20250224-è¯­ä¹‰åˆ†å‰²æ¦‚è¿°\"},{\"text\":\"è¯­ä¹‰åˆ†å‰²ä¸Šé‡‡æ ·\",\"link\":\"/column/image_segmentation/220250224-è¯­ä¹‰åˆ†å‰²ä¸Šé‡‡æ ·\"},{\"text\":\"å›¾åƒåˆ†å‰²åŸºç¡€\",\"link\":\"/column/image_segmentation/å›¾åƒåˆ†å‰²åŸºç¡€\"},{\"text\":\"è¯­ä¹‰åˆ†å‰²åŸºç¡€æ¨¡å‹\",\"link\":\"/column/image_segmentation/è¯­ä¹‰åˆ†å‰²åŸºç¡€æ¨¡å‹\"},{\"text\":\"FCNæ¨¡å‹è®²è§£\",\"link\":\"/column/image_segmentation/FCNæ¨¡å‹è®²è§£\"}]},{\"text\":\"å·ç§¯ç½‘ç»œ\",\"collapsed\":false,\"items\":[{\"text\":\"å·ç§¯ç½‘ç»œ\",\"link\":\"/column/image_segmentation/20250312-Pytorchæ•™ç¨‹\"},{\"text\":\"åˆ†å‰²ç®—æ³•(åŒæµå­è±ªå…„)\",\"link\":\"/column/image_segmentation/segment algrothm\"}]}],\"/column/Puruse/\":[{\"text\":\"è®ºæ–‡ç²¾è¯»\",\"collapsed\":false,\"items\":[{\"text\":\"ç²¾è¯»æ¨¡æ¿\",\"link\":\"/column/Puruse/template\"}]}]},\"lastUpdated\":{\"text\":\"æœ€åæ›´æ–°äº\",\"formatOptions\":{\"dateStyle\":\"full\",\"timeStyle\":\"medium\"}},\"editLink\":{\"pattern\":\"https://github.com/Louaq/blog/tree/main/docs/:path\",\"text\":\"åœ¨githubä¸Šç¼–è¾‘æ­¤é¡µé¢\"},\"outline\":{\"level\":[2,6],\"label\":\"å½“å‰å¤§çº²\"},\"docFooter\":{\"prev\":\"ä¸Šä¸€é¡µ\",\"next\":\"ä¸‹ä¸€é¡µ\"},\"search\":{\"provider\":\"local\"},\"footer\":{\"message\":\"Released under the <a href=\\\"https://mit-license.org/\\\">MIT License.</a> | \\n    æœ¬ç«™è®¿å®¢æ•° <span id=\\\"busuanzi_value_site_uv\\\"></span> äººæ¬¡\",\"copyright\":\"Copyright Â© 2024-2025\"},\"i18nRouting\":true},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>