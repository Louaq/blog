<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels | lab blog</title>
    <meta name="description" content="A VitePress Site">
    <meta name="generator" content="VitePress v1.2.2">
    <link rel="preload stylesheet" href="/blog/assets/style.DjOpM9sR.css" as="style">
    
    <script type="module" src="/blog/assets/app.CNJiusZ9.js"></script>
    <link rel="preload" href="/blog/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/blog/assets/chunks/framework.CLo04awk.js">
    <link rel="modulepreload" href="/blog/assets/chunks/theme.BI0VntTk.js">
    <link rel="modulepreload" href="/blog/assets/column_Paper_Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels.md.BPDcB6-k.lean.js">
    <link rel="icon" href="/blog/icon.png">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <script id="register-sw">"serviceWorker"in navigator&&navigator.serviceWorker.register("/sw.js");</script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
    <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
    <script>typeof LA<"u"&&LA.init({id:"3LPXyA1ZitpV3O1s",ck:"3LPXyA1ZitpV3O1s",autoTrack:!0,hashMode:!0});</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-f10dfbfe><!--[--><!--]--><!--[--><span tabindex="-1" data-v-990bc0c7></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-990bc0c7> Skip to content </a><!--]--><!----><header class="VPNav" data-v-f10dfbfe data-v-a3d208eb><div class="VPNavBar has-sidebar top" data-v-a3d208eb data-v-b617171c><div class="wrapper" data-v-b617171c><div class="container" data-v-b617171c><div class="title" data-v-b617171c><div class="VPNavBarTitle has-sidebar" data-v-b617171c data-v-40e0514d><a class="title" href="/blog/" data-v-40e0514d><!--[--><!--]--><!--[--><img class="VPImage logo" src="/blog/b.jpg" alt data-v-72d3edbf><!--]--><span data-v-40e0514d>lab blog</span><!--[--><!--]--></a></div></div><div class="content" data-v-b617171c><div class="content-body" data-v-b617171c><!--[--><!--]--><div class="VPNavBarSearch search" data-v-b617171c><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-b617171c data-v-9189896b><span id="main-nav-aria-label" class="visually-hidden" data-v-9189896b>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/" tabindex="0" data-v-9189896b data-v-c2001aa6><!--[--><span data-v-c2001aa6>é¦–é¡µ</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/column/Paper/" tabindex="0" data-v-9189896b data-v-c2001aa6><!--[--><span data-v-c2001aa6>è®ºæ–‡é˜…è¯»ç¬”è®°</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/column/Puruse/" tabindex="0" data-v-9189896b data-v-c2001aa6><!--[--><span data-v-c2001aa6>è®ºæ–‡ç²¾è¯»ç¬”è®°</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/column/image_segmentation.html" tabindex="0" data-v-9189896b data-v-c2001aa6><!--[--><span data-v-c2001aa6>å›¾åƒåˆ†å‰²</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-b617171c data-v-cdb349b7><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-cdb349b7 data-v-6a6948a0 data-v-33c43c25><span class="check" data-v-33c43c25><span class="icon" data-v-33c43c25><!--[--><span class="vpi-sun sun" data-v-6a6948a0></span><span class="vpi-moon moon" data-v-6a6948a0></span><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-b617171c data-v-81c4a4eb data-v-3cb196e4><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-3cb196e4><span class="vpi-more-horizontal icon" data-v-3cb196e4></span></button><div class="menu" data-v-3cb196e4><div class="VPMenu" data-v-3cb196e4 data-v-e035cd6c><!----><!--[--><!--[--><!----><div class="group" data-v-81c4a4eb><div class="item appearance" data-v-81c4a4eb><p class="label" data-v-81c4a4eb>æ·±æµ…æ¨¡å¼</p><div class="appearance-action" data-v-81c4a4eb><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-81c4a4eb data-v-6a6948a0 data-v-33c43c25><span class="check" data-v-33c43c25><span class="icon" data-v-33c43c25><!--[--><span class="vpi-sun sun" data-v-6a6948a0></span><span class="vpi-moon moon" data-v-6a6948a0></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-b617171c data-v-9f10abfc><span class="container" data-v-9f10abfc><span class="top" data-v-9f10abfc></span><span class="middle" data-v-9f10abfc></span><span class="bottom" data-v-9f10abfc></span></span></button></div></div></div></div><div class="divider" data-v-b617171c><div class="divider-line" data-v-b617171c></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-f10dfbfe data-v-c91f5bc2><div class="container" data-v-c91f5bc2><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-c91f5bc2><span class="vpi-align-left menu-icon" data-v-c91f5bc2></span><span class="menu-text" data-v-c91f5bc2>ç›®å½•</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-c91f5bc2 data-v-32c38b9b><button data-v-32c38b9b>è¿”å›é¡¶éƒ¨</button><!----></div></div></div><aside class="VPSidebar" data-v-f10dfbfe data-v-0f776768><div class="curtain" data-v-0f776768></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-0f776768><span class="visually-hidden" id="sidebar-aria-label" data-v-0f776768> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-0f776768><section class="VPSidebarItem level-0 collapsible collapsed" data-v-0f776768 data-v-7f773a2d><div class="item" role="button" tabindex="0" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><h2 class="text" data-v-7f773a2d>è®ºæ–‡é˜…è¯»</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-7f773a2d><span class="vpi-chevron-right caret-icon" data-v-7f773a2d></span></div></div><div class="items" data-v-7f773a2d><!--[--><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Visual%20Studio%20Code%20latex.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>latexç¯å¢ƒé…ç½®</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Segment%20Anything.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>Segment Anything</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/DGSS.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/SED.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºåˆ†å±‚ç¼–ç å™¨çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/High_Quality_Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>è¶…é«˜åˆ†è¾¨ç‡åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Night-time_Semantic_Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>å¤œé—´åœºæ™¯è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/PAT.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>æç¤ºè¯è¿ç§»çš„å°‘æ ·æœ¬åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>å¤šæ¨¡æ€å›¾åƒåˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/A%20Transformer-basedAdaptivePrototypeMatchingNetwork.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºTransformerçš„è‡ªé€‚åº”åŸå‹åŒ¹é…ç½‘ç»œ</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Cross-Domain%20Few-Shot%20Semantic%20Segmentation%20via%20Doubly%20Matching%20Transformation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>è·¨é¢†åŸŸå°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Relevant%20Intrinsic%20Feature%20Enhancement%20Network%20for%20Few-Shot%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>ç›¸å…³å†…åœ¨ç‰¹å¾å¢å¼ºçš„å°‘æ ·æœ¬ä¸æ„ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Scribble-Supervised%20Semantic%20Segmentation%20with%20Prototype-based%20Feature%20Augmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºæ¶‚é¸¦çš„æ— ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Progressive%20Feature%20Self-Reinforcement%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„æ¸è¿›å¼ç‰¹å¾è‡ªå¢å¼º</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Self-supervised_ViT.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºè‡ªç›‘ç£Vitçš„è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/LearningGeneralizedMedicalImageSegmentationfromDecoupledFeatureQueries.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŒ»å­¦å›¾åƒåˆ†å‰²ï¼šåŸºäºè§£è€¦ç‰¹å¾æŸ¥è¯¢</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Scaling_UpMulti-domain_Semantic_Segmentation_with_Sentence.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºè¯­å¥åµŒå…¥çš„å¤šé¢†åŸŸè¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Scribbl_Hides_Class_Promoting_Scribble-Based_Weakly-Supervised_Semantic_Segmentation_with%20Its%20Class%20Label.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºæ¶‚é¸¦çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-0f776768><section class="VPSidebarItem level-0 collapsible has-active" data-v-0f776768 data-v-7f773a2d><div class="item" role="button" tabindex="0" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><h2 class="text" data-v-7f773a2d>è¯­ä¹‰åˆ†å‰²è®ºæ–‡é˜…è¯»</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-7f773a2d><span class="vpi-chevron-right caret-icon" data-v-7f773a2d></span></div></div><div class="items" data-v-7f773a2d><!--[--><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/CC4S%20Encouraging%20Certainty%20and%20Consistency%20in%20Scribble-Supervised%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>æ¶‚é¸¦ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç¡®å®šæ€§å’Œä¸€è‡´æ€§(CC4S)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/CorrMatch%20Label%20Propagation%20via%20Correlation%20Matching%20for%20Semi-Supervised%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºå…³è”åŒ¹é…çš„æ ‡ç­¾ä¼ æ’­åŠç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/LLMFormer%20Large%20LanguageModel%20for%20Open-Vocabulary%20Semantic.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºLLMçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Towards%20Open-Vocabulary%20Semantic%20Segmentation%20Without%20Semantic%20Labels.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>æ— éœ€è¯­ä¹‰æ ‡ç­¾çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²(æ–‡ç« æ™¦æ¶©ï¼Œä¸å»ºè®®é˜…è¯»)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/USE%20Universal%20Segment%20Embeddings%20for%20Open-Vocabulary%20Image%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>é¢å‘å¼€æ”¾è¯æ±‡å›¾åƒåˆ†å‰²çš„é€šç”¨ç‰‡æ®µåµŒå…¥</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Class%20Tokens%20Infusion%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç±»åˆ«æ ‡è®°æ³¨å…¥</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/LGAD%20Local%20and%20Global%20Attention%20Distillation%20for%20Efficient%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºå…¨å±€å’Œå±€éƒ¨æ³¨æ„åŠ›è’¸é¦çš„é«˜æ•ˆè¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/DSMF-Net%20Dual%20Semantic%20Metric%20Learning%20Fusion%20Network%20for%20Few-Shot%20Aerial%20Image%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºåŒé‡è¯­ä¹‰åº¦é‡å­¦ä¹ çš„å°‘æ ·æœ¬èˆªæ‹å›¾åƒè¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Kill%20Two%20Birds%20with%20One%20Stone%20Domain%20Generalization%20for%20Semantic%20Segmentation%20via%20Network%20Pruning.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºå‰ªæçš„é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/All-pairs%20Consistency%20Learning%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºå…¨å¯¹ä¸€è‡´æ€§å­¦ä¹ çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/WeakCLIP%20Adapting%20CLIP%20for%20Weakly-Supervised%20Semantic.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>weakCLIP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/SFC%20Shared%20Feature%20Calibration%20in%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ä¸­çš„å…±äº«æƒé‡æ ¡å‡†</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-7f773a2d data-v-7f773a2d><div class="item" data-v-7f773a2d><div class="indicator" data-v-7f773a2d></div><a class="VPLink link link" href="/blog/column/Paper/Knowledge%20Transfer%20with%20Simulated%20Inter-Image%20Erasing%20for%20Weakly%20Supervised%20Semantic%20Segmentation.html" data-v-7f773a2d><!--[--><p class="text" data-v-7f773a2d>åŸºäºæ¨¡æ‹Ÿå›¾åƒé—´æ“¦é™¤çŸ¥è¯†è¿ç§»çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-f10dfbfe data-v-5dff0740><div class="VPDoc has-sidebar has-aside" data-v-5dff0740 data-v-35102dec><!--[--><!--]--><div class="container" data-v-35102dec><div class="aside" data-v-35102dec><div class="aside-curtain" data-v-35102dec></div><div class="aside-container" data-v-35102dec><div class="aside-content" data-v-35102dec><div class="VPDocAside" data-v-35102dec data-v-a63ed339><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-a63ed339 data-v-315f7e94><div class="content" data-v-315f7e94><div class="outline-marker" data-v-315f7e94></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-315f7e94>å½“å‰å¤§çº²</div><ul class="VPDocOutlineItem root" data-v-315f7e94 data-v-4f398093><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-a63ed339></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-35102dec><div class="content-container" data-v-35102dec><!--[--><!--]--><main class="main" data-v-35102dec><div style="position:relative;" class="vp-doc _blog_column_Paper_Towards%20Open-Vocabulary%20Semantic%20Segmentation%20Without%20Semantic%20Labels" data-v-35102dec><div><h1 id="towards-open-vocabulary-semantic-segmentation-without-semantic-labels" tabindex="-1">Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels <a class="header-anchor" href="#towards-open-vocabulary-semantic-segmentation-without-semantic-labels" aria-label="Permalink to &quot;Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels&quot;">â€‹</a></h1><div class="word"><p><svg t="1724572866572" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="18131" width="16" height="16"><path d="M168.021333 504.192A343.253333 343.253333 0 0 1 268.629333 268.8a342.229333 342.229333 0 0 1 243.285334-100.778667A341.504 341.504 0 0 1 755.029333 268.8c9.856 9.898667 19.2 20.394667 27.733334 31.402667l-60.16 46.976a8.021333 8.021333 0 0 0 2.986666 14.122666l175.701334 43.008a8.021333 8.021333 0 0 0 9.898666-7.68l0.810667-180.906666a7.936 7.936 0 0 0-12.885333-6.314667L842.666667 253.44a418.858667 418.858667 0 0 0-330.922667-161.493333c-229.12 0-415.488 183.594667-419.797333 411.818666a8.021333 8.021333 0 0 0 8.021333 8.192H160a7.978667 7.978667 0 0 0 8.021333-7.808zM923.946667 512H864a7.978667 7.978667 0 0 0-8.021333 7.808 341.632 341.632 0 0 1-26.88 125.994667 342.186667 342.186667 0 0 1-73.685334 109.397333 342.442667 342.442667 0 0 1-243.328 100.821333 342.229333 342.229333 0 0 1-270.976-132.224l60.16-46.976a8.021333 8.021333 0 0 0-2.986666-14.122666l-175.701334-43.008a8.021333 8.021333 0 0 0-9.898666 7.68l-0.682667 181.034666c0 6.698667 7.68 10.496 12.885333 6.314667L181.333333 770.56a419.072 419.072 0 0 0 330.922667 161.408c229.205333 0 415.488-183.722667 419.797333-411.818667a8.021333 8.021333 0 0 0-8.021333-8.192z" fill="#8a8a8a" p-id="18132"></path></svg> æ›´æ–°: 4/11/2025 <svg t="1724571760788" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6125" width="16" height="16"><path d="M204.8 0h477.866667l273.066666 273.066667v614.4c0 75.093333-61.44 136.533333-136.533333 136.533333H204.8c-75.093333 0-136.533333-61.44-136.533333-136.533333V136.533333C68.266667 61.44 129.706667 0 204.8 0z m307.2 607.573333l68.266667 191.146667c13.653333 27.306667 54.613333 27.306667 61.44 0l102.4-273.066667c6.826667-20.48 0-34.133333-20.48-40.96s-34.133333 0-40.96 13.653334l-68.266667 191.146666-68.266667-191.146666c-13.653333-27.306667-54.613333-27.306667-68.266666 0l-68.266667 191.146666-68.266667-191.146666c-6.826667-13.653333-27.306667-27.306667-47.786666-20.48s-27.306667 27.306667-20.48 47.786666l102.4 273.066667c13.653333 27.306667 54.613333 27.306667 61.44 0l75.093333-191.146667z" fill="#777777" p-id="6126"></path><path d="M682.666667 0l273.066666 273.066667h-204.8c-40.96 0-68.266667-27.306667-68.266666-68.266667V0z" fill="#E0E0E0" opacity=".619" p-id="6127"></path></svg> å­—æ•°: 0 å­— <svg t="1724572797268" class="icon" viewBox="0 0 1060 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15031" width="16" height="16"><path d="M556.726857 0.256A493.933714 493.933714 0 0 0 121.929143 258.998857L0 135.021714v350.390857h344.649143L196.205714 334.482286a406.820571 406.820571 0 1 1-15.908571 312.649143H68.937143A505.819429 505.819429 0 1 0 556.726857 0.256z m-79.542857 269.531429v274.907428l249.197714 150.966857 42.422857-70.070857-212.114285-129.389714V269.787429h-79.542857z" fill="#8a8a8a" p-id="15032"></path></svg> æ—¶é•¿: 0 åˆ†é’Ÿ </p></div><p>éŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢ã€Korea Universityã€Google Research</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>æ™¦æ¶©</p></div><h2 id="æ‘˜è¦" tabindex="-1">æ‘˜è¦ <a class="header-anchor" href="#æ‘˜è¦" aria-label="Permalink to &quot;æ‘˜è¦&quot;">â€‹</a></h2><p>Large-scale vision-language models like CLIP have demonstrated impressive open-vocabulary capabilities for image-level tasks, excelling in recognizing what objects are present. However, they struggle with pixel-level recognition tasks like semantic segmentation, which additionally require understanding where the objects are located. In this work, we propose a novel method, PixelCLIP, to adapt the CLIP image encoder for pixel-level understanding by guiding the model on where, which is achieved using unlabeled images and masks generated from vision foundation models such as SAM and DINO. To address the challenges of leveraging masks without semantic labels, we devise an online clustering algorithm using learnable class names to acquire general semantic concepts. PixelCLIP shows significant performance improvements over CLIP and competitive results compared to caption supervised methods in open-vocabulary semantic segmentation. Project page is available at <a href="https://cvlab-kaist.github.io/PixelCLIP" target="_blank" rel="noreferrer">https://cvlab-kaist.github.io/PixelCLIP</a></p><h2 id="ç¿»è¯‘" tabindex="-1">ç¿»è¯‘ <a class="header-anchor" href="#ç¿»è¯‘" aria-label="Permalink to &quot;ç¿»è¯‘&quot;">â€‹</a></h2><p>åƒCLIPè¿™æ ·çš„å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹å·²ç»ä¸ºå›¾åƒçº§ä»»åŠ¡å±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„å¼€æ”¾è¯æ±‡è¡¨èƒ½åŠ›ï¼Œåœ¨è¯†åˆ«å­˜åœ¨çš„å¯¹è±¡æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œä»–ä»¬åœ¨åƒè¯­ä¹‰åˆ†å‰²è¿™æ ·çš„åƒç´ çº§è¯†åˆ«ä»»åŠ¡ä¸­æŒ£æ‰ï¼Œè¿™è¿˜éœ€è¦ç†è§£ç‰©ä½“çš„ä½ç½®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼ŒPixelCLIPï¼Œé€šè¿‡å¼•å¯¼æ¨¡å‹åœ¨å“ªé‡Œæ¥è°ƒæ•´CLIPå›¾åƒç¼–ç å™¨ä»¥è¿›è¡Œåƒç´ çº§ç†è§£ï¼Œè¿™æ˜¯ä½¿ç”¨ä»è§†è§‰åŸºç¡€æ¨¡å‹(å¦‚SAMå’ŒDINO)ç”Ÿæˆçš„æœªæ ‡è®°å›¾åƒå’Œæ©ç æ¥å®ç°çš„ã€‚ä¸ºäº†è§£å†³åœ¨æ²¡æœ‰è¯­ä¹‰æ ‡ç­¾çš„æƒ…å†µä¸‹åˆ©ç”¨æ©ç çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä½¿ç”¨å¯å­¦ä¹ ç±»åæ¥è·å–ä¸€èˆ¬è¯­ä¹‰æ¦‚å¿µçš„åœ¨çº¿èšç±»ç®—æ³•ã€‚åœ¨å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ä¸­ï¼Œä¸å­—å¹•ç›‘ç£æ–¹æ³•ç›¸æ¯”ï¼ŒPixelCLIPè¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›å’Œç«äº‰ç»“æœã€‚é¡¹ç›®é¡µé¢å¯è®¿é—®<a href="https://cvlab-kaist.github.io/PixelCLIP" target="_blank" rel="noreferrer">https://cvlab-kaist.github.io/PixelCLIP</a></p><h2 id="ç ”ç©¶èƒŒæ™¯" tabindex="-1">ç ”ç©¶èƒŒæ™¯ <a class="header-anchor" href="#ç ”ç©¶èƒŒæ™¯" aria-label="Permalink to &quot;ç ”ç©¶èƒŒæ™¯&quot;">â€‹</a></h2><p><strong>è¯­ä¹‰åˆ†å‰²</strong>æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„åŸºç¡€ä»»åŠ¡ï¼Œæ—¨åœ¨ä¸ºå›¾åƒä¸­æ¯ä¸ªåƒç´ è¯†åˆ«ç±»åˆ«æ ‡ç­¾ã€‚ä½†ä¼ ç»Ÿåˆ†å‰²æ•°æ®é›†è·å–å¯†é›†æ ‡æ³¨çš„è¯­ä¹‰æ ‡ç­¾éœ€å¤§é‡äººåŠ›ï¼Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§ã€‚ è¿‘å¹´æ¥ï¼Œå¤§è§„æ¨¡é¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPã€ALIGNï¼‰æ¨åŠ¨äº†å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²çš„å‘å±•ï¼Œèƒ½å°†è¯­ä¹‰åˆ†å‰²æ¨å¹¿åˆ°æ— é™ç±»åˆ«çš„èŒƒå›´ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨è¿›è¡Œè¯­ä¹‰åˆ†å‰²æ—¶ä»éœ€åƒç´ çº§è¯­ä¹‰æ ‡ç­¾ã€‚ éƒ¨åˆ†ç ”ç©¶å°è¯•åœ¨æ— å¯†é›†æ ‡æ³¨è¯­ä¹‰æ ‡ç­¾çš„æƒ…å†µä¸‹è¿›è¡Œå¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ï¼Œåˆ©ç”¨å›¾åƒçº§è¯­ä¹‰æ ‡ç­¾ï¼ˆå¦‚å›¾åƒæ ‡é¢˜ï¼‰å¢å¼ºé¢„è®­ç»ƒè§†è§‰ - è¯­è¨€æ¨¡å‹ã€‚ä½†å›¾åƒæ ‡é¢˜é€šå¸¸åªæä¾›å›¾åƒä¸­æœ‰ä»€ä¹ˆï¼Œè€Œä¸åŒ…å«ç‰©ä½“ä½ç½®ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹åªèƒ½éšå¼å­¦ä¹ ç‰©ä½“ä½ç½®ï¼Œæ€§èƒ½ä¸ä½³æˆ–éœ€å¤§é‡å›¾åƒ-æ ‡é¢˜å¯¹æ¥å¼¥è¡¥å¼±ç›‘ç£ã€‚ å› æ­¤ï¼Œæœ¬æ–‡æå‡ºä¸€ç§æ–°æ–¹æ³•PixelCLIPï¼Œä¸ä¾èµ–è¯­ä¹‰æ ‡ç­¾ï¼Œè€Œæ˜¯åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚DINOã€SAMï¼‰ç”Ÿæˆçš„æ©ç å¼•å¯¼é¢„è®­ç»ƒè§†è§‰ - è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰å…³æ³¨ç‰©ä½“ä½ç½®ï¼Œä»¥å®ç°å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ï¼Œè§£å†³ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚</p><h2 id="ç ”ç©¶ç°çŠ¶" tabindex="-1">ç ”ç©¶ç°çŠ¶ <a class="header-anchor" href="#ç ”ç©¶ç°çŠ¶" aria-label="Permalink to &quot;ç ”ç©¶ç°çŠ¶&quot;">â€‹</a></h2><ul><li><strong>å¤§æ¨¡å‹åŠ©åŠ›å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</strong>ï¼šå¤§è§„æ¨¡é¢„è®­ç»ƒè§†è§‰ - è¯­è¨€æ¨¡å‹ï¼Œå¦‚CLIPå’ŒALIGNï¼Œæ¨åŠ¨äº†å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²çš„å‘å±•ï¼Œå¯å°†è¯­ä¹‰åˆ†å‰²æ¨å¹¿åˆ°æ— é™ç±»åˆ«çš„èŒƒå›´ã€‚</li><li><strong>å¼±ç›‘ç£æ–¹æ³•å…´èµ·</strong>ï¼šéƒ¨åˆ†ç ”ç©¶å°è¯•åœ¨æ— å¯†é›†æ ‡æ³¨è¯­ä¹‰æ ‡ç­¾çš„æƒ…å†µä¸‹è¿›è¡Œå¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ï¼Œåˆ©ç”¨å›¾åƒçº§è¯­ä¹‰æ ‡ç­¾ï¼ˆå¦‚å›¾åƒå­—å¹•ï¼‰å¢å¼ºé¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†å­˜åœ¨ä¿¡æ¯ç¼ºå¤±é—®é¢˜ã€‚</li><li><strong>è§†è§‰åŸºç¡€æ¨¡å‹åº”ç”¨</strong>ï¼šå¦‚DINOå’ŒSAMç­‰è§†è§‰åŸºç¡€æ¨¡å‹å¯ç”Ÿæˆç»†ç²’åº¦æ©ç ï¼Œä½†æ©ç æ— è¯­ä¹‰æ ‡ç­¾ã€‚</li></ul><h2 id="æå‡ºçš„æ¨¡å‹" tabindex="-1">æå‡ºçš„æ¨¡å‹ <a class="header-anchor" href="#æå‡ºçš„æ¨¡å‹" aria-label="Permalink to &quot;æå‡ºçš„æ¨¡å‹&quot;">â€‹</a></h2><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-03-25_16-05-19.png" alt="Snipaste_2025-03-25_16-05-19" loading="lazy"></p><ol><li>æ©ç é›†æˆåˆ°CLIPç‰¹å¾ <ul><li>ç”±äºæ²¡æœ‰è¯­ä¹‰æ ‡ç­¾ï¼Œä½œè€…é€šè¿‡æ©ç æ± åŒ–å°†æ— æ ‡ç­¾æ©ç é›†æˆåˆ°CLIPå›¾åƒç‰¹å¾å›¾ä¸­ï¼Œå¾—åˆ°æ¯ä¸ªæ©ç çš„CLIPç‰¹å¾ã€‚</li><li>åˆ©ç”¨è¿™äº›ç‰¹å¾è®¡ç®—å›¾åƒ - æ©ç ç›¸ä¼¼åº¦å›¾ï¼Œå¹¶ä½¿ç”¨äºŒå…ƒæ©ç æŸå¤±å¯¹æ¨¡å‹è¿›è¡Œç›‘ç£ï¼Œä»¥å¾®è°ƒCLIPå›¾åƒç¼–ç å™¨ã€‚</li><li>ä¸ºäº†ç¼“è§£ç›¸ä¼¼åº¦å›¾å’Œæ©ç ä¹‹é—´çš„åˆ†è¾¨ç‡å·®è·ï¼Œä½¿ç”¨è½»é‡çº§è§£ç å™¨è¿›è¡Œä¸Šé‡‡æ ·ã€‚</li></ul></li><li>æ©ç çš„è¯­ä¹‰èšç±» <ul><li><strong>åœ¨çº¿èšç±»</strong>ï¼šä¸ºäº†è§£å†³DINOå’ŒSAMç”Ÿæˆçš„æ©ç è¿‡åº¦åˆ†å‰²é—®é¢˜ï¼Œä½œè€…æå‡ºä½¿ç”¨å¯å­¦ä¹ çš„ç±»æç¤ºå°†è¯­ä¹‰ç›¸ä¼¼çš„æ©ç èšç±»æˆå…¨å±€å…±äº«çš„ç°‡ã€‚æ¯ä¸ªç°‡ç”±CLIPæ–‡æœ¬ç‰¹å¾è¡¨ç¤ºä¸ºè´¨å¿ƒï¼Œé€šè¿‡ä¼˜åŒ–å›¾åƒ - æ–‡æœ¬ç›¸ä¼¼åº¦å’Œç†µæ­£åˆ™åŒ–æ¥ç¡®å®šæ©ç çš„åˆ†é…ã€‚</li><li><strong>åŠ¨é‡ç¼–ç å™¨</strong>ï¼šä¸ºäº†ç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼Œä½¿ç”¨åŠ¨é‡ç¼–ç å™¨æ¥æå–æ©ç æ± åŒ–ç‰¹å¾ï¼Œé¿å…è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§å’Œé¢„è®­ç»ƒçŸ¥è¯†çš„é—å¿˜ã€‚</li></ul></li></ol><h2 id="å®éªŒ-compared-with-sota" tabindex="-1">å®éªŒï¼ˆCompared with SOTAï¼‰ <a class="header-anchor" href="#å®éªŒ-compared-with-sota" aria-label="Permalink to &quot;å®éªŒï¼ˆCompared with SOTAï¼‰&quot;">â€‹</a></h2><ol><li><strong>å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</strong>ï¼šPixelCLIPåœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­å‡æ˜¾è‘—ä¼˜äºCLIPï¼Œå¹³å‡mIoUæé«˜äº†16.2ã€‚ä¸ä½¿ç”¨å›¾åƒçº§ç›‘ç£çš„æ–¹æ³•ç›¸æ¯”ï¼ŒPixelCLIPåœ¨ä¸ä½¿ç”¨è¯­ä¹‰æ ‡ç­¾çš„æƒ…å†µä¸‹è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œç”šè‡³åœ¨æŸäº›åŸºå‡†æµ‹è¯•ä¸­è¶…è¿‡äº†è¿™äº›æ–¹æ³•ã€‚</li><li><strong>é›¶æ ·æœ¬æ©ç åˆ†ç±»</strong>ï¼šPixelCLIPå¯ä»¥ç›´æ¥åº”ç”¨äºç°æœ‰çš„ä½¿ç”¨CLIPä½œä¸ºé›¶æ ·æœ¬æ©ç åˆ†ç±»å™¨çš„æ¡†æ¶ï¼Œé€šè¿‡ç®€å•æ›¿æ¢CLIPæ¨¡å‹å’Œæƒé‡ï¼Œå³å¯å¸¦æ¥å³æ—¶çš„æ€§èƒ½æå‡ã€‚</li></ol><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-03-25_16-08-46.png" alt="Snipaste_2025-03-25_16-08-46" loading="lazy"></p><h2 id="å®éªŒ-ablation-experiments" tabindex="-1">å®éªŒï¼ˆAblation Experimentsï¼‰ğŸ¥‡ <a class="header-anchor" href="#å®éªŒ-ablation-experiments" aria-label="Permalink to &quot;å®éªŒï¼ˆAblation Experimentsï¼‰:1st_place_medal:&quot;">â€‹</a></h2><ol><li><strong>æ¶ˆèç ”ç©¶</strong>ï¼šé€šè¿‡æ¶ˆèç ”ç©¶éªŒè¯äº†æ¨¡å‹è®¾è®¡çš„å…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬å…¨å±€è¯­ä¹‰èšç±»ã€å¯å­¦ä¹ ç±»æç¤ºå’ŒåŠ¨é‡ç¼–ç å™¨çš„é‡è¦æ€§ã€‚åŒæ—¶ï¼Œç ”ç©¶äº†èšç±»æ•°é‡ã€å¯å­¦ä¹ æç¤ºä»¤ç‰Œé•¿åº¦ç­‰å› ç´ å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚</li></ol><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-03-25_16-09-10.png" alt="Snipaste_2025-03-25_16-09-10" loading="lazy"></p><h2 id="ç»“è®º" tabindex="-1">ç»“è®º <a class="header-anchor" href="#ç»“è®º" aria-label="Permalink to &quot;ç»“è®º&quot;">â€‹</a></h2><p>ä½œè€…æå‡ºäº†<strong>PixelCLIPæ¡†æ¶ç”¨äºå¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</strong>ï¼Œå¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š</p><ol><li><strong>æ–¹æ³•æœ‰æ•ˆæ€§</strong>ï¼šPixelCLIPé€šè¿‡åˆ©ç”¨æ— æ ‡ç­¾å›¾åƒå’Œæ©ç å¾®è°ƒé¢„è®­ç»ƒ<strong>è§†è§‰-è¯­è¨€æ¨¡å‹</strong>ï¼Œåœ¨å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†CLIPçš„æ€§èƒ½ï¼Œå¹³å‡mIoUæé«˜äº†16.2ï¼Œä¸”ä¼˜äºä½¿ç”¨å›¾åƒçº§è¯­ä¹‰æ ‡ç­¾çš„æ–¹æ³•ã€‚</li><li><strong>èšç±»ä¸æç¤ºå­¦ä¹ ä½œç”¨</strong>ï¼šæå‡ºçš„å…¨å±€è¯­ä¹‰èšç±»å’Œå¯å­¦ä¹ ç±»æç¤ºæ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆè§£å†³æ— æ ‡ç­¾æ©ç å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œä½¿æ¨¡å‹å­¦ä¹ åˆ°é€šç”¨è¯­ä¹‰æ¦‚å¿µï¼Œå¯¹æ¡†æ¶æ€§èƒ½æå‡è‡³å…³é‡è¦ã€‚</li><li><strong>é€‚ç”¨æ€§ä¸æ”¹è¿›</strong>ï¼šPixelCLIPå¯åº”ç”¨äºç°æœ‰åˆ©ç”¨CLIPè¿›è¡Œé›¶æ ·æœ¬æ©ç åˆ†ç±»çš„æ¡†æ¶ï¼Œç®€å•æ›¿æ¢CLIPå³å¯å¸¦æ¥å³æ—¶æ”¹è¿›ã€‚</li></ol></div></div></main><footer class="VPDocFooter" data-v-35102dec data-v-993905e5><!--[--><!--[--><!--[--><!--[--><div style="" class="vitepress-backTop-main" title="è¿”å›é¡¶éƒ¨" data-v-16856a25><svg t="1720595052079" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4279" width="200" height="200" data-v-16856a25><path d="M752.736 431.063C757.159 140.575 520.41 8.97 504.518 0.41V0l-0.45 0.205-0.41-0.205v0.41c-15.934 8.56-252.723 140.165-248.259 430.653-48.21 31.457-98.713 87.368-90.685 184.074 8.028 96.666 101.007 160.768 136.601 157.287 35.595-3.482 25.232-30.31 25.232-30.31l12.206-50.095s52.47 80.569 69.304 80.528c15.114-1.23 87-0.123 95.6 0h0.82c8.602-0.123 80.486-1.23 95.6 0 16.794 0 69.305-80.528 69.305-80.528l12.165 50.094s-10.322 26.83 25.272 30.31c35.595 3.482 128.574-60.62 136.602-157.286 8.028-96.665-42.475-152.617-90.685-184.074z m-248.669-4.26c-6.758-0.123-94.781-3.359-102.891-107.192 2.95-98.714 95.97-107.438 102.891-107.93 6.964 0.492 99.943 9.216 102.892 107.93-8.11 103.833-96.174 107.07-102.892 107.192z m-52.019 500.531c0 11.838-9.42 21.382-21.012 21.382a21.217 21.217 0 0 1-21.054-21.34V821.74c0-11.797 9.421-21.382 21.054-21.382 11.591 0 21.012 9.585 21.012 21.382v105.635z m77.333 57.222a21.504 21.504 0 0 1-21.34 21.626 21.504 21.504 0 0 1-21.34-21.626V827.474c0-11.96 9.543-21.668 21.299-21.668 11.796 0 21.38 9.708 21.38 21.668v157.082z m71.147-82.043c0 11.796-9.42 21.34-21.053 21.34a21.217 21.217 0 0 1-21.013-21.34v-75.367c0-11.755 9.421-21.299 21.013-21.299 11.632 0 21.053 9.544 21.053 21.3v75.366z" fill="#FFF" p-id="4280" data-v-16856a25></path></svg></div><!--]--><!--]--><!--]--><!--]--><div class="edit-info" data-v-993905e5><div class="edit-link" data-v-993905e5><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/Louaq/blog/tree/main/docs/column/Paper/Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels.md" target="_blank" rel="noreferrer" data-v-993905e5><!--[--><span class="vpi-square-pen edit-link-icon" data-v-993905e5></span> åœ¨githubä¸Šç¼–è¾‘æ­¤é¡µé¢<!--]--></a></div><div class="last-updated" data-v-993905e5><p class="VPLastUpdated" data-v-993905e5 data-v-47822a2b>æœ€åæ›´æ–°äº: <time datetime="2025-04-11T09:37:48.000Z" data-v-47822a2b></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-993905e5><span class="visually-hidden" id="doc-footer-aria-label" data-v-993905e5>Pager</span><div class="pager" data-v-993905e5><a class="VPLink link pager-link prev" href="/blog/column/Paper/LLMFormer%20Large%20LanguageModel%20for%20Open-Vocabulary%20Semantic.html" data-v-993905e5><!--[--><span class="desc" data-v-993905e5>ä¸Šä¸€é¡µ</span><span class="title" data-v-993905e5>åŸºäºLLMçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²</span><!--]--></a></div><div class="pager" data-v-993905e5><a class="VPLink link pager-link next" href="/blog/column/Paper/USE%20Universal%20Segment%20Embeddings%20for%20Open-Vocabulary%20Image%20Segmentation.html" data-v-993905e5><!--[--><span class="desc" data-v-993905e5>ä¸‹ä¸€é¡µ</span><span class="title" data-v-993905e5>é¢å‘å¼€æ”¾è¯æ±‡å›¾åƒåˆ†å‰²çš„é€šç”¨ç‰‡æ®µåµŒå…¥</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-f10dfbfe data-v-8682a75c><div class="container" data-v-8682a75c><p class="message" data-v-8682a75c>Released under the <a href="https://mit-license.org/">MIT License.</a> | 
    æœ¬ç«™è®¿å®¢æ•° <span id="busuanzi_value_site_uv"></span> äººæ¬¡</p><p class="copyright" data-v-8682a75c>Copyright Â© 2024-2025</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"D5aKduv8\",\"column_paper_a transformer-basedadaptiveprototypematchingnetwork.md\":\"B--tmkRd\",\"column_paper_all-pairs consistency learning for weakly supervised semantic segmentation.md\":\"DOzoNQEK\",\"column_paper_cc4s encouraging certainty and consistency in scribble-supervised semantic segmentation.md\":\"BJdHqWXZ\",\"column_paper_class tokens infusion for weakly supervised semantic segmentation.md\":\"MQ5IotcS\",\"column_paper_corrmatch label propagation via correlation matching for semi-supervised semantic segmentation.md\":\"C-Ay97Y-\",\"column_paper_cross-domain few-shot semantic segmentation via doubly matching transformation.md\":\"DP0-0bBL\",\"column_paper_dgss.md\":\"BX1YZhn-\",\"column_paper_dsmf-net dual semantic metric learning fusion network for few-shot aerial image semantic segmentation.md\":\"BwE2wND-\",\"column_paper_high_quality_segmentation.md\":\"BF6oqMqy\",\"column_paper_kill two birds with one stone domain generalization for semantic segmentation via network pruning.md\":\"BcpagYs7\",\"column_paper_knowledge transfer with simulated inter-image erasing for weakly supervised semantic segmentation.md\":\"DdF76l77\",\"column_paper_lgad local and global attention distillation for efficient semantic segmentation.md\":\"BLYPPqDR\",\"column_paper_llmformer large languagemodel for open-vocabulary semantic.md\":\"CmrhycHk\",\"column_paper_learninggeneralizedmedicalimagesegmentationfromdecoupledfeaturequeries.md\":\"BUGoO665\",\"column_paper_night-time_semantic_segmentation.md\":\"FfG0Jyqa\",\"column_paper_pat.md\":\"CvbTl1SQ\",\"column_paper_progressive feature self-reinforcement for weakly supervised semantic segmentation.md\":\"BqorakmV\",\"column_paper_prompting_multi-moda_segmetation.md\":\"Ben9Nl-6\",\"column_paper_relevant intrinsic feature enhancement network for few-shot semantic segmentation.md\":\"DxYEt1BA\",\"column_paper_sed.md\":\"vCH0Lv17\",\"column_paper_sfc shared feature calibration in weakly supervised semantic segmentation.md\":\"B6H0YLzb\",\"column_paper_scaling_upmulti-domain_semantic_segmentation_with_sentence.md\":\"Cw3rfmJ8\",\"column_paper_scribbl_hides_class_promoting_scribble-based_weakly-supervised_semantic_segmentation_with its class label.md\":\"Bh5WiKlk\",\"column_paper_scribble-supervised semantic segmentation with prototype-based feature augmentation.md\":\"D4XCsM9u\",\"column_paper_segment anything.md\":\"Dty7-lcy\",\"column_paper_self-supervised_vit.md\":\"xMu1aKEJ\",\"column_paper_towards open-vocabulary semantic segmentation without semantic labels.md\":\"BPDcB6-k\",\"column_paper_use universal segment embeddings for open-vocabulary image segmentation.md\":\"B2PfEQxd\",\"column_paper_visual studio code latex.md\":\"CzNUGyqb\",\"column_paper_weakclip adapting clip for weakly-supervised semantic.md\":\"o-dpcudj\",\"column_paper_index.md\":\"B30j3khH\",\"column_puruse_index.md\":\"BP9-gop-\",\"column_puruse_template.md\":\"B0U97JJB\",\"column_image_segmentation_20250224-è¯­ä¹‰åˆ†å‰²æ¦‚è¿°.md\":\"mQ6rMlYH\",\"column_image_segmentation_20250312-pytorchæ•™ç¨‹.md\":\"DdEW4ONw\",\"column_image_segmentation_220250224-è¯­ä¹‰åˆ†å‰²ä¸Šé‡‡æ ·.md\":\"BTXAuYMi\",\"column_image_segmentation_fcnæ¨¡å‹è®²è§£.md\":\"CDxGKwtj\",\"column_image_segmentation_index.md\":\"DMQR_je7\",\"column_image_segmentation_segment algrothm.md\":\"e2j2ZgBI\",\"column_image_segmentation_å›¾åƒåˆ†å‰²åŸºç¡€.md\":\"uFajrVas\",\"column_image_segmentation_è¯­ä¹‰åˆ†å‰²åŸºç¡€æ¨¡å‹.md\":\"Cii2xXeN\",\"index.md\":\"RGMUHMKX\",\"markdown-examples.md\":\"DcnrEzY2\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"lab blog\",\"description\":\"A VitePress Site\",\"base\":\"/blog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"darkModeSwitchLabel\":\"æ·±æµ…æ¨¡å¼\",\"logo\":\"/b.jpg\",\"nav\":[{\"text\":\"é¦–é¡µ\",\"link\":\"/\"},{\"text\":\"è®ºæ–‡é˜…è¯»ç¬”è®°\",\"link\":\"/column/Paper/\"},{\"text\":\"è®ºæ–‡ç²¾è¯»ç¬”è®°\",\"link\":\"/column/Puruse/\"},{\"text\":\"å›¾åƒåˆ†å‰²\",\"link\":\"/column/image_segmentation\"}],\"sidebarMenuLabel\":\"ç›®å½•\",\"returnToTopLabel\":\"è¿”å›é¡¶éƒ¨\",\"sidebar\":{\"/column/Paper/\":[{\"text\":\"è®ºæ–‡é˜…è¯»\",\"collapsed\":true,\"items\":[{\"text\":\"latexç¯å¢ƒé…ç½®\",\"link\":\"/column/Paper/Visual Studio Code latex\"},{\"text\":\"Segment Anything\",\"link\":\"/column/Paper/Segment Anything\"},{\"text\":\"é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/DGSS\"},{\"text\":\"åŸºäºåˆ†å±‚ç¼–ç å™¨çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/SED\"},{\"text\":\"è¶…é«˜åˆ†è¾¨ç‡åˆ†å‰²\",\"link\":\"/column/Paper/High_Quality_Segmentation\"},{\"text\":\"å¤œé—´åœºæ™¯è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Night-time_Semantic_Segmentation\"},{\"text\":\"æç¤ºè¯è¿ç§»çš„å°‘æ ·æœ¬åˆ†å‰²\",\"link\":\"/column/Paper/PAT\"},{\"text\":\"å¤šæ¨¡æ€å›¾åƒåˆ†å‰²\",\"link\":\"/column/Paper/Prompting_Multi-Moda_Segmetation\"},{\"text\":\"åŸºäºTransformerçš„è‡ªé€‚åº”åŸå‹åŒ¹é…ç½‘ç»œ\",\"link\":\"/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork\"},{\"text\":\"è·¨é¢†åŸŸå°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Cross-Domain Few-Shot Semantic Segmentation via Doubly Matching Transformation\"},{\"text\":\"ç›¸å…³å†…åœ¨ç‰¹å¾å¢å¼ºçš„å°‘æ ·æœ¬ä¸æ„ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic Segmentation\"},{\"text\":\"åŸºäºæ¶‚é¸¦çš„æ— ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Scribble-Supervised Semantic Segmentation with Prototype-based Feature Augmentation\"},{\"text\":\"é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„æ¸è¿›å¼ç‰¹å¾è‡ªå¢å¼º\",\"link\":\"/column/Paper/Progressive Feature Self-Reinforcement for Weakly Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºè‡ªç›‘ç£Vitçš„è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Self-supervised_ViT\"},{\"text\":\"åŒ»å­¦å›¾åƒåˆ†å‰²ï¼šåŸºäºè§£è€¦ç‰¹å¾æŸ¥è¯¢\",\"link\":\"/column/Paper/LearningGeneralizedMedicalImageSegmentationfromDecoupledFeatureQueries\"},{\"text\":\"åŸºäºè¯­å¥åµŒå…¥çš„å¤šé¢†åŸŸè¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Scaling_UpMulti-domain_Semantic_Segmentation_with_Sentence\"},{\"text\":\"åŸºäºæ¶‚é¸¦çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Scribbl_Hides_Class_Promoting_Scribble-Based_Weakly-Supervised_Semantic_Segmentation_with Its Class Label\"}]},{\"text\":\"è¯­ä¹‰åˆ†å‰²è®ºæ–‡é˜…è¯»\",\"collapsed\":false,\"items\":[{\"text\":\"æ¶‚é¸¦ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç¡®å®šæ€§å’Œä¸€è‡´æ€§(CC4S)\",\"link\":\"/column/Paper/CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºå…³è”åŒ¹é…çš„æ ‡ç­¾ä¼ æ’­åŠç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"column/Paper/CorrMatch Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºLLMçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/LLMFormer Large LanguageModel for Open-Vocabulary Semantic\"},{\"text\":\"æ— éœ€è¯­ä¹‰æ ‡ç­¾çš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²(æ–‡ç« æ™¦æ¶©ï¼Œä¸å»ºè®®é˜…è¯»)\",\"link\":\"/column/Paper/Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels\"},{\"text\":\"é¢å‘å¼€æ”¾è¯æ±‡å›¾åƒåˆ†å‰²çš„é€šç”¨ç‰‡æ®µåµŒå…¥\",\"link\":\"/column/Paper/USE Universal Segment Embeddings for Open-Vocabulary Image Segmentation\"},{\"text\":\"é¢å‘å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²çš„ç±»åˆ«æ ‡è®°æ³¨å…¥\",\"link\":\"/column/Paper/Class Tokens Infusion for Weakly Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºå…¨å±€å’Œå±€éƒ¨æ³¨æ„åŠ›è’¸é¦çš„é«˜æ•ˆè¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/LGAD Local and Global Attention Distillation for Efficient Semantic Segmentation\"},{\"text\":\"åŸºäºåŒé‡è¯­ä¹‰åº¦é‡å­¦ä¹ çš„å°‘æ ·æœ¬èˆªæ‹å›¾åƒè¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/DSMF-Net Dual Semantic Metric Learning Fusion Network for Few-Shot Aerial Image Semantic Segmentation\"},{\"text\":\"åŸºäºå‰ªæçš„é¢†åŸŸæ³›åŒ–è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Kill Two Birds with One Stone Domain Generalization for Semantic Segmentation via Network Pruning\"},{\"text\":\"åŸºäºå…¨å¯¹ä¸€è‡´æ€§å­¦ä¹ çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/All-pairs Consistency Learning for Weakly Supervised Semantic Segmentation\"},{\"text\":\"weakCLIP\",\"link\":\"/column/Paper/WeakCLIP Adapting CLIP for Weakly-Supervised Semantic\"},{\"text\":\"å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ä¸­çš„å…±äº«æƒé‡æ ¡å‡†\",\"link\":\"/column/Paper/SFC Shared Feature Calibration in Weakly Supervised Semantic Segmentation\"},{\"text\":\"åŸºäºæ¨¡æ‹Ÿå›¾åƒé—´æ“¦é™¤çŸ¥è¯†è¿ç§»çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²\",\"link\":\"/column/Paper/Knowledge Transfer with Simulated Inter-Image Erasing for Weakly Supervised Semantic Segmentation\"}]}],\"/column/image_segmentation/\":[{\"text\":\"å›¾åƒåˆ†å‰²åŸç†åŠæ¦‚å¿µ\",\"collapsed\":false,\"items\":[{\"text\":\"è¯­ä¹‰åˆ†å‰²æ¦‚è¿°\",\"link\":\"/column/image_segmentation/20250224-è¯­ä¹‰åˆ†å‰²æ¦‚è¿°\"},{\"text\":\"è¯­ä¹‰åˆ†å‰²ä¸Šé‡‡æ ·\",\"link\":\"/column/image_segmentation/220250224-è¯­ä¹‰åˆ†å‰²ä¸Šé‡‡æ ·\"},{\"text\":\"å›¾åƒåˆ†å‰²åŸºç¡€\",\"link\":\"/column/image_segmentation/å›¾åƒåˆ†å‰²åŸºç¡€\"},{\"text\":\"è¯­ä¹‰åˆ†å‰²åŸºç¡€æ¨¡å‹\",\"link\":\"/column/image_segmentation/è¯­ä¹‰åˆ†å‰²åŸºç¡€æ¨¡å‹\"},{\"text\":\"FCNæ¨¡å‹è®²è§£\",\"link\":\"/column/image_segmentation/FCNæ¨¡å‹è®²è§£\"}]},{\"text\":\"å·ç§¯ç½‘ç»œ\",\"collapsed\":false,\"items\":[{\"text\":\"å·ç§¯ç½‘ç»œ\",\"link\":\"/column/image_segmentation/20250312-Pytorchæ•™ç¨‹\"},{\"text\":\"åˆ†å‰²ç®—æ³•(åŒæµå­è±ªå…„)\",\"link\":\"/column/image_segmentation/segment algrothm\"}]}],\"/column/Puruse/\":[{\"text\":\"è®ºæ–‡ç²¾è¯»\",\"collapsed\":false,\"items\":[{\"text\":\"ç²¾è¯»æ¨¡æ¿\",\"link\":\"/column/Puruse/template\"}]}]},\"lastUpdated\":{\"text\":\"æœ€åæ›´æ–°äº\",\"formatOptions\":{\"dateStyle\":\"full\",\"timeStyle\":\"medium\"}},\"editLink\":{\"pattern\":\"https://github.com/Louaq/blog/tree/main/docs/:path\",\"text\":\"åœ¨githubä¸Šç¼–è¾‘æ­¤é¡µé¢\"},\"outline\":{\"level\":[2,6],\"label\":\"å½“å‰å¤§çº²\"},\"docFooter\":{\"prev\":\"ä¸Šä¸€é¡µ\",\"next\":\"ä¸‹ä¸€é¡µ\"},\"search\":{\"provider\":\"local\"},\"footer\":{\"message\":\"Released under the <a href=\\\"https://mit-license.org/\\\">MIT License.</a> | \\n    æœ¬ç«™è®¿å®¢æ•° <span id=\\\"busuanzi_value_site_uv\\\"></span> äººæ¬¡\",\"copyright\":\"Copyright Â© 2024-2025\"},\"i18nRouting\":true},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>