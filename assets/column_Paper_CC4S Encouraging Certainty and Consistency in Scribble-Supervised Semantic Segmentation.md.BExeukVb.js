import{_ as a,c as t,I as i,j as e,a as o,a8 as r,D as s,o as c}from"./chunks/framework.CLo04awk.js";const _=JSON.parse(`{"title":"CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation","description":"","frontmatter":{"head":[["script",{"charset":"UTF-8","id":"LA_COLLECT","src":"//sdk.51.la/js-sdk-pro.min.js"}],["script",{},"typeof LA !== 'undefined' && LA.init({\\"id\\":\\"3LPXyA1ZitpV3O1s\\",\\"ck\\":\\"3LPXyA1ZitpV3O1s\\",\\"autoTrack\\":true,\\"hashMode\\":true})"]]},"headers":[],"relativePath":"column/Paper/CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation.md","filePath":"column/Paper/CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation.md","lastUpdated":1744089208000}`),l={name:"column/Paper/CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation.md"},d=e("h1",{id:"cc4s-encouraging-certainty-and-consistency-in-scribble-supervised-semantic-segmentation",tabindex:"-1"},[o("CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation "),e("a",{class:"header-anchor",href:"#cc4s-encouraging-certainty-and-consistency-in-scribble-supervised-semantic-segmentation","aria-label":'Permalink to "CC4S Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation"'},"​")],-1),p=r('<p>Peking University、Shandong Universit</p><h2 id="摘要" tabindex="-1">摘要 <a class="header-anchor" href="#摘要" aria-label="Permalink to &quot;摘要&quot;">​</a></h2><p><strong>Deep learning-based</strong> solutions have achieved impressive performance in semantic segmentation but often require large amounts of training data with fine-grained annotations. To alleviate such requisition, a variety of weakly supervised annotation strategies have been proposed, among which scribble supervision is emerging as a popular one due to its user-friendly annotation way. However, the sparsity and diversity of scribble annotations make it nontrivial to train a network to produce deterministic and consistent predictions directly. To address these issues, in this paper we propose holistic solutions involving the design of network structure, loss and training procedure, named <strong>CC4S</strong> to improve Certainty and Consistency for Scribble-Supervised Semantic Segmentation. Specifically, to reduce uncertainty, CC4S embeds a random walkmodule into the network structure to make neural representations uniformly distributed within similar semantic regions, which works together with a soft entropy loss function to force the network to produce deterministic predictions. To encourage consistency, CC4S adopts self-supervision training and imposes the consistency loss on the eigenspace of the probability transition matrix in the random walk module (we named neural eigenspace). Such self-supervision inherits the category-level discriminability from the neural eigenspace and meanwhile helps the network focus on producing consistent predictions for the salient parts and neglect semantically heterogeneous backgrounds. Finally, to further improve the performance, CC4S uses the network predictions as pseudo-labels and retrains the network with an extra color constraint regularizer. From comprehensive experiments, CC4S achieves comparable performance to those from fully supervised methods and shows promising robustness under extreme supervision cases.</p><p>代码： <a href="https://github.com/panzhiyi/CC4S" target="_blank" rel="noreferrer">https://github.com/panzhiyi/CC4S</a>.</p><h2 id="翻译" tabindex="-1">翻译 <a class="header-anchor" href="#翻译" aria-label="Permalink to &quot;翻译&quot;">​</a></h2><p>基于深度学习的方法在语义分割中取得了令人印象深刻的性能，但通常需要大量带有细粒度标注的训练数据。为了减少这种需求，研究者提出了多种弱监督标注策略，其中<strong>涂鸦监督</strong>因其用户友好的标注方式而逐渐流行。然而，涂鸦标注的稀疏性和多样性使得直接训练网络生成确定且一致的预测具有挑战性。为解决这些问题，本文提出了包含网络结构设计、损失函数和训练流程的完整解决方案——CC4S（提升涂鸦监督语义分割确定性与一致性的方法）。具体而言，为降低不确定性，CC4S在网络架构中嵌入<strong>随机游走模块</strong>，使神经表征在相似语义区域内均匀分布。该模块与软熵损失函数共同作用，迫使网络生成确定性预测结果。为增强一致性，CC4S采用自监督训练策略，在随机游走模块的概率转移矩阵特征空间（称为神经特征空间）中施加一致性损失。这种自监督机制既继承了神经特征空间的类别级判别能力，又能促使网络专注于对显著区域生成一致预测，同时忽略语义异构的背景区域。为进一步提升性能，CC4S将网络预测结果作为伪标签，通过引入额外的色彩约束正则化项对网络进行重训练。综合实验表明，CC4S取得了与全监督方法相媲美的性能，在极端监督条件下也展现出良好的鲁棒性。</p><h2 id="研究背景" tabindex="-1">研究背景 <a class="header-anchor" href="#研究背景" aria-label="Permalink to &quot;研究背景&quot;">​</a></h2><p>本文聚焦于涂鸦监督语义分割领域，旨在解决该领域存在的问题，其研究背景主要如下：</p><ul><li><strong>数据标注难题</strong>：基于深度学习的语义分割方法虽表现出色，但需大量细粒度标注的训练数据。以Cityscapes为例，手动生成像素级语义分割标注平均耗时3 - 5分钟，收集大规模标注数据集并非易事。</li><li><strong>弱监督方法兴起</strong>：为缓解数据标注压力，多种弱监督标注策略应运而生，如<strong>图像级监督、边界框监督、点监督和涂鸦监督</strong>等。其中，涂鸦监督因<strong>标注方式友好</strong>且能提供有效监督信息，受到越来越多关注。</li><li><strong>涂鸦监督现存问题</strong>：尽管涂鸦监督语义分割取得了一定进展，但仍存在预测结果不确定和不一致的问题。标注稀疏会导致预测结果不确定，而标注的多样性会使网络难以学习到稳定一致的分割模式，从而产生不一致的预测结果。 基于以上背景，作者提出了CC4S方法，以提高涂鸦监督语义分割的确定性和一致性，减少标注稀疏和多样性带来的影响。</li></ul><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-03-20_16-12-13.png" alt="Snipaste_2025-03-20_16-12-13" loading="lazy"></p><h2 id="研究现状" tabindex="-1">研究现状 <a class="header-anchor" href="#研究现状" aria-label="Permalink to &quot;研究现状&quot;">​</a></h2><blockquote><p>弱监督语义分割：分为四种，图像级监督、边界框监督、点监督和涂鸦监督。图像级监督仅为整个图像提供类别标签，缺乏定位信息；边界框监督仍然缺乏可靠和有效的措施来产生高质量的物体掩膜；点监督通过在每个图像对象内标记带有类别信息的点来完成注释；涂鸦监督是一种用户友好的弱监督形式。</p></blockquote><blockquote><p>涂鸦监督语义分割：现有方法包括利用辅助任务信息、图割算法传播标注、在损失函数引入分割正则化等，但仍存在预测不确定和不一致问题。</p></blockquote><h2 id="提出的模型" tabindex="-1">提出的模型 <a class="header-anchor" href="#提出的模型" aria-label="Permalink to &quot;提出的模型&quot;">​</a></h2><p>本文提出了一种名为<strong>CC4S（Encouraging Certainty and Consistency in Scribble-Supervised Semantic Segmentation）<strong>的模型，旨在解决涂鸦监督语义分割任务中预测结果的</strong>不确定性和不一致性</strong>问题</p><p>核心网络包含两个模块：</p><ul><li><strong>ResNet骨干网络</strong>：用于提取图像的特征。</li><li><strong>相似度测量模块（SMM）</strong>：计算每两个神经元之间的转移概率，形成转移矩阵。</li></ul><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-03-20_16-24-44.png" alt="Snipaste_2025-03-20_16-24-44" loading="lazy"></p><h4 id="减少神经表示的不确定性" tabindex="-1">减少神经表示的不确定性 <a class="header-anchor" href="#减少神经表示的不确定性" aria-label="Permalink to &quot;减少神经表示的不确定性&quot;">​</a></h4><h4 id="神经特征空间的自监督学习" tabindex="-1">神经特征空间的自监督学习 <a class="header-anchor" href="#神经特征空间的自监督学习" aria-label="Permalink to &quot;神经特征空间的自监督学习&quot;">​</a></h4><h4 id="带有颜色约束的伪标签再训练" tabindex="-1">带有颜色约束的伪标签再训练 <a class="header-anchor" href="#带有颜色约束的伪标签再训练" aria-label="Permalink to &quot;带有颜色约束的伪标签再训练&quot;">​</a></h4><h2 id="实验-compared-with-sota" tabindex="-1">实验（Compared with SOTA） <a class="header-anchor" href="#实验-compared-with-sota" aria-label="Permalink to &quot;实验（Compared with SOTA）&quot;">​</a></h2><blockquote><p>数据集：Pascal VOC 2012 and Pascal Context</p><p>比较的方法：Scribblesup, RAWKS, NCL, GraphNet，KCL, BPG, URSS, PSI, SPML, A2GNN, DBFNet, PCE , CCL , TEL and CDL</p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-03-20_16-30-25.png" alt="Snipaste_2025-03-20_16-30-25" loading="lazy"></p><h2 id="实验-ablation-experiments" tabindex="-1">实验（Ablation Experiments）🥇 <a class="header-anchor" href="#实验-ablation-experiments" aria-label="Permalink to &quot;实验（Ablation Experiments）:1st_place_medal:&quot;">​</a></h2><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-03-20_16-29-58.png" alt="Snipaste_2025-03-20_16-29-58" loading="lazy"></p><h2 id="结论" tabindex="-1">结论 <a class="header-anchor" href="#结论" aria-label="Permalink to &quot;结论&quot;">​</a></h2><p>作者通过研究得出以下结论：</p><ol><li>仅使用涂鸦注释进行语义分割会导致预测结果<strong>不确定和不一致</strong>。为此，提出了两种策略，即减少神经表示的不确定性以产生可靠结果，以及在神经特征空间进行自监督以保证输出的一致性。</li><li>结合<strong>伪标签再训练</strong>，该方法达到了最先进的性能，甚至可与全标签监督方法相媲美，且整个过程无需额外信息或注释准备要求。</li><li>大量的消融实验和中间可视化验证了所提解决方案的有效性。</li><li>该方法在涂鸦<strong>随机丢弃或按比例缩小</strong>的困难情况下也能表现良好，具有较强的鲁棒性。</li></ol>',29);function h(g,u,m,S,b,C){const n=s("ArticleMetadata");return c(),t("div",null,[d,i(n),p])}const f=a(l,[["render",h]]);export{_ as __pageData,f as default};
