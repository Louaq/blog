import{_ as a,c as i,I as n,j as e,a as s,a8 as o,D as r,o as l}from"./chunks/framework.CLo04awk.js";const P=JSON.parse(`{"title":"Pixel-Wise Reclassification with Prototypes for Enhancing Weakly Supervised Semantic Segmentation","description":"","frontmatter":{"head":[["script",{"charset":"UTF-8","id":"LA_COLLECT","src":"//sdk.51.la/js-sdk-pro.min.js"}],["script",{},"typeof LA !== 'undefined' && LA.init({\\"id\\":\\"3LPXyA1ZitpV3O1s\\",\\"ck\\":\\"3LPXyA1ZitpV3O1s\\",\\"autoTrack\\":true,\\"hashMode\\":true})"]]},"headers":[],"relativePath":"column/Paper/Pixel-Wise Reclassification with Prototypes for Enhancing Weakly Supervised Semantic Segmentation.md","filePath":"column/Paper/Pixel-Wise Reclassification with Prototypes for Enhancing Weakly Supervised Semantic Segmentation.md","lastUpdated":1745324497000}`),c={name:"column/Paper/Pixel-Wise Reclassification with Prototypes for Enhancing Weakly Supervised Semantic Segmentation.md"},g=e("h1",{id:"pixel-wise-reclassification-with-prototypes-for-enhancing-weakly-supervised-semantic-segmentation",tabindex:"-1"},[s("Pixel-Wise Reclassification with Prototypes for Enhancing Weakly Supervised Semantic Segmentation "),e("a",{class:"header-anchor",href:"#pixel-wise-reclassification-with-prototypes-for-enhancing-weakly-supervised-semantic-segmentation","aria-label":'Permalink to "Pixel-Wise Reclassification with Prototypes for Enhancing Weakly Supervised Semantic Segmentation"'},"​")],-1),p=o('<p>天津大学</p><div class="tip custom-block"><p class="custom-block-title">TIP</p><p>启发、参考文献</p></div><h2 id="摘要" tabindex="-1">摘要 <a class="header-anchor" href="#摘要" aria-label="Permalink to &quot;摘要&quot;">​</a></h2><p>Refining the seed region to obtain finely annotated <strong>pseudo masks</strong> for training a segmentation model is a crucial step in the multi-stage weakly supervised semantic segmentation (WSSS) framework. One of the most popular refinement methods, IRN, extends seed regions towards the edges in the image. However, we observed that, due to the lack of guidance from semantic information, IRN’s refinement may lead the generation of partially erroneous refinement directions. To address this issue, we leverage prototypes to recover the overlooked category semantic information in the refinement stage. We propose a prototype-based pseudo mask reclassification post-processing (PtReCl) to correct misclassified pixels in the pseudo masks, generating refined pseudo masks with more accurate coverage. Experimental evaluations demonstrate that our post-processing approach brings improvements in both pseudo mask quality and segmentation results on PASCAL VOC and MS COCO datasets, achieving state-of-the-art performance on VOC.</p><h2 id="翻译" tabindex="-1">翻译 <a class="header-anchor" href="#翻译" aria-label="Permalink to &quot;翻译&quot;">​</a></h2><p>在多阶段弱监督语义分割(WSSS)框架中，对种子区域进行细化以获得精细标注的<strong>伪掩膜</strong>用于训练分割模型是至关重要的一步。最流行的细化方法之一是IRN，它将种子区域向图像的边缘扩展。然而，我们观察到，由于缺乏语义信息的指导，IRN的细化可能导致部分错误的细化方向的产生。为了解决这个问题，我们利用原型来恢复细化阶段中被忽略的类别语义信息。我们提出了一种基于原型的伪掩码重分类后处理(PtReCl)来纠正伪掩膜中的错误分类像素，生成更精确覆盖的精细伪掩膜。实验评估表明，我们的后处理方法改善了<strong>PASCAL VOC</strong>和<strong>MS COCO</strong>数据集的伪掩码质量和分割结果，实现了最先进的VOC性能。</p><h2 id="研究背景" tabindex="-1">研究背景 <a class="header-anchor" href="#研究背景" aria-label="Permalink to &quot;研究背景&quot;">​</a></h2><p>本文聚焦于弱监督语义分割（WSSS）领域，旨在解决现有方法在生成伪掩码时存在的问题，具体研究背景如下：</p><ul><li><strong>WSSS的目标与流程</strong>：WSSS旨在利用图像级标注数据集完成像素级分类任务，以降低数据标注成本。当前主流方法遵循三阶段流程，其中生成高质量伪掩码对最终分割模型的性能至关重要。</li><li><strong>现有方法的局限性</strong>：最常用的细化方法IRN在细化种子区域时，因缺乏语义信息指导，可能导致部分错误的细化方向，产生大量错误的伪掩码。</li><li><strong>原型学习的潜力</strong>：近年来，研究发现原型学习可助力语义分割，它能从少量类样本中归纳特定类别的特征，实现特征的像素级分类，还能保留更多非学习参数以预测多样特征。</li><li><strong>本文的研究动机</strong>：基于上述背景，作者提出基于<strong>原型的伪掩码重分类后处理方法</strong>（<strong>PtReCl</strong>），利用原型的类别区分性恢复伪掩码中误分类的像素，以提高伪掩码质量和分割性能。</li></ul><h2 id="研究现状" tabindex="-1">研究现状 <a class="header-anchor" href="#研究现状" aria-label="Permalink to &quot;研究现状&quot;">​</a></h2><ul><li><strong>多阶段WSSS框架</strong>：主流方法分三步，先训练分类模型生成种子区域，再用细化方法生成伪掩码，最后用伪掩码训练全监督语义分割模型。</li><li><strong>CAM方法</strong>：解决CAM作为种子区域时前景覆盖不足问题，如采用擦除、对抗学习、利用ViT上下文建模等方法。</li><li><strong>细化方法</strong>：主要分为利用显著性检测和随机游走与语义亲和两类，部分方法还借助Transformer中的注意力矩阵。</li><li><strong>原型学习</strong>：在语义分割中，部分研究将原型用于对比学习或自监督学习，部分用原型替换分类器结构。</li></ul><h2 id="提出的模型" tabindex="-1">提出的模型 <a class="header-anchor" href="#提出的模型" aria-label="Permalink to &quot;提出的模型&quot;">​</a></h2><p>多阶段弱监督语义分割框架中，细化种子区域以获得精细注释的伪掩码是训练分割模型的关键步骤。现有流行的细化方法IRN在细化过程中缺乏语义信息的引导，可能导致部分错误的细化方向。为解决这一问题，作者提出了<strong>PtReCl</strong>方法。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-13_19-21-22.png" alt="Snipaste_2025-04-13_19-21-22" loading="lazy"></p><h3 id="模型流程" tabindex="-1">模型流程 <a class="header-anchor" href="#模型流程" aria-label="Permalink to &quot;模型流程&quot;">​</a></h3><ol><li><strong>种子区域获取</strong>：利用原始的类激活映射（Class Activation Maps, CAM）方法获取种子区域。训练分类模型后，丢弃分类器中的全局平均池化（Global Average Pooling, GAP）层，直接在原始特征图上进行预测，忽略负预测分数并归一化生成CAM。</li><li><strong>伪掩码生成</strong>：使用IRN方法对种子区域进行细化，生成伪掩码。</li><li><strong>伪掩码恢复网络</strong>：参考Deeplab的结构构建伪分割网络，以伪掩码作为像素级注释，通过空洞空间金字塔池化层（Atrous Spatial Pyramid Pooling, ASPP）提取图像特征并获得像素级预测结果。引入标签条件策略（Label Conditioning strategy），根据图像级类别注释保留相关通道，丢弃无关通道，以减轻无关通道对后续原型准确性的影响。</li><li><strong>前景 - 背景原型获取</strong>：依次遍历训练集图像，使用骨干网络提取特征。对于伪掩码中每个类别的前景区域，收集其对应特征到前景特征集；对于非该类别区域，收集其对应特征到背景特征集。使用余弦距离作为度量，采用K - means聚类方法为每个类别获取多个前景和背景原型。</li><li><strong>多原型像素级重新分类</strong>：使用伪掩码恢复网络的骨干提取图像特征，利用特定类别的前景和背景原型对像素特征的语义信息进行重新分类。计算每个位置与前景 - 背景原型的余弦相似度，对相似度进行降序排序，选择前m个距离参与像素分类计算，生成像素级重新分类图。</li><li><strong>重新细化</strong>：将重新分类图替换IRN中的CAM，再次使用IRN进行细化，增强其边缘信息，得到后处理的伪掩码。</li><li><strong>全监督语义分割</strong>：使用后处理的伪掩码训练全监督语义分割模型，如DeeplabV2和UperNet - Swin。</li></ol><h3 id="模型贡献" tabindex="-1">模型贡献 <a class="header-anchor" href="#模型贡献" aria-label="Permalink to &quot;模型贡献&quot;">​</a></h3><ul><li><strong>解决分类错误</strong>：提出PtReCl后处理方法，利用原型的类别区分性，通过前景 - 背景特征恢复伪掩码中误分类的像素。</li><li><strong>多原型分类</strong>：设计多原型像素级分类方法，利用伪分割网络重建伪掩码并通过聚类方法获取原型，缓解不同类别有效原型数量的差异，获得准确的重新分类图。</li><li><strong>实验验证</strong>：在PASCAL VOC和MS COCO数据集上进行了广泛实验，结果表明PtReCl方法能有效提高伪掩码的准确性，从而提升分割性能，在VOC数据集上取得了最先进的结果。</li></ul><h2 id="实验-compared-with-sota" tabindex="-1">实验（Compared with SOTA） <a class="header-anchor" href="#实验-compared-with-sota" aria-label="Permalink to &quot;实验（Compared with SOTA）&quot;">​</a></h2><p>数据集：<strong>PASCAL VOC 2012</strong>、<strong>MS COCO 2014</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-13_19-25-57.png" alt="Snipaste_2025-04-13_19-25-57" loading="lazy"></p><ul><li><strong>伪掩码增强</strong>：与一些先进的WSSS方法相比，经PtReCl处理后的伪掩码在VOC上提升了8.4%，在COCO上提升了3.4%，在VOC上取得了最佳性能，在COCO上也有出色表现。</li><li><strong>分割性能提升</strong>：在使用DeepLab作为全监督分割方法的VOC实验中，PtReCl在两种常用预训练ResNet101骨干网络下均取得了最先进的结果。在基于Transformer的分割方法中，使用UperNet - Swin作为骨干网络时，PtReCl也达到了最先进的性能。在COCO上，尽管受噪声影响，PtReCl仍优于除AMN和LPCAM外的其他方法，与基线IRN相比，在验证集上提升了2.2%。</li></ul><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-13_19-26-36.png" alt="Snipaste_2025-04-13_19-26-36" loading="lazy"></p><h2 id="实验-ablation-experiments" tabindex="-1">实验（Ablation Experiments）🥇 <a class="header-anchor" href="#实验-ablation-experiments" aria-label="Permalink to &quot;实验（Ablation Experiments）:1st_place_medal:&quot;">​</a></h2><ul><li><strong>有效性验证</strong>：PtReCl在VOC和COCO上分别将伪掩码的mIoU提高了8.4%和3.4%。通过对比不使用原型和使用不同数量原型时的像素级分类结果，验证了多原型像素级分类方法的有效性，当M设为[10, 15, 20]时，重分类图的mIoU最高可达70%。</li><li><strong>原型数量影响</strong>：研究了调整每个类别的原型数量K（范围从2到30）对重分类效果的影响。重分类图的mIoU随原型数量增加先上升后稳定，最终将类中心数量设为20。在10到30的范围内，重分类图的mIoU波动仅在1%以内，表明在合理范围内改变原型数量对重分类效果影响不大。</li></ul><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-13_19-28-20.png" alt="Snipaste_2025-04-13_19-28-20" loading="lazy"></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-13_19-28-28.png" alt="Snipaste_2025-04-13_19-28-28" loading="lazy"></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/Snipaste_2025-04-13_19-28-33.png" alt="Snipaste_2025-04-13_19-28-33" loading="lazy"></p><h2 id="结论" tabindex="-1">结论 <a class="header-anchor" href="#结论" aria-label="Permalink to &quot;结论&quot;">​</a></h2><p>作者指出广泛使用的<strong>WSSS</strong>方法IRN在细化策略上存在局限，它在不考虑特定像素级语义信息的情况下将种子区域向图像边缘扩展，导致部分错误细化。基于现有的WSSS三阶段框架，作者引入了基于原型的重分类后处理方法，以纠正伪掩码中的像素错误分类，得到更精确的后处理伪掩码。 通过在<strong>VOC和COCO</strong>数据集上的大量实验，结果表明该后处理阶段有效提高了伪掩码的质量和分割模型的性能，在VOC数据集上取得了最先进的成果。</p>',30);function d(h,m,u,S,_,C){const t=r("ArticleMetadata");return l(),i("div",null,[g,n(t),p])}const y=a(c,[["render",d]]);export{P as __pageData,y as default};
