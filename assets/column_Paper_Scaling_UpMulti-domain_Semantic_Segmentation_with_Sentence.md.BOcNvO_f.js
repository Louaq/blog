import{_ as e,c as a,o as t,a8 as n}from"./chunks/framework.CLo04awk.js";const g=JSON.parse(`{"title":"Scaling Up Multi-domain Semantic Segmentation with Sentence Embeddings","description":"","frontmatter":{"head":[["script",{"charset":"UTF-8","id":"LA_COLLECT","src":"//sdk.51.la/js-sdk-pro.min.js"}],["script",{},"typeof LA !== 'undefined' && LA.init({\\"id\\":\\"3LPXyA1ZitpV3O1s\\",\\"ck\\":\\"3LPXyA1ZitpV3O1s\\",\\"autoTrack\\":true,\\"hashMode\\":true})"]]},"headers":[],"relativePath":"column/Paper/Scaling_UpMulti-domain_Semantic_Segmentation_with_Sentence.md","filePath":"column/Paper/Scaling_UpMulti-domain_Semantic_Segmentation_with_Sentence.md","lastUpdated":1742201599000}`),i={name:"column/Paper/Scaling_UpMulti-domain_Semantic_Segmentation_with_Sentence.md"},o=n('<h1 id="scaling-up-multi-domain-semantic-segmentation-with-sentence-embeddings" tabindex="-1">Scaling Up Multi-domain Semantic Segmentation with Sentence Embeddings <a class="header-anchor" href="#scaling-up-multi-domain-semantic-segmentation-with-sentence-embeddings" aria-label="Permalink to &quot;Scaling Up Multi-domain Semantic Segmentation with Sentence Embeddings&quot;">â€‹</a></h1><h2 id="æ‘˜è¦" tabindex="-1">æ‘˜è¦ <a class="header-anchor" href="#æ‘˜è¦" aria-label="Permalink to &quot;æ‘˜è¦&quot;">â€‹</a></h2><p>The <strong>state-of-the-art semantic segmentation methods</strong> have achieved impressive performance on predefined close-set individual datasets, but their generalization to zero-shot domains and unseen categories is limited. Labeling a large-scale dataset is challenging and expensive, Training a robust semantic segmentation model on multi-domains has drawn much attention. However, inconsistent taxonomies hinder the naive merging of current publicly available annotations. To address this, we propose a simple solution to scale up the multi-domain semantic segmentation dataset with less human effort.We replace each class label with a sentence embedding, which is a vector-valued embedding of a sentence describing the class. This approach enables the merging of multiple datasets from different domains, each with varying class labels and semantics. We merged publicly available noisy and weak annotations with the most finely annotated data, over 2 million images, which enables training a model that achieves performance equal to that of state-of-the-art supervised methods on 7 benchmark datasets, despite not using any images therefrom. Instead of manually tuning a consistent label space, we utilized a vector-valued embedding of short paragraphs to describe the classes. By fine-tuning the model on standard semantic segmentation datasets, we also achieve a significant improvement over the state-of-the-art supervised segmentation on NYUD-V2 (Silberman et al., in: European conference on computer vision, Springer, pp 746â€“760, 2012) and PASCAL-context (Everingham et al. in Int J Comput Visi 111(1):98â€“136, 2015) at 60% and 65% mIoU, respectively. Our method can segment unseen labels based on the closeness of language embeddings, showing strong generalization to unseen image domains and labels. Additionally, it enables impressive performance improvements in some adaptation applications, such as depth estimation and instance segmentation. Code is available at <a href="https://github.com/YvanYin/SSIW" target="_blank" rel="noreferrer">https://github.com/YvanYin/SSIW</a>.</p><h2 id="ç¿»è¯‘" tabindex="-1">ç¿»è¯‘ <a class="header-anchor" href="#ç¿»è¯‘" aria-label="Permalink to &quot;ç¿»è¯‘&quot;">â€‹</a></h2><p>å½“å‰æœ€å…ˆè¿›çš„è¯­ä¹‰åˆ†å‰²æ–¹æ³•åœ¨é¢„è®¾çš„å°é—­æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åœ¨é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰é¢†åŸŸå’Œæœªè§è¿‡ç±»åˆ«ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚ç”±äºå¤§è§„æ¨¡æ•°æ®æ ‡æ³¨æ—¢å›°éš¾åˆæ˜‚è´µï¼Œå¼€å‘è·¨é¢†åŸŸé€šç”¨çš„é²æ£’è¯­ä¹‰åˆ†å‰²æ¨¡å‹æˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚ç„¶è€Œï¼Œç°æœ‰å…¬å¼€æ•°æ®é›†çš„ä¸åŒåˆ†ç±»æ ‡å‡†é˜»ç¢äº†å®ƒä»¬çš„ç›´æ¥èåˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆæ‰©å±•å¤šé¢†åŸŸè¯­ä¹‰åˆ†å‰²æ•°æ®é›†çš„æ–¹æ³•ï¼šç”¨æ–‡æœ¬åµŒå…¥ï¼ˆtext embeddingï¼‰æ›¿ä»£ä¼ ç»Ÿç±»åˆ«æ ‡ç­¾ï¼Œè¿™ç§å‘é‡åŒ–çš„è¯­ä¹‰è¡¨ç¤ºå¯ä»¥èåˆä¸åŒé¢†åŸŸã€ä¸åŒæ ‡ç­¾ä½“ç³»çš„æ•°æ®ã€‚é€šè¿‡æ•´åˆåŒ…å« 200 ä¸‡å¼ å›¾åƒçš„ç²¾ç»†æ ‡æ³¨æ•°æ®ä¸å…¬å¼€çš„å¸¦å™ªå£°å¼±æ ‡æ³¨æ•°æ®ï¼Œæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹åœ¨ 7 ä¸ªä¸»æµæµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†ç›‘ç£å­¦ä¹ çš„é¡¶å°–æ°´å¹³ï¼Œå°½ç®¡å®Œå…¨æ²¡æœ‰ä½¿ç”¨è¿™äº›æµ‹è¯•é›†çš„è®­ç»ƒå›¾åƒã€‚ä¸äººå·¥ç»Ÿä¸€æ ‡ç­¾ä½“ç³»ä¸åŒï¼Œæˆ‘ä»¬é€šè¿‡è¯­è¨€æ¨¡å‹ç”ŸæˆçŸ­æ–‡æœ¬æè¿°æ¥è¡¨å¾ç±»åˆ«è¯­ä¹‰ã€‚åœ¨æ ‡å‡†æ•°æ®é›†å¾®è°ƒåï¼Œæ¨¡å‹åœ¨ NYUD-V2 (Silberman et al., 2012) å’Œ PASCAL-context (Everingham et al., 2015) ä¸Šåˆ†åˆ«å–å¾— 60% å’Œ 65% çš„å¹³å‡äº¤å¹¶æ¯”ï¼ˆmIoUï¼‰ï¼Œæ˜¾è‘—è¶…è¶Šç°æœ‰ç›‘ç£æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦å®ç°æœªè§è¿‡æ ‡ç­¾çš„åˆ†å‰²ï¼Œå±•ç°å‡ºä¼˜å¼‚çš„è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶åœ¨æ·±åº¦ä¼°è®¡ã€å®ä¾‹åˆ†å‰²ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡ã€‚ä»£ç å·²å¼€æºï¼š<a href="https://github.com/YvanYin/SSIW" target="_blank" rel="noreferrer">https://github.com/YvanYin/SSIW</a></p><h2 id="ç ”ç©¶èƒŒæ™¯" tabindex="-1">ç ”ç©¶èƒŒæ™¯ <a class="header-anchor" href="#ç ”ç©¶èƒŒæ™¯" aria-label="Permalink to &quot;ç ”ç©¶èƒŒæ™¯&quot;">â€‹</a></h2><h2 id="ç ”ç©¶ç°çŠ¶" tabindex="-1">ç ”ç©¶ç°çŠ¶ <a class="header-anchor" href="#ç ”ç©¶ç°çŠ¶" aria-label="Permalink to &quot;ç ”ç©¶ç°çŠ¶&quot;">â€‹</a></h2><h2 id="æå‡ºçš„æ¨¡å‹" tabindex="-1">æå‡ºçš„æ¨¡å‹ <a class="header-anchor" href="#æå‡ºçš„æ¨¡å‹" aria-label="Permalink to &quot;æå‡ºçš„æ¨¡å‹&quot;">â€‹</a></h2><h2 id="å®éªŒ-compared-with-sota" tabindex="-1">å®éªŒï¼ˆCompared with SOTAï¼‰ <a class="header-anchor" href="#å®éªŒ-compared-with-sota" aria-label="Permalink to &quot;å®éªŒï¼ˆCompared with SOTAï¼‰&quot;">â€‹</a></h2><h2 id="å®éªŒ-ablation-experiments" tabindex="-1">å®éªŒï¼ˆAblation Experimentsï¼‰ğŸ¥‡ <a class="header-anchor" href="#å®éªŒ-ablation-experiments" aria-label="Permalink to &quot;å®éªŒï¼ˆAblation Experimentsï¼‰:1st_place_medal:&quot;">â€‹</a></h2><h2 id="ç»“è®º" tabindex="-1">ç»“è®º <a class="header-anchor" href="#ç»“è®º" aria-label="Permalink to &quot;ç»“è®º&quot;">â€‹</a></h2>',11),s=[o];function r(l,d,m,c,h,p){return t(),a("div",null,s)}const b=e(i,[["render",r]]);export{g as __pageData,b as default};
