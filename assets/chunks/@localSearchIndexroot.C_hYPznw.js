const e='{"documentCount":94,"nextId":94,"documentIds":{"0":"/blog/api-examples.html#runtime-api-examples","1":"/blog/api-examples.html#results","2":"/blog/api-examples.html#theme-data","3":"/blog/api-examples.html#page-data","4":"/blog/api-examples.html#page-frontmatter","5":"/blog/api-examples.html#more","6":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#a-transformer-based-adaptive-prototype-matching-network-for-few-shot-semantic-segmentation","7":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#南京信息工程大学、青海师范大学、澳门大学、中国科学院","8":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#摘要","9":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#翻译","10":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#研究背景","11":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#研究现状","12":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#提出的模型","13":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#实验-compared-with-the-state-of-the-art-models-and-ablation-experiments","14":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#comparison-with-the-state-of-the-arts","15":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#ablation-experiments","16":"/blog/column/Paper/A Transformer-basedAdaptivePrototypeMatchingNetwork.html#结论","17":"/blog/column/Paper/DGSS.html#stronger-fewer-superior-harnessing-vision-foundation-models-for-domain-generalized-semantic-segmentation-dgss","18":"/blog/column/Paper/DGSS.html#中国科学技术大学-上海人工智能实验室","19":"/blog/column/Paper/High_Quality_Segmentation.html#high-quality-segmentation-for-ultra-high-resolution-images","20":"/blog/column/Paper/High_Quality_Segmentation.html#香港中文大学-adobe-等","21":"/blog/column/Paper/Night-time_Semantic_Segmentation.html#disentangle-then-parse-night-time-semantic-segmentation-with-illumination-disentanglement","22":"/blog/column/Paper/PAT.html#prompt-and-transfer-dynamic-class-aware-enhancement-for-few-shot-segmentation","23":"/blog/column/Paper/PAT.html#中科院","24":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#prompting-multi-modal-image-segmentation-with-semantic-grouping","25":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#university-of-chinese-academy-of-sciences","26":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#摘要","27":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#翻译","28":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#研究背景","29":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#研究现状","30":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#提出的模型","31":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#实验过程-与sota方法的对比","32":"/blog/column/Paper/Prompting_Multi-Moda_Segmetation.html#实验过程-消融实验","33":"/blog/column/Paper/SED.html#sed-a-simple-encoder-decoder-for-open-vocabulary-semantic-segmentation","34":"/blog/column/Paper/SED.html#天津大学-重庆大学等","35":"/blog/column/Paper/Visual Studio Code latex.html#前言","36":"/blog/column/Paper/Visual Studio Code latex.html#_1-tex-live-下载与安装","37":"/blog/column/Paper/Visual Studio Code latex.html#_2-vscode下载与安装","38":"/blog/column/Paper/Visual Studio Code latex.html#_3-中文语言环境配置","39":"/blog/column/Paper/Visual Studio Code latex.html#_4-latex的支持插件-latex-workshop安装","40":"/blog/column/Paper/Visual Studio Code latex.html#_5-打开latex环境设置页面","41":"/blog/column/Paper/Visual Studio Code latex.html#_6-latex环境的代码配置","42":"/blog/column/Paper/Visual Studio Code latex.html#_6-1-latex配置代码展示","43":"/blog/column/Paper/Visual Studio Code latex.html#_6-2-latex配置代码解读","44":"/blog/column/Paper/Visual Studio Code latex.html#_7-tex文件编译","45":"/blog/column/Paper/Visual Studio Code latex.html#_7-1-tex测试文件下载","46":"/blog/column/Paper/Visual Studio Code latex.html#_7-2-tex-测试文件编译","47":"/blog/column/Paper/Visual Studio Code latex.html#_8-sumatrapdf-安装设置-可选","48":"/blog/column/Paper/Visual Studio Code latex.html#_8-1-sumatrapdf下载与安装","49":"/blog/column/Paper/Visual Studio Code latex.html#_8-2-使用sumatrapdf查看的代码配置","50":"/blog/column/Paper/Visual Studio Code latex.html#_8-2-1-代码展示","51":"/blog/column/Paper/Visual Studio Code latex.html#_8-2-2-代码解读","52":"/blog/column/Paper/Visual Studio Code latex.html#_9-sumatrapdf-的使用","53":"/blog/column/Paper/Visual Studio Code latex.html#_10-pdf-内部查看与外部查看的切换","54":"/blog/column/Paper/Visual Studio Code latex.html#_11-个人完整配置","55":"/blog/column/Paper/#论文阅读笔记","56":"/blog/column/Paper/Segment Anything.html#segment-anything","57":"/blog/column/Paper/Segment Anything.html#meta-ai","58":"/blog/column/Pytorch/#pytorch笔记","59":"/blog/column/deepLearning/#深度学习笔记","60":"/blog/column/image_segmentation/20250224-语义分割概述.html#_1-什么是语义分割","61":"/blog/column/image_segmentation/20250224-语义分割概述.html#_2-模型的输入和输出","62":"/blog/column/image_segmentation/20250224-语义分割概述.html#_3-常见的分割模型","63":"/blog/column/image_segmentation/20250224-语义分割概述.html#_4-语义分割的思路","64":"/blog/column/image_segmentation/20250224-语义分割概述.html#_5-评价指标","65":"/blog/column/image_segmentation/220250224-语义分割上采样.html#上采样","66":"/blog/column/image_segmentation/#图像分割学习笔记","67":"/blog/column/image_segmentation/图像分割基础.html#_1-基本概念","68":"/blog/column/image_segmentation/图像分割基础.html#_1-1-什么是图像分割","69":"/blog/column/image_segmentation/图像分割基础.html#_1-2-图像分割的应用场景","70":"/blog/column/image_segmentation/图像分割基础.html#_1-3-图像分割的前景和背景","71":"/blog/column/image_segmentation/图像分割基础.html#_1-4-图像分割的三个层次","72":"/blog/column/image_segmentation/图像分割基础.html#_2-经典数据集","73":"/blog/column/image_segmentation/图像分割基础.html#_2-1-pascal数据集","74":"/blog/column/image_segmentation/图像分割基础.html#_2-1cityscape-用于自动驾驶场景","75":"/blog/column/image_segmentation/图像分割基础.html#_2-3-coco数据集","76":"/blog/column/image_segmentation/图像分割基础.html#_3-评估指标和优化目标","77":"/blog/column/image_segmentation/图像分割基础.html#_3-1-语义分割评估指标","78":"/blog/column/image_segmentation/图像分割基础.html#_3-2-语义分割常用优化目标","79":"/blog/column/image_segmentation/图像分割基础.html#_4-上采样","80":"/blog/column/image_segmentation/图像分割基础.html#_4-1-图像分割网络的两个模块","81":"/blog/column/image_segmentation/图像分割基础.html#_4-2-上采样实现方法-插值法","82":"/blog/column/image_segmentation/图像分割基础.html#_4-3-典型的图像分割网络","83":"/blog/column/image_segmentation/语义分割基础模型.html#fcn","84":"/blog/column/image_segmentation/语义分割基础模型.html#fcn基本原理","85":"/blog/column/image_segmentation/语义分割基础模型.html#fcn细节","86":"/blog/column/image_segmentation/语义分割基础模型.html#fcn结果","87":"/blog/column/image_segmentation/语义分割基础模型.html#segnet","88":"/blog/column/image_segmentation/语义分割基础模型.html#segnet的基本原理","89":"/blog/column/image_segmentation/语义分割基础模型.html#unet","90":"/blog/markdown-examples.html#markdown-extension-examples","91":"/blog/markdown-examples.html#syntax-highlighting","92":"/blog/markdown-examples.html#custom-containers","93":"/blog/markdown-examples.html#more"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[3,1,52],"1":[1,3,1],"2":[2,4,2],"3":[2,4,2],"4":[2,4,2],"5":[1,3,11],"6":[12,1,1],"7":[5,12,1],"8":[2,12,103],"9":[2,12,33],"10":[2,12,34],"11":[2,12,16],"12":[2,12,73],"13":[12,12,1],"14":[6,24,6],"15":[2,24,66],"16":[2,12,24],"17":[15,1,1],"18":[2,15,259],"19":[7,1,1],"20":[3,1,341],"21":[10,1,284],"22":[11,1,1],"23":[1,11,379],"24":[8,1,1],"25":[5,8,1],"26":[2,8,133],"27":[2,8,33],"28":[2,8,25],"29":[2,8,15],"30":[2,8,64],"31":[3,8,10],"32":[3,8,43],"33":[10,1,1],"34":[2,10,332],"35":[1,1,63],"36":[4,1,132],"37":[2,1,30],"38":[2,1,33],"39":[4,1,34],"40":[2,1,34],"41":[2,1,1],"42":[3,2,105],"43":[3,2,257],"44":[2,1,1],"45":[3,2,75],"46":[4,2,88],"47":[5,1,31],"48":[3,5,11],"49":[3,5,1],"50":[4,6,45],"51":[3,6,105],"52":[3,1,39],"53":[3,1,9],"54":[2,1,158],"55":[1,1,2],"56":[2,1,1],"57":[2,2,214],"58":[1,1,2],"59":[1,1,3],"60":[2,1,28],"61":[2,1,28],"62":[2,1,11],"63":[2,1,7],"64":[2,1,29],"65":[1,1,94],"66":[1,1,1],"67":[2,1,1],"68":[2,2,2],"69":[3,2,4],"70":[3,2,2],"71":[3,2,1],"72":[2,1,1],"73":[3,2,1],"74":[4,2,1],"75":[3,2,1],"76":[2,1,1],"77":[3,2,1],"78":[3,2,1],"79":[2,1,1],"80":[3,2,1],"81":[4,2,1],"82":[3,2,1],"83":[1,1,1],"84":[1,1,1],"85":[1,1,1],"86":[1,1,1],"87":[1,1,1],"88":[1,1,1],"89":[1,1,1],"90":[3,1,14],"91":[2,3,27],"92":[2,3,21],"93":[1,3,11]},"averageFieldLength":[3.0531914893617023,3.9468085106382986,43.882978723404236],"storedFields":{"0":{"title":"Runtime API Examples","titles":[]},"1":{"title":"Results","titles":["Runtime API Examples"]},"2":{"title":"Theme Data","titles":["Runtime API Examples","Results"]},"3":{"title":"Page Data","titles":["Runtime API Examples","Results"]},"4":{"title":"Page Frontmatter","titles":["Runtime API Examples","Results"]},"5":{"title":"More","titles":["Runtime API Examples"]},"6":{"title":"A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation","titles":[]},"7":{"title":"南京信息工程大学、青海师范大学、澳门大学、中国科学院  💯","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"8":{"title":"摘要：","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"9":{"title":"翻译：","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"10":{"title":"研究背景：","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"11":{"title":"研究现状：","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"12":{"title":"提出的模型：","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"13":{"title":"实验（compared with the state-of-the-art models and ablation experiments）","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"14":{"title":"Comparison with the State-of-the-Arts","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation","实验（compared with the state-of-the-art models and ablation experiments）"]},"15":{"title":"ablation experiments","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation","实验（compared with the state-of-the-art models and ablation experiments）"]},"16":{"title":"结论：","titles":["A Transformer-based Adaptive Prototype Matching Network for Few-Shot Semantic Segmentation"]},"17":{"title":"Stronger, Fewer, &amp; Superior Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation（DGSS）","titles":[]},"18":{"title":"中国科学技术大学，上海人工智能实验室","titles":["Stronger, Fewer, &amp; Superior Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation（DGSS）"]},"19":{"title":"High Quality Segmentation for Ultra High-resolution Images","titles":[]},"20":{"title":"香港中文大学  Adobe 等","titles":[]},"21":{"title":"Disentangle then Parse: Night-time Semantic Segmentation with Illumination Disentanglement","titles":[]},"22":{"title":"Prompt-and-Transfer：Dynamic Class-Aware Enhancement for Few-Shot Segmentation","titles":[]},"23":{"title":"中科院","titles":["Prompt-and-Transfer：Dynamic Class-Aware Enhancement for Few-Shot Segmentation"]},"24":{"title":"Prompting Multi-Modal Image Segmentation with Semantic Grouping","titles":[]},"25":{"title":"University of Chinese Academy of Sciences","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"26":{"title":"摘要：","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"27":{"title":"翻译：","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"28":{"title":"研究背景：","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"29":{"title":"研究现状：","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"30":{"title":"提出的模型：","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"31":{"title":"实验过程（与SOTA方法的对比）：","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"32":{"title":"实验过程（消融实验）：","titles":["Prompting Multi-Modal Image Segmentation with Semantic Grouping"]},"33":{"title":"SED:A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation","titles":[]},"34":{"title":"天津大学，重庆大学等","titles":["SED:A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation"]},"35":{"title":"前言","titles":[]},"36":{"title":"1 TeX Live 下载与安装","titles":[]},"37":{"title":"2 vscode下载与安装","titles":[]},"38":{"title":"3 中文语言环境配置","titles":[]},"39":{"title":"4 LaTeX的支持插件 LaTeX Workshop安装","titles":[]},"40":{"title":"5 打开LaTeX环境设置页面","titles":[]},"41":{"title":"6 LaTeX环境的代码配置","titles":[]},"42":{"title":"6.1 LaTeX配置代码展示","titles":["6 LaTeX环境的代码配置"]},"43":{"title":"6.2 LaTeX配置代码解读","titles":["6 LaTeX环境的代码配置"]},"44":{"title":"7 tex文件编译","titles":[]},"45":{"title":"7.1 tex测试文件下载","titles":["7 tex文件编译"]},"46":{"title":"7.2 tex 测试文件编译","titles":["7 tex文件编译"]},"47":{"title":"8 SumatraPDF 安装设置（可选）","titles":[]},"48":{"title":"8.1 SumatraPDF下载与安装","titles":["8 SumatraPDF 安装设置（可选）"]},"49":{"title":"8.2 使用SumatraPDF查看的代码配置","titles":["8 SumatraPDF 安装设置（可选）"]},"50":{"title":"8.2.1 代码展示","titles":["8 SumatraPDF 安装设置（可选）","8.2 使用SumatraPDF查看的代码配置"]},"51":{"title":"8.2.2 代码解读","titles":["8 SumatraPDF 安装设置（可选）","8.2 使用SumatraPDF查看的代码配置"]},"52":{"title":"9 SumatraPDF 的使用","titles":[]},"53":{"title":"10 pdf 内部查看与外部查看的切换","titles":[]},"54":{"title":"11 个人完整配置","titles":[]},"55":{"title":"论文阅读笔记","titles":[]},"56":{"title":"Segment Anything","titles":[]},"57":{"title":"Meta AI","titles":["Segment Anything"]},"58":{"title":"Pytorch笔记","titles":[]},"59":{"title":"深度学习笔记","titles":[]},"60":{"title":"1.什么是语义分割","titles":[]},"61":{"title":"2.模型的输入和输出","titles":[]},"62":{"title":"3.常见的分割模型","titles":[]},"63":{"title":"4.语义分割的思路","titles":[]},"64":{"title":"5.评价指标","titles":[]},"65":{"title":"上采样","titles":[]},"66":{"title":"图像分割学习笔记","titles":[]},"67":{"title":"1. 基本概念","titles":[]},"68":{"title":"1.1 什么是图像分割","titles":["1. 基本概念"]},"69":{"title":"1.2 图像分割的应用场景","titles":["1. 基本概念"]},"70":{"title":"1.3 图像分割的前景和背景","titles":["1. 基本概念"]},"71":{"title":"1.4 图像分割的三个层次","titles":["1. 基本概念"]},"72":{"title":"2.经典数据集","titles":[]},"73":{"title":"2.1 PASCAL数据集","titles":["2.经典数据集"]},"74":{"title":"2.1Cityscape(用于自动驾驶场景)","titles":["2.经典数据集"]},"75":{"title":"2.3 COCO数据集","titles":["2.经典数据集"]},"76":{"title":"3. 评估指标和优化目标","titles":[]},"77":{"title":"3.1 语义分割评估指标","titles":["3. 评估指标和优化目标"]},"78":{"title":"3.2 语义分割常用优化目标","titles":["3. 评估指标和优化目标"]},"79":{"title":"4. 上采样","titles":[]},"80":{"title":"4.1 图像分割网络的两个模块","titles":["4. 上采样"]},"81":{"title":"4.2 上采样实现方法--插值法","titles":["4. 上采样"]},"82":{"title":"4.3 典型的图像分割网络","titles":["4. 上采样"]},"83":{"title":"FCN","titles":[]},"84":{"title":"FCN基本原理","titles":["FCN"]},"85":{"title":"FCN细节","titles":["FCN"]},"86":{"title":"FCN结果","titles":["FCN"]},"87":{"title":"SegNet","titles":[]},"88":{"title":"SegNet的基本原理","titles":["SegNet"]},"89":{"title":"UNet","titles":[]},"90":{"title":"Markdown Extension Examples","titles":[]},"91":{"title":"Syntax Highlighting","titles":["Markdown Extension Examples"]},"92":{"title":"Custom Containers","titles":["Markdown Extension Examples"]},"93":{"title":"More","titles":["Markdown Extension Examples"]}},"dirtCount":0,"index":[["```",{"2":{"91":1}}],["典型的图像分割网络",{"0":{"82":1}}],["插值法",{"0":{"81":1}}],["插值等操作",{"2":{"65":1}}],["经典数据集",{"0":{"72":1},"1":{"73":1,"74":1,"75":1}}],["经过对方同意",{"2":{"35":1}}],["什么是图像分割",{"0":{"68":1}}],["什么是语义分割",{"0":{"60":1}}],["−2∗padding",{"2":{"65":2}}],["∗stride",{"2":{"65":2}}],["添加偏置",{"2":{"65":1}}],["添加到path",{"2":{"37":1}}],["高宽都增加padding",{"2":{"65":1}}],["高宽都增加2",{"2":{"65":1}}],["高斯抑制的作用",{"2":{"23":1}}],["补",{"2":{"65":1}}],["情况下的反卷积则体现为",{"2":{"65":1}}],["kerner",{"2":{"65":1}}],["kernel",{"2":{"65":1}}],["kernelsize−stride",{"2":{"65":1}}],["kernelsize=",{"2":{"65":2}}],["kernelsize",{"2":{"65":1}}],["keybinding",{"2":{"42":3,"43":1,"54":1}}],["key",{"2":{"21":1,"23":1,"34":1}}],["卷积核元素之间的间距",{"2":{"65":1}}],["卷积核的大小",{"2":{"65":1}}],["卷积核大小",{"2":{"65":1}}],["卷积产生的通道数",{"2":{"65":1}}],["卷积步长",{"2":{"65":2}}],["卷积变压器架构",{"2":{"15":1}}],["小特征图",{"2":{"65":1}}],["反卷积是一种特殊的正向卷积",{"2":{"65":1}}],["反池化",{"2":{"65":1}}],["反向同步测试",{"2":{"46":1}}],["映射回一个较大的",{"2":{"65":1}}],["表示两个区域的交并比",{"2":{"64":1}}],["表明该编码器能灵活地为不同的新类别生成类别感知特征",{"2":{"23":1}}],["表明从支持和查询图像中提取特定类别的线索能显著增强类别感知能力",{"2":{"23":1}}],["表明引入的模块有效解决了固有偏差",{"2":{"15":1}}],["概念一致",{"2":{"64":1}}],["像素分类准确率",{"2":{"64":1}}],["像素分类精度",{"2":{"64":1}}],["像素级",{"2":{"60":1}}],["评价指标",{"0":{"64":1}}],["评估指标和优化目标",{"0":{"76":1},"1":{"77":1,"78":1}}],["评估设置",{"2":{"20":1}}],["评估并利用视觉基础模型",{"2":{"18":1}}],["评估并应用了多种视觉基础模型",{"2":{"18":1}}],["遍历一些小区域",{"2":{"63":1}}],["滑动窗口的思路可以概括如下",{"2":{"63":1}}],["事实上",{"2":{"61":1}}],["回顾一下之前的全连接网络的分类模型",{"2":{"61":1}}],["那么实际上模型的输出为w×d×n",{"2":{"61":1}}],["那么输出是什么呢",{"2":{"61":1}}],["那么可以点击上图左下角的",{"2":{"36":1}}],["很显然",{"2":{"61":1}}],["很多博主也只是贴上了配置代码",{"2":{"35":1}}],["又要区分出同个类别中的不同实例",{"2":{"60":1}}],["简单的说",{"2":{"60":1}}],["区域为不规则的物体边界",{"2":{"64":1}}],["区域级",{"2":{"60":1}}],["区别如下",{"2":{"43":1}}],["检测",{"2":{"60":1}}],["检查安装是否正常",{"2":{"36":1}}],["图片级",{"2":{"60":1}}],["图像分割网络的两个模块",{"0":{"80":1}}],["图像分割的三个层次",{"0":{"71":1}}],["图像分割的前景和背景",{"0":{"70":1}}],["图像分割的应用场景",{"0":{"69":1}}],["图像分割学习笔记",{"0":{"66":1}}],["图像分割领域存在多种任务",{"2":{"57":1}}],["图像分割任务",{"2":{"57":1}}],["图像分辨率为2048x1024",{"2":{"21":1}}],["图像分辨率范围2k",{"2":{"20":1}}],["图像分辨率越来越高",{"2":{"20":1}}],["图像编码器学习率多乘以一个",{"2":{"34":1}}],["图像裁剪和级联模型",{"2":{"20":1}}],["所谓的分割",{"2":{"60":1}}],["所以得到的输出",{"2":{"61":1}}],["所以",{"2":{"61":1}}],["所以生成pdf时",{"2":{"43":1}}],["所以传统的语义分割取得了飞速进步",{"2":{"10":1}}],["专门的交互式分割方法通常会优于sam",{"2":{"57":1}}],["放大",{"2":{"57":1}}],["数量和质量远超现有数据集",{"2":{"57":1}}],["数据创新",{"2":{"57":1}}],["数据驱动方法的局限",{"2":{"23":1}}],["数据集的创新",{"2":{"57":1}}],["数据集大小和训练计算量的增加而提升",{"2":{"57":1}}],["数据集贡献",{"2":{"21":1}}],["数据集和对比方法选择",{"2":{"20":1}}],["数据集",{"2":{"14":1,"21":1,"31":1,"34":1}}],["含超10亿掩码",{"2":{"57":1}}],["支持灵活提示",{"2":{"57":1}}],["支持和查询语义的重要性",{"2":{"23":1}}],["边缘检测",{"2":{"57":1}}],["尚无网络规模的数据源",{"2":{"57":1}}],["许多问题缺乏充足的训练数据",{"2":{"57":1}}],["甚至在某些情况下表现更好",{"2":{"57":1}}],["甚至被其他应用程序修改",{"2":{"43":1}}],["通常与之前的完全监督方法相当",{"2":{"57":1}}],["通过提示工程实现零样本迁移到下游分割任务",{"2":{"57":1}}],["通过提示工程可适应多种任务和数据分布",{"2":{"57":2}}],["通过使用我们高效的模型进行数据收集",{"2":{"57":1}}],["通过调整其与",{"2":{"47":1}}],["通过网址",{"2":{"36":1}}],["通过对特定模态的类令牌进行分组",{"2":{"32":1}}],["通过在解码器的早期层次中剔除不存在的类别",{"2":{"34":1}}],["通过在提示学习中引入显式语义分组",{"2":{"32":1}}],["通过在模型执行的三个阶段进行策略性和高效交互",{"2":{"10":1}}],["通过引入特定于模态的类标记",{"2":{"30":1}}],["通过冻结预训练的基础模型",{"2":{"30":1}}],["通过共享提示参数聚合不同模态的类特征表示",{"2":{"27":1}}],["通过聚类同类模态特征",{"2":{"27":1}}],["通过语义分组机制学习模态专属提示",{"2":{"27":1}}],["通过精确地将图像中的类别特定语义迁移到提示中",{"2":{"23":1}}],["通过观察到光照成分可以作为一些语义模糊区域的线索",{"2":{"21":1}}],["通过可学习令牌对特征图进行实例级细化",{"2":{"18":1}}],["通过消融实验",{"2":{"32":1}}],["通过消融实验分析rein各组件的有效性",{"2":{"18":1}}],["通过消融实验评估不同的dcm组件",{"2":{"15":1}}],["通过广泛的实验验证",{"2":{"18":1}}],["通过减少可训练的参数",{"2":{"18":1}}],["通过利用更强大的预训练模型和更少的可训练参数",{"2":{"18":1}}],["通过修改模型采用不同的注意力机制",{"2":{"15":1}}],["通过与其他方法在计算量和准确性方面进行对比实验",{"2":{"15":1}}],["通过优化查询特征和类别原型生成基于语义相似度的掩码来识别目标类别",{"2":{"12":1}}],["通过增强查询特征的语义和空间感知能力",{"2":{"9":1}}],["发现它的零样本表现非常优秀",{"2":{"57":1}}],["阅读论文",{"2":{"55":1}}],["阅读功能的同时很轻量",{"2":{"47":1}}],["论文阅读笔记",{"0":{"55":1}}],["非常感谢",{"2":{"54":1}}],["给笔者一点小小的激励",{"2":{"54":1}}],["希望您能够不吝点赞",{"2":{"54":1}}],["希望能够对大家有所帮助",{"2":{"35":1}}],["另",{"2":{"54":1}}],["另一方面",{"2":{"28":1}}],["另一方面下游任务标注数据往往匮乏",{"2":{"27":1}}],["争取以后学得更扎实再编写这些文字",{"2":{"54":1}}],["欢迎您在评论区批评指正",{"2":{"54":1}}],["预测目标的轮廓",{"2":{"68":1}}],["预览编译好的pdf文件",{"2":{"54":1}}],["预训练模型进行全局微调",{"2":{"27":1}}],["预训练骨干网络有固有偏差",{"2":{"10":1}}],["默认",{"2":{"54":1}}],["默认会放大一些",{"2":{"47":1}}],["个人完整配置",{"0":{"54":1}}],["个性化安装",{"2":{"36":1}}],["或双击",{"2":{"54":1}}],["或",{"2":{"53":1}}],["或者复制以下代码进行文档的简单编译测试",{"2":{"45":1}}],["或者在前一页面",{"2":{"36":1}}],["内部查看与外部查看的切换",{"0":{"53":1}}],["内置",{"2":{"51":1}}],["时操作步骤相同",{"2":{"52":1}}],["时构建项目",{"2":{"43":1}}],["变为了在",{"2":{"52":1}}],["变量有两种",{"2":{"43":1}}],["原本内嵌输出的",{"2":{"52":1}}],["原始的nightcity是最大的夜间语义分割数据集",{"2":{"21":1}}],["修改如下图",{"2":{"51":1}}],["路径修改",{"2":{"51":1}}],["扩展名为",{"2":{"51":1}}],["扩展实验",{"2":{"20":1}}],["是一张张的图片",{"2":{"61":1}}],["是语义分割和实例分割的结合",{"2":{"60":1}}],["是语义分割或全像素语义分割的子类型",{"2":{"60":1}}],["是触发synctex的扩展名为",{"2":{"54":1}}],["是当触发synctex被触发时",{"2":{"51":1}}],["是生成pdf文件的绝对路径的占位符",{"2":{"51":1,"54":1}}],["是行号",{"2":{"51":1,"54":1}}],["是用于生成pdf文件的绝对路径的占位符",{"2":{"51":1,"54":1}}],["转置卷积",{"2":{"65":2}}],["转发到外部查看器时要执行的命令",{"2":{"51":1}}],["转到",{"2":{"40":1}}],["请注意中间为",{"2":{"51":1}}],["请记得在最后一句",{"2":{"42":1}}],["正向同步和反向同步",{"2":{"52":1}}],["正向同步测试",{"2":{"46":1}}],["正常情况下只需更改磁盘盘符即可",{"2":{"51":1}}],["引用查看",{"2":{"51":1}}],["引入了对齐诱导的跨模态提示器",{"2":{"32":1}}],["引入显式语义分组机制到提示学习中",{"2":{"30":1}}],["引入额外的语言信息有助于生成更强大的提示",{"2":{"23":1}}],["引入额外类别语义",{"2":{"23":1}}],["引入背景提示",{"2":{"23":1}}],["引入前景提示",{"2":{"23":1}}],["引入跨模态语言信息初始化提示",{"2":{"23":1}}],["引入跨模态的语言信息来初始化每个任务的提示",{"2":{"23":1}}],["引入光照感知解析器",{"2":{"21":2}}],["引入隐函数",{"2":{"20":1}}],["引入深度卷积网络",{"2":{"20":1}}],["引入基于卷积transformer架构的多尺度局部感知调制transformer进行多尺度特征提取",{"2":{"12":1}}],["链接",{"2":{"51":1,"54":1}}],["命令上的",{"2":{"51":1}}],["让您进行查看",{"2":{"50":1}}],["记得更改安装路径并记住",{"2":{"48":1}}],["记得修改安装路径",{"2":{"37":1}}],["查看效果图",{"2":{"52":1}}],["查看",{"2":{"51":1}}],["查看器查看",{"2":{"51":1}}],["查看器",{"2":{"51":1}}],["查看器设置",{"2":{"42":1}}],["查看具有相同的效果",{"2":{"47":1}}],["达到与内置",{"2":{"47":1}}],["要更加让人舒服一些",{"2":{"47":1}}],["要注意的是",{"2":{"36":1}}],["外部查看器了",{"2":{"52":1}}],["外部查看器展示出来的",{"2":{"47":1}}],["外部查看器的优势是能够看到",{"2":{"47":1}}],["跳转到对应代码",{"2":{"46":1}}],["鼠标左键双击或ctrl+鼠标左键单击",{"2":{"46":1}}],["按ctrl+alt+v",{"2":{"52":1}}],["按ctrl+alt+j",{"2":{"46":1}}],["按win",{"2":{"36":1}}],["快捷键",{"2":{"46":1}}],["左侧工具栏",{"2":{"46":1}}],["左边为设置false情况",{"2":{"43":1}}],["相反",{"2":{"46":1}}],["相关代码和数据集可以在https",{"2":{"21":1}}],["相关代码可以在https",{"2":{"20":1}}],["符号",{"2":{"46":1}}],["符号时",{"2":{"46":1}}],["符合word设定",{"2":{"45":1}}],["√",{"2":{"46":1}}],["选中想要跳转行",{"2":{"46":1}}],["选中需要跳转的代码所在行",{"2":{"46":1}}],["选中",{"2":{"46":2}}],["选中tex文件的代码页面",{"2":{"46":1}}],["选择第一个latex",{"2":{"39":1}}],["选择第一个chinese",{"2":{"38":1}}],["选择3次",{"2":{"23":1}}],["选择panopticfcn和entity",{"2":{"20":1}}],["选择mgmatting作为掩码引导抠图方法",{"2":{"20":1}}],["选择cascadepsp作为超高清图像的主要对比方法",{"2":{"20":1}}],["选择clip",{"2":{"18":1}}],["选择方法",{"2":{"18":1}}],["开始编译文件",{"2":{"46":1}}],["开放词汇语义分割",{"2":{"34":1}}],["开放词汇语义分割旨在将像素划分到一个开放类别集中的不同语义组",{"2":{"34":1}}],["世界",{"2":{"45":1}}],["你好",{"2":{"45":1}}],["\\t",{"2":{"45":2}}],["zhihu",{"2":{"54":1}}],["zhuanlan",{"2":{"54":1}}],["zihao",{"2":{"45":1}}],["zero",{"2":{"23":1,"57":3}}],["功能是否比较完整",{"2":{"45":1}}],["比如区分一个像素是猫还是狗",{"2":{"60":1}}],["比如区分一张图片是猫还是狗",{"2":{"60":1}}],["比如检测一个区域是猫还是狗",{"2":{"60":1}}],["比如编译目录和编译参考文献时",{"2":{"43":1}}],["比较便捷",{"2":{"40":1}}],["比较麻烦",{"2":{"40":1,"43":1}}],["清除辅助文件",{"2":{"43":1}}],["速度快",{"2":{"43":1}}],["速度提升",{"2":{"34":1}}],["允许用户使用操作系统字体来代替",{"2":{"43":1}}],["标准字体进行替换",{"2":{"43":1}}],["标记",{"2":{"46":1}}],["标记能够编译文档",{"2":{"43":1}}],["标记使用",{"2":{"43":1}}],["编译工具和命令",{"2":{"54":1}}],["编译出错时设置是否弹出气泡设置",{"2":{"54":1}}],["编译成功",{"2":{"46":1}}],["编译bixtex文件",{"2":{"45":1}}],["编译",{"2":{"43":2}}],["编译模式与",{"2":{"43":1}}],["编译器中能够看到的编译顺序",{"2":{"43":1}}],["编译链的存在是为了更方便编译",{"2":{"43":1}}],["编译链中被使用的编译命令",{"2":{"43":1}}],["编译链自动构建",{"2":{"43":1}}],["则为鼠标左键双击",{"2":{"46":1}}],["则无法进行编译",{"2":{"46":1}}],["则会导致编译不出完整结果甚至编译失败",{"2":{"43":1}}],["则该拓展能够从使用的宏包中自动提取命令和环境",{"2":{"43":1}}],["则安装正常",{"2":{"36":1}}],["菜单中多了两个选项",{"2":{"43":1}}],["右侧就会跳转到相应行",{"2":{"46":1}}],["右边为设置true情况",{"2":{"43":1}}],["右键菜单",{"2":{"54":1}}],["右键以管理员身份运行",{"2":{"36":1}}],["右键",{"2":{"36":1}}],["新的",{"2":{"43":1}}],["此功能不受官方支持",{"2":{"54":3}}],["此属性必须是字符串数组",{"2":{"54":1}}],["此路径为",{"2":{"51":1}}],["此命令作用于",{"2":{"51":1}}],["此参数为下文进行pdf内部查看和外部查看进行切换的关键参数",{"2":{"51":1}}],["此处就不再赘述",{"2":{"52":1}}],["此处需要您根据自身情况进行路径更改",{"2":{"51":1}}],["此处设置为auto",{"2":{"51":1}}],["此处选择",{"2":{"51":1}}],["此处快捷键的选择为上文设置",{"2":{"46":1}}],["此处笔者使用的为double",{"2":{"43":1}}],["此处为默认配置",{"2":{"43":1}}],["此菜单默认状态下停用",{"2":{"43":1}}],["此项笔者设置为never",{"2":{"43":1}}],["此前探索了多种图像表示解纠缠方法",{"2":{"21":1}}],["此前采用无监督域适应技术将白天知识迁移到夜间",{"2":{"21":1}}],["项目",{"2":{"43":1,"57":1}}],["第一个",{"2":{"43":1}}],["下面给出具体的计算公式",{"2":{"64":1}}],["下面进行代码注释解读",{"2":{"43":1}}],["下文配置需要使用其路径",{"2":{"48":1}}],["下文会进行提及",{"2":{"43":1}}],["下图展示两者区别",{"2":{"43":1}}],["下载步骤如图",{"2":{"45":1}}],["下载",{"2":{"36":1,"45":1}}],["下载页面",{"2":{"36":1}}],["下载与安装",{"0":{"36":1}}],["切记",{"2":{"42":1}}],["否则就会报错",{"2":{"42":1}}],["否则后期手动添加比较麻烦",{"2":{"36":1}}],["都不清除辅助文件",{"2":{"43":1}}],["都不一样",{"2":{"35":1}}],["都选择清除辅助文件",{"2":{"43":1}}],["都需要加上英文状态下的",{"2":{"42":1}}],["除了代码块儿最后一句",{"2":{"42":1}}],[">",{"2":{"42":4,"43":4,"54":4}}],["配置",{"2":{"54":1}}],["配置代码如下",{"2":{"42":1}}],["配备pat提出的动态类别感知编码器后",{"2":{"23":1}}],["jsexport",{"2":{"91":1}}],["js",{"2":{"50":1,"51":1,"54":1}}],["json界面设置",{"2":{"53":1}}],["json",{"2":{"40":1,"42":2,"50":1,"52":1}}],["just",{"2":{"18":1}}],["处打开",{"2":{"40":1}}],["处理注意力偏差",{"2":{"16":1}}],["即要将输入扩大的倍数",{"2":{"65":1}}],["即要对所有目标都检测出来",{"2":{"60":1}}],["即某一个像素属于哪一类物体",{"2":{"60":1}}],["即从",{"2":{"46":1}}],["即从代码定位到",{"2":{"46":1}}],["即从代码定位到编译出来的",{"2":{"43":1}}],["即从编译出的",{"2":{"43":1}}],["即此命令设置是否将编译文档的选项出现在鼠标右键的菜单中",{"2":{"43":1}}],["即变量设置为false",{"2":{"43":1}}],["即变为",{"2":{"42":1}}],["即需编写者手动编译文档",{"2":{"43":1}}],["即当检测到代码被更改时就自动编译tex文件",{"2":{"43":1}}],["即什么时候自动进行代码的编译",{"2":{"43":1}}],["即可使用",{"2":{"52":1}}],["即可完成",{"2":{"42":1}}],["即可",{"2":{"39":1}}],["即使加入额外的网络来提供空间信息",{"2":{"34":1}}],["即使从低分辨率细化到高分辨率",{"2":{"20":1}}],["页面定位到代码相应位置",{"2":{"46":1}}],["页面相应位置",{"2":{"46":1}}],["页面",{"2":{"46":1}}],["页面右下角跳出如下弹窗",{"2":{"39":1}}],["页面和笔者所用图片中展示的页面有略微不同",{"2":{"35":1}}],["显示如下",{"2":{"38":1}}],["显著提升泛化性",{"2":{"18":1}}],["完成中文环境配置",{"2":{"38":1}}],["完成分割任务",{"2":{"34":1}}],["自行选择",{"2":{"37":1}}],["自带的",{"2":{"36":1}}],["点进去之后就可以进行下载了",{"2":{"37":1}}],["点击编辑页面任意位置来选中",{"2":{"52":1}}],["点击选中",{"2":{"46":1}}],["点击下图",{"2":{"40":1}}],["点击设置",{"2":{"40":1}}],["点击设置图标",{"2":{"40":1}}],["点击页面右下角跳出窗口中的",{"2":{"38":1}}],["点击拓展图标",{"2":{"38":1,"39":1}}],["点击关闭即可",{"2":{"36":1}}],["点击",{"2":{"36":1,"38":1,"39":2}}],["点击红框圈画链接进行",{"2":{"36":1}}],["点击图示红框圈画位置进入随机的镜像网站",{"2":{"36":1}}],["官网下载",{"2":{"37":1,"48":1}}],["若使用笔者的代码",{"2":{"46":1}}],["若未选中",{"2":{"46":1}}],["若因网络原因无法连接到github导致无法下载",{"2":{"45":1}}],["若无特殊需求",{"2":{"43":1}}],["若不想了解",{"2":{"39":1}}],["若您感觉此文写得勉强还行",{"2":{"54":1}}],["若您想要更改",{"2":{"46":1}}],["若您想要了解新版本增加的功能",{"2":{"39":1}}],["若您不想要配置外部查看器以及了解内部查看和外部查看之间切换操作",{"2":{"42":1}}],["若您的",{"2":{"35":1}}],["若在安装完该插件之后在",{"2":{"39":1}}],["若输出了一些版本信息",{"2":{"36":1}}],["⑩",{"2":{"36":1}}],["几分钟左右",{"2":{"36":1}}],["⑨",{"2":{"36":1}}],["根据",{"2":{"42":1}}],["根据个人想法可以选择是否在开始菜单文件夹创建",{"2":{"37":1}}],["根据您的需要进行相应的更改",{"2":{"36":1}}],["根据显式分组的语义相似性",{"2":{"30":1}}],["⑧",{"2":{"36":1}}],["安装包不到",{"2":{"47":1}}],["安装设置",{"0":{"47":1},"1":{"48":1,"49":1,"50":1,"51":1}}],["安装好之后",{"2":{"37":1}}],["安装",{"2":{"36":1}}],["故而选择xelatex",{"2":{"46":1}}],["故而您可以根据自己的需要更改编译链顺序",{"2":{"43":1}}],["故而笔者使用了onfailed",{"2":{"43":1}}],["故而笔者设置均设置为false",{"2":{"43":1}}],["故而取消",{"2":{"36":1}}],["故此项笔者设置为true",{"2":{"43":1}}],["故笔者写下了此文",{"2":{"35":1}}],["需要更多的努力来改进",{"2":{"57":1}}],["需要清除辅助文件了",{"2":{"43":1}}],["需要进行路径的更改",{"2":{"36":1}}],["需要额外的计算资源",{"2":{"20":1}}],["出现如下图页面",{"2":{"52":1}}],["出现编译好的",{"2":{"46":1}}],["出现下图后",{"2":{"36":1}}],["出现基于两阶段和单阶段框架的方法",{"2":{"34":1}}],["基本概念",{"0":{"67":1},"1":{"68":1,"69":1,"70":1,"71":1}}],["基本更改",{"2":{"36":1}}],["基础模型",{"2":{"57":1}}],["基础模型发展",{"2":{"57":1}}],["基于大规模网络数据集预训练的大语言模型展现出强大的零样本和少样本泛化能力",{"2":{"57":1}}],["基于",{"2":{"34":1}}],["基于分层编码器的代价图",{"2":{"34":1}}],["基于层次编码器的成本图生成使用层次化的骨干网络",{"2":{"34":1}}],["基于层次编码器的成本图生成和逐渐融合的解码器",{"2":{"34":1}}],["基于聚合的融合易忽略模态内传播",{"2":{"28":1}}],["基于对齐的融合因信息交换弱",{"2":{"28":1}}],["基于全卷积网络",{"2":{"21":1}}],["基于传播的方法面临计算和内存限制",{"2":{"20":1}}],["基于人类从粗略到精细地逐步区分物体的方式",{"2":{"20":1}}],["基于利用更强预训练模型和更少可训练参数实现更优泛化能力的动机",{"2":{"18":1}}],["基于此",{"2":{"18":1}}],["基于像素匹配的方法建立支持像素和查询像素的密集关联",{"2":{"11":1}}],["基于原型的方法用原型代表目标类信息进行匹配预测",{"2":{"11":1}}],["基于度量学习的fss主要分为基于原型和基于像素匹配两类方法",{"2":{"11":1}}],["基于上述问题",{"2":{"10":1}}],["⑦",{"2":{"36":1}}],["⑥",{"2":{"36":1,"46":1}}],["⑤",{"2":{"36":1,"38":1,"46":1,"52":1}}],["打开编译出的",{"2":{"52":1}}],["打开测试文件所在文件夹",{"2":{"46":1}}],["打开latex环境设置页面",{"0":{"40":1}}],["打开拓展",{"2":{"38":1,"39":1}}],["打开命令行窗口",{"2":{"36":1}}],["打开运行",{"2":{"36":1}}],["打开",{"2":{"36":1,"37":1}}],["资源管理器",{"2":{"36":1}}],["找到",{"2":{"36":1}}],["找到下载好的压缩包",{"2":{"36":1}}],["找了很多资料",{"2":{"35":1}}],["④",{"2":{"36":1,"38":1,"39":1,"40":1,"46":1,"52":1}}],["直到下载速度在您的可接受范围内即可",{"2":{"36":1}}],["直接上图",{"2":{"35":1}}],["③",{"2":{"36":1,"37":1,"38":1,"39":1,"40":1,"46":1,"52":1}}],["②",{"2":{"36":1,"37":1,"38":1,"39":1,"40":1,"46":1,"52":1}}],["进行分屏",{"2":{"52":1}}],["进行文件内容查看",{"2":{"46":1}}],["进行解压",{"2":{"45":1}}],["进行编译的速度比",{"2":{"43":1}}],["进行查看",{"2":{"39":1}}],["进行",{"2":{"38":1}}],["进行等待即可",{"2":{"36":1}}],["进行安装",{"2":{"36":1,"38":1,"39":1}}],["进行重新点击",{"2":{"36":1}}],["进行超高清图像评估",{"2":{"20":1}}],["进入设置页面",{"2":{"40":1}}],["进入代码设置页面",{"2":{"40":1}}],["进入镜像列表",{"2":{"36":1}}],["进入",{"2":{"36":1}}],["①",{"2":{"36":1,"37":1,"38":1,"39":1,"40":1,"46":1,"52":1}}],["接口与参数说明",{"2":{"65":1}}],["接下来是",{"2":{"36":1}}],["接着就会出现下图",{"2":{"36":1}}],["接着",{"2":{"9":1}}],["系统是",{"2":{"36":1}}],["系列等方法不断发展",{"2":{"20":1}}],["文中如果出现错误的地方",{"2":{"54":1}}],["文档时的默认编译链",{"2":{"43":1}}],["文档编译有时需要用到辅助文件",{"2":{"43":1}}],["文件清理",{"2":{"54":1}}],["文件同步到外部查看器时latex",{"2":{"51":1}}],["文件路径",{"2":{"51":2}}],["文件内后",{"2":{"52":1}}],["文件内",{"2":{"50":1}}],["文件在查看器中的目录",{"2":{"47":1}}],["文件的完整展现效果",{"2":{"47":1}}],["文件可以从",{"2":{"45":1}}],["文件指定位置跳转到",{"2":{"43":1}}],["文件没有正常更新的情况",{"2":{"43":1}}],["文件修改后进行编译时",{"2":{"43":1}}],["文件也会有些字体没有嵌入",{"2":{"43":1}}],["文件默认嵌入所有字体",{"2":{"43":1}}],["文件仍需要根文件完整路径",{"2":{"43":1}}],["文件相应位置",{"2":{"43":1}}],["文件编写规则",{"2":{"42":1}}],["文件中任意的代码",{"2":{"46":2}}],["文件中相应代码所在位置",{"2":{"43":1}}],["文件中",{"2":{"42":1}}],["文件",{"2":{"36":1,"40":1,"43":1,"45":1,"46":2,"52":2}}],["文末有完整的个人配置代码",{"2":{"35":1}}],["文本到掩码任务的探索还不够成熟",{"2":{"57":1}}],["文本到掩码任务待完善",{"2":{"57":1}}],["文本代价图",{"2":{"34":1}}],["文本编码器冻结",{"2":{"34":1}}],["文本数据集中学习",{"2":{"34":1}}],["文本对数据中学习视觉特征",{"2":{"34":1}}],["文本成本图",{"2":{"34":1}}],["只不过相比较目标检测的矩形框",{"2":{"64":1}}],["只是提醒该插件已经更新到了8",{"2":{"39":1}}],["只需将此变量设置为true即可恢复菜单",{"2":{"43":1}}],["只需要更改下图框选出的部分即可",{"2":{"36":1}}],["只需按照图片中所指向图标进行配置即可",{"2":{"35":1}}],["只训练图像编码器和解码器",{"2":{"34":1}}],["您注意更改路径",{"2":{"51":1}}],["您可根据个人适应选择相应的方法",{"2":{"53":1}}],["您可自行选择是否需要设置此部分内容",{"2":{"47":1}}],["您可以通过https",{"2":{"18":1}}],["您无需担心",{"2":{"35":1}}],["注意修改路径",{"2":{"50":3,"51":3,"54":3}}],["注意到",{"2":{"46":1}}],["注意力机制在目标类别内差异大时",{"2":{"10":1}}],["注意力偏差和空间感知偏差导致的背景干扰问题",{"2":{"16":1}}],["注意力偏差和空间感知偏差导致的对背景噪声敏感的问题",{"2":{"12":1}}],["注意力偏差和空间感知偏差问题",{"2":{"15":1}}],["注意力偏差和空间感知偏差",{"2":{"9":1}}],["注",{"2":{"35":3,"40":2,"42":1,"43":2,"45":1,"46":1,"51":1,"54":1}}],["没有详细的介绍说明",{"2":{"35":1}}],["没有充分利用上下文信息",{"2":{"34":1}}],["笔者会虚心接受这些产生错误的地方",{"2":{"54":1}}],["笔者也只是一个初学者",{"2":{"54":1}}],["笔者将快捷键设置为ctrl+alt+r",{"2":{"46":1}}],["笔者编写了一份简单的",{"2":{"45":1}}],["笔者选择",{"2":{"47":1}}],["笔者选择使用lastused",{"2":{"43":1}}],["笔者选用的",{"2":{"36":1}}],["笔者此处设置为",{"2":{"43":1}}],["笔者觉得菜单多了此选项较方便",{"2":{"43":1}}],["笔者只对几个要点进行提及",{"2":{"37":1}}],["笔者进入了清华大学镜像网站",{"2":{"36":1}}],["笔者配置了好久",{"2":{"35":1}}],["笔者前期使用的是texstudio进行文档的编译的",{"2":{"35":1}}],["颜值也很高",{"2":{"35":1}}],["话不多说",{"2":{"35":1}}],["头秃",{"2":{"35":1}}],["它并不是正向卷积的完全逆过程",{"2":{"65":1}}],["它将每个像素分类为属于对象类以及该类的实体",{"2":{"60":1}}],["它是将每个像素分类为属于对象类的过程",{"2":{"60":1}}],["它不仅能够对代码高亮",{"2":{"35":1}}],["它对于括号根本就没有高亮",{"2":{"35":1}}],["它们的分割性能得到增强",{"2":{"20":1}}],["最突出的特点就是其强大的插件功能",{"2":{"35":1}}],["最让人头疼的是",{"2":{"35":1}}],["最后提出本文的不足",{"2":{"57":1}}],["最后将两个掩码相加得到最终的查询前景分割图",{"2":{"12":1}}],["最后",{"2":{"9":1}}],["至少对笔者而言是如此",{"2":{"35":1}}],["秃头专业",{"2":{"35":1}}],["特征图填充宽度",{"2":{"65":1}}],["特征融合",{"2":{"30":1}}],["特征融合和像素匹配三种方法",{"2":{"23":1}}],["特定领域表现不佳",{"2":{"57":1}}],["特定提示设计困难",{"2":{"57":1}}],["特定场景表现弱",{"2":{"57":1}}],["特别是公式比较多的数学专业",{"2":{"35":1}}],["前端的选项",{"2":{"36":1}}],["前言",{"0":{"35":1}}],["前者通过融合深浅层特征",{"2":{"34":1}}],["前者通过条件损失对齐子网络嵌入",{"2":{"29":1}}],["影响了对复杂场景的理解和处理能力",{"2":{"34":1}}],["效果验证",{"2":{"34":1}}],["效果出乎意料地优于完全参数微调",{"2":{"18":1}}],["缩短了推理时间",{"2":{"34":1}}],["×",{"2":{"34":2,"46":1}}],["次迭代",{"2":{"34":1}}],["共有两种操作方式",{"2":{"53":1}}],["共",{"2":{"34":1}}],["共修正了2554个标签图",{"2":{"21":1}}],["倍的因子",{"2":{"34":1}}],["均为笔者所安装的其余插件以及其余设置所致",{"2":{"35":1}}],["均为",{"2":{"34":1}}],["同一类的不同物体也要进行分割",{"2":{"60":1}}],["同",{"2":{"34":1}}],["同时解决了上述两个问题",{"2":{"43":1}}],["同时两阶段和单阶段的方法都存在不足",{"2":{"34":1}}],["同时保留各模态独有的特征模式",{"2":{"27":1}}],["跨数据集测试",{"2":{"34":1}}],["跨域fss",{"2":{"23":1}}],["测试文件编译",{"0":{"46":1}}],["测试所用的",{"2":{"45":1}}],["测试时直接放缩图像到",{"2":{"34":1}}],["测试集",{"2":{"34":1}}],["测试数据集",{"2":{"20":1}}],["密集标注的",{"2":{"34":1}}],["渐进式融合编码器",{"2":{"34":1}}],["后如clip从大规模图像",{"2":{"34":1}}],["后者将transformer用作骨干网络或分割解码器",{"2":{"34":1}}],["后者运用特定算子组合多模态子网络",{"2":{"29":1}}],["早期通过学习特征映射对齐视觉和文本特征",{"2":{"34":1}}],["早期基于预训练的视觉和语言模型开发",{"2":{"34":1}}],["早期因缺乏大规模标注数据集",{"2":{"21":1}}],["也叫反卷积",{"2":{"65":1}}],["也称为全像素语义分割",{"2":{"60":1}}],["也就是出现在工具栏中的链名称",{"2":{"43":1}}],["也就是上图所完成的功能",{"2":{"36":1}}],["也会增加计算资源",{"2":{"34":1}}],["也取得了令人满意的结果",{"2":{"23":1}}],["主干网络对空间信息变得不敏感",{"2":{"34":1}}],["主要是通过输入边缘的",{"2":{"65":1}}],["主要是因为夜间的光照条件复杂且不足",{"2":{"21":1}}],["主要组件",{"2":{"30":1}}],["主要分为基于对齐和基于聚合的融合方法",{"2":{"29":1}}],["主要有原型匹配",{"2":{"23":1}}],["单阶段直接扩展视觉",{"2":{"34":1}}],["单阶段的框架存在不足",{"2":{"34":1}}],["单独使用dcam增强类别原型的判别能力可提升2",{"2":{"15":1}}],["单独使用tem增强查询前景特征可使性能提升0",{"2":{"15":1}}],["两阶段先生成掩码提案再分类",{"2":{"34":1}}],["两阶段的框架存在不足",{"2":{"34":1}}],["两个基本基线",{"2":{"18":1}}],["运行于单个a6000显卡",{"2":{"34":1}}],["每个像素的分类类别均为",{"2":{"61":1}}],["每个代码语句",{"2":{"42":1}}],["每个使用者的",{"2":{"35":1}}],["每个使用者都能够根据自己的需求和想法下载相应的插件",{"2":{"35":1}}],["每个标记与特定实例对应",{"2":{"18":1}}],["每张图像的推理时间为82毫秒",{"2":{"34":1}}],["层次化骨干网络能够更好地捕捉局部空间信息",{"2":{"34":1}}],["来扩大输入图像的尺寸",{"2":{"65":1}}],["来实现这一目标",{"2":{"57":1}}],["来自原始的",{"2":{"34":1}}],["来预测像素级的图像",{"2":{"34":1}}],["来进行超高分辨率图像的分割细化任务",{"2":{"20":1}}],["称为sed",{"2":{"34":1}}],["关键是将图像级的模型适应为像素级的分割任务",{"2":{"34":1}}],["重叠区域的特征反复计算",{"2":{"63":1}}],["重启",{"2":{"38":1}}],["重庆大学等",{"0":{"34":1}}],["重建更多细节",{"2":{"20":1}}],["重建图像细节",{"2":{"20":1}}],["天津大学",{"0":{"34":1}}],["768大小",{"2":{"34":1}}],["768",{"2":{"34":3}}],["7倍的加速",{"2":{"34":1}}],["7",{"0":{"44":1,"45":1,"46":1},"1":{"45":1,"46":1},"2":{"32":2,"34":1,"42":1}}],["78",{"2":{"23":1}}],["就是从像素层面上对图像进行描述",{"2":{"60":1}}],["就要找失败原因了",{"2":{"46":1}}],["就需要进行多次不同命令的转换编译",{"2":{"43":1}}],["就在多个下游多模态图像分割任务中取得了sota性能",{"2":{"32":1}}],["就在多个多模态图像分割基准任务中刷新了最高性能记录",{"2":{"27":1}}],["就能在各项指标上取得优于现有方法的性能",{"2":{"30":1}}],["上采样实现方法",{"0":{"81":1}}],["上采样",{"0":{"65":1,"79":1},"1":{"80":1,"81":1,"82":1}}],["上查看",{"2":{"52":1}}],["上面代码串中记得进行",{"2":{"51":1}}],["上",{"2":{"46":1}}],["上的实验表明",{"2":{"34":1}}],["上进行了广泛实验",{"2":{"30":1}}],["上海人工智能实验室",{"0":{"18":1}}],["优化策略",{"2":{"30":1}}],["辅助建模模态公共统计信息",{"2":{"30":1}}],["聚合类感知表示并辅助建模公共统计信息",{"2":{"32":1}}],["聚合辅助模态的类感知表示",{"2":{"30":1}}],["聚合多级别支持掩码等",{"2":{"11":1}}],["平均交并比",{"2":{"64":1}}],["平均准确率",{"2":{"64":1}}],["平均边界准确率",{"2":{"20":1}}],["平衡了模态内和模态间的语义传播",{"2":{"32":1}}],["平衡模态内和模态间的语义传播",{"2":{"30":1}}],["把标记送入分组提示器",{"2":{"30":1}}],["生成的",{"2":{"43":1}}],["生成新的跨模态对齐诱导提示",{"2":{"30":1}}],["生成特定于模态的提示",{"2":{"30":1}}],["生成对应的rgb标记和辅助模态标记",{"2":{"30":1}}],["生成鲁棒的支持类别原型",{"2":{"12":1}}],["输出尺寸的计算公式为",{"2":{"65":1}}],["输出边补充0的层数",{"2":{"65":1}}],["输出也可能会比实际输入更大或者更小一些",{"2":{"61":1}}],["输出节点数为",{"2":{"61":1}}],["输出步长多设为",{"2":{"20":1}}],["输入的每一条边补充0的层数",{"2":{"65":1}}],["输入的图像大小为w×h的",{"2":{"61":1}}],["输入信号的通道数",{"2":{"65":1}}],["输入",{"2":{"38":1,"39":1}}],["输入cmd",{"2":{"36":1}}],["输入处理",{"2":{"30":1}}],["整体架构",{"2":{"30":1}}],["核心思想",{"2":{"30":1}}],["再进行普通的卷积",{"2":{"65":1}}],["再点击安装即可",{"2":{"36":1}}],["再点击安装",{"2":{"36":1}}],["再基于此和分层编码器的不同特征图",{"2":{"34":1}}],["再输入到基础模型的下一层",{"2":{"30":1}}],["再在特定下游任务数据集上微调",{"2":{"29":1}}],["再以此为指导在整个查询特征图中寻找特征相似度高的点",{"2":{"12":1}}],["参数",{"2":{"51":1}}],["参数存储负担大",{"2":{"28":1}}],["参数高效微调",{"2":{"18":2}}],["全景分割",{"2":{"60":1}}],["全景质量",{"2":{"20":1}}],["全微调虽有效",{"2":{"28":1}}],["全微调方法的局限",{"2":{"28":1}}],["现在编译的结果为内部查看器查看",{"2":{"46":1}}],["现存方法的挑战",{"2":{"28":1}}],["现有多模态分割方法主要分为基于对齐和基于聚合的融合",{"2":{"28":1}}],["现有fss方法的问题",{"2":{"23":1}}],["现有fss模型虽有成果",{"2":{"10":1}}],["现有白天方法在夜间性能会下降",{"2":{"21":1}}],["现有方法通常先加载基于rgb的预训练模型参数",{"2":{"29":1}}],["现有方法主要基于语义一致性进行预测",{"2":{"12":1}}],["现有方法利用单层注意力机制建立支持集和查询集的关系",{"2":{"12":1}}],["现有方法多依赖语义相关性",{"2":{"10":1}}],["展现出高效性和优越性",{"2":{"30":1}}],["展现出显著优势",{"2":{"27":1}}],["展示将crm应用于全景分割的可视化结果",{"2":{"20":1}}],["展示cascadepsp",{"2":{"20":1}}],["展示了该方法在图像分割细化上的高效性和快速性",{"2":{"20":1}}],["促进跨模态语义对齐",{"2":{"27":1}}],["首先是类感知单模态提示器",{"2":{"27":1}}],["首次在",{"2":{"18":1}}],["受大语言模型中提示学习方法取得突破的启发",{"2":{"27":1}}],["受此启发",{"2":{"23":1}}],["红外等",{"2":{"27":1}}],["当同步到外部查看器时",{"2":{"54":1}}],["当编译成功后",{"2":{"46":1}}],["当编译失败时",{"2":{"43":1}}],["当发现页面下方出现",{"2":{"46":1}}],["当其余编译器引用时该",{"2":{"43":1}}],["当代码被保存时自动编译文件",{"2":{"43":1}}],["当出现下图所示弹窗时",{"2":{"36":1}}],["当上面标示的时间安装完之后",{"2":{"36":1}}],["当公式比较长的时候",{"2":{"35":1}}],["当使用convnext",{"2":{"34":1}}],["当前主流方法主要通过对基于可见光",{"2":{"27":1}}],["当将其扩展到跨领域",{"2":{"23":1}}],["当部分掩码数量",{"2":{"23":1}}],["做法后",{"2":{"23":1}}],["盲目使用变压器提取特征可能无法带来预期的性能提升",{"2":{"23":1}}],["例如两种vit变体在10个块时效果最佳",{"2":{"23":1}}],["块的数量并非越多越好",{"2":{"23":1}}],["块数量的影响",{"2":{"23":1}}],["较小的vit",{"2":{"23":1}}],["较为合适",{"2":{"23":1}}],["骨干网络设置消融实验",{"2":{"23":1}}],["说明",{"2":{"64":1}}],["说明编译失败",{"2":{"46":1}}],["说明编译成功",{"2":{"46":1}}],["说明安装完毕",{"2":{"36":1}}],["说明两者对于查询图像的分割都至关重要",{"2":{"23":1}}],["说明挖掘细粒度的部分语义能进一步发挥提示的作用",{"2":{"23":1}}],["产生冗余和噪声",{"2":{"23":1}}],["产生空间感知偏差",{"2":{"10":1}}],["过多的部分掩码可能导致目标对象无法清晰划分",{"2":{"23":1}}],["过滤无关像素",{"2":{"11":1}}],["继续增加数量",{"2":{"23":1}}],["从输入通道到输出通道的阻塞连接数",{"2":{"65":1}}],["从使用的包中自动补全命令和环境",{"2":{"54":1}}],["从不自动编译",{"2":{"43":1}}],["从上文整个代码块儿可以看出此规则",{"2":{"42":1}}],["从1增加到8时",{"2":{"23":1}}],["从而推动图像分割进入基础模型时代",{"2":{"57":1}}],["从而补全正在编写的代码",{"2":{"43":1}}],["从而可以对",{"2":{"42":1}}],["从而直接完成相应设置",{"2":{"40":1}}],["从而将之配置为高度个性化的编辑器",{"2":{"35":1}}],["从而在不牺牲精度的情况下",{"2":{"34":1}}],["从而提高分割精度",{"2":{"23":1}}],["从而提高预测的精度",{"2":{"21":1}}],["从而减轻固有的偏差",{"2":{"9":1}}],["语言模型进行分割",{"2":{"34":1}}],["语言模型",{"2":{"34":2}}],["语言信息比支持平均令牌更具类别代表性",{"2":{"23":1}}],["语言信息的优势",{"2":{"23":1}}],["语义提示转移",{"2":{"23":1}}],["语义提示迁移",{"2":{"23":1}}],["语义导向解耦",{"2":{"21":1}}],["语义分割常用优化目标",{"0":{"78":1}}],["语义分割评估指标",{"0":{"77":1}}],["语义分割的思路",{"0":{"63":1}}],["语义分割模型",{"2":{"62":1}}],["语义分割只需要对像素进行分类就行了",{"2":{"60":1}}],["语义分割方法",{"2":{"34":1}}],["语义分割旨在为场景中每个像素分配语义类别",{"2":{"28":1}}],["语义分割",{"2":{"20":1,"21":1,"60":1}}],["体现了背景语义对分割的重要性",{"2":{"23":1}}],["弱标签甚至零样本等更现实的场景时",{"2":{"23":1}}],["弱标签和零样本分割等场景",{"2":{"23":1}}],["弱标签fss和零",{"2":{"23":1}}],["挖掘细粒度语义提示",{"2":{"23":1}}],["挖掘目标对象自身的空间一致性",{"2":{"12":1}}],["精确转移语义",{"2":{"23":1}}],["精确的图像分割细化",{"2":{"20":1}}],["构建数据引擎收集sa",{"2":{"57":1}}],["构建部分掩码生成器",{"2":{"23":1}}],["构建三个关键增强点",{"2":{"23":1}}],["构建框架",{"2":{"18":1}}],["动态驱动编码器关注特定对象",{"2":{"23":1}}],["动态类别感知提示范式",{"2":{"23":1}}],["模仿人类视觉感知模式",{"2":{"23":1}}],["模型的输入是什么",{"2":{"61":1}}],["模型的输入和输出",{"0":{"61":1}}],["模型创新",{"2":{"57":1}}],["模型和数据集",{"2":{"57":1}}],["模型有时难以区分近义词类别",{"2":{"34":1}}],["模型在识别近义词类别时存在困难",{"2":{"34":1}}],["模型设定",{"2":{"34":1}}],["模型训练方式",{"2":{"29":1}}],["模型实现",{"2":{"20":1}}],["模型易过拟合或细化能力有限等问题",{"2":{"20":1}}],["模型结构图",{"2":{"18":1}}],["模型整体比基线提升了3",{"2":{"15":1}}],["计算机视觉领域也在探索基础模型",{"2":{"57":1}}],["计算机视觉领域虽也对基础模型有所探索",{"2":{"57":1}}],["计算机视觉领域尝试引入可学习参数激活语义知识",{"2":{"23":1}}],["计算效率低",{"2":{"34":1}}],["计算成本高",{"2":{"20":1}}],["源于自然语言处理",{"2":{"23":1}}],["人类能够以独特的视觉感知模式选择性地关注视线中的关键对象",{"2":{"23":1}}],["人类视觉感知的启示",{"2":{"23":1}}],["人类可以轻松聚焦于视线中的特定物体",{"2":{"23":1}}],["会将所有的非",{"2":{"43":1}}],["会出现一些配置文件的安装运行写入",{"2":{"36":1}}],["会先出现下图",{"2":{"36":1}}],["会激活与目标类别无关的对象",{"2":{"23":1}}],["会导致注意力偏差",{"2":{"10":1}}],["旨在推动计算机视觉领域的基础模型研究",{"2":{"57":1}}],["旨在利用多数据源增强细粒度细节和像素级语义",{"2":{"29":1}}],["旨在利用少量标注样本快速泛化到未见领域",{"2":{"23":1}}],["旨在通过少量的标注样本为新的类别生成一个分割模型",{"2":{"9":1}}],["应如下图页面所示",{"2":{"37":1}}],["应运而生",{"2":{"23":1}}],["应用示例",{"2":{"20":1}}],["少样本学习",{"2":{"23":2}}],["少样本分割",{"2":{"10":1,"23":2}}],["半监督学习也难以很好地泛化到未见类别",{"2":{"23":1}}],["深度多模态融合展现出比单模态分割更显著的优势",{"2":{"28":1}}],["深度学习",{"2":{"59":1}}],["深度学习笔记",{"0":{"59":1}}],["深度学习推动下",{"2":{"28":1}}],["深度学习在计算机视觉任务中取得显著进展",{"2":{"23":1}}],["深度表示解耦",{"2":{"21":1}}],["遥感领域",{"2":{"23":1}}],["医学影像",{"2":{"69":1}}],["医学图像分割",{"2":{"69":1}}],["医学",{"2":{"23":1}}],["医学诊断等领域带来了新机遇",{"2":{"20":1}}],["令人惊喜的是",{"2":{"23":1}}],["令人惊讶的是",{"2":{"23":1}}],["令牌长度和秩对模型性能的影响",{"2":{"18":1}}],["部分掩码数量影响",{"2":{"23":1}}],["部分掩码生成器",{"2":{"23":2}}],["部分工作探索了与少样本学习的结合",{"2":{"23":1}}],["部分研究开始探索适用于fss的特征编码器",{"2":{"23":1}}],["部分方法引入文本信息用于分类",{"2":{"23":1}}],["部分方法开始应用于计算机视觉",{"2":{"18":1}}],["感兴趣的物体",{"2":{"23":1}}],["尤其是在当前大模型时代",{"2":{"23":1}}],["类目标",{"2":{"34":1}}],["类感知单模态提示器",{"2":{"30":1}}],["类别识别局限",{"2":{"34":1}}],["类别模板数量",{"2":{"34":1}}],["类别早期拒接",{"2":{"34":1}}],["类别",{"2":{"23":1}}],["类内差异表示在三种不同的注意力机制中都有益",{"2":{"15":1}}],["类内差异表示利用一组可学习向量建模支持集和查询集之间的差异",{"2":{"12":1}}],["框架",{"2":{"21":1}}],["框架能够在不受光照影响的情况下提取反射成分",{"2":{"21":1}}],["细节处理欠佳",{"2":{"57":1}}],["细节重建难",{"2":{"20":1}}],["细化nightcity数据集",{"2":{"21":1}}],["借助语义约束分离图像",{"2":{"21":1}}],["创新点",{"2":{"21":1,"57":1}}],["近期也开始应用于视觉任务",{"2":{"29":1}}],["近期有基于nightcity数据集的方法",{"2":{"21":1}}],["近年来",{"2":{"10":1,"18":1}}],["夜间语义分割",{"2":{"21":1}}],["夜间场景光照强度低且人工光源复杂",{"2":{"21":1}}],["解码器架构",{"2":{"34":1}}],["解码器架构的方法成为主流",{"2":{"21":1}}],["解决固定编码器类别无关问题",{"2":{"23":1}}],["解决固有偏差",{"2":{"16":1}}],["解决该问题将是未来工作方向",{"2":{"20":1}}],["解决特征分类阶段的空间感知偏差问题",{"2":{"12":1}}],["解决特征匹配阶段的注意力偏差问题",{"2":{"12":1}}],["难以提取用于语义分割的判别特征",{"2":{"21":1}}],["难以对单张图像中不同实例的特征进行细化",{"2":{"18":1}}],["使得字体变大",{"2":{"47":1}}],["使冻结的预训练基础模型适应各种下游多模态分割任务",{"2":{"32":1}}],["使冻结的预训练模型能灵活适配多种多模态分割任务",{"2":{"27":1}}],["使模型适应各种下游多模态分割任务",{"2":{"30":1}}],["使特定区域的全局语义更好地聚合到提示中",{"2":{"23":1}}],["使其初步定位目标",{"2":{"23":1}}],["使编码器更精准地聚焦于目标对象",{"2":{"23":1}}],["使分割不受复杂光照干扰",{"2":{"21":1}}],["使网络在不同光照下提取一致特征",{"2":{"21":1}}],["使光不变反射率和光特定光照之间的纠缠加剧",{"2":{"21":1}}],["使用上次的recipe编译组合",{"2":{"54":1}}],["使用vscode内置pdf查看器或使用电脑默认浏览器进行pdf查看",{"2":{"51":1}}],["使用外部pdf查看器查看",{"2":{"51":1}}],["使用外部查看器时",{"2":{"54":1}}],["使用外部查看器时要执行的命令",{"2":{"54":1}}],["使用外部查看器",{"2":{"51":1}}],["使用外部",{"2":{"51":1}}],["使用电脑默认浏览器进行",{"2":{"51":1}}],["使用sumatrapdf查看的代码配置",{"0":{"49":1},"1":{"50":1,"51":1}}],["使用内置查看器已无法满足需求",{"2":{"47":1}}],["使用快捷键",{"2":{"46":1}}],["使用右键菜单",{"2":{"46":1}}],["使用侧边工具栏",{"2":{"46":1}}],["使用鼠标左键双击",{"2":{"43":1}}],["使用最近一次编译所用的编译链",{"2":{"43":1}}],["使用latex",{"2":{"43":1}}],["使用",{"2":{"43":1,"51":1,"54":1}}],["使用的是tex的标准字体",{"2":{"43":1}}],["使用的括号就比较多",{"2":{"35":1}}],["使用的数据集",{"2":{"21":1}}],["使用基于rgb的预训练基础模型的参数初始化多模态分割模型",{"2":{"30":1}}],["使用更复杂的解码器不一定能优于简单的相似度计算",{"2":{"23":1}}],["使用一致编码器的比较",{"2":{"23":1}}],["使用deit",{"2":{"23":1}}],["使用dcm实现语义对齐和空间对齐可额外提升1",{"2":{"15":1}}],["使用ctrl",{"2":{"43":1}}],["使用clip提取的语言信息作为初始提示具有最优的分割结果",{"2":{"23":1}}],["使用cascadepsp提出的高分辨率图像分割数据集big",{"2":{"20":1}}],["使用随机初始化的提示来调整编码器不会带来性能提升",{"2":{"23":1}}],["使用其子集bdd100k",{"2":{"21":1}}],["使用超高分辨率图像进行训练和测试仍面临资源消耗大的问题",{"2":{"20":1}}],["使用超高清图像进行训练和测试仍耗资源",{"2":{"20":1}}],["使用adam优化器",{"2":{"20":1}}],["使用去掉conv5",{"2":{"20":1}}],["使用pytorch实现模型",{"2":{"20":1}}],["使用掩码注意力减轻背景噪声干扰对性能提升影响不大",{"2":{"15":1}}],["不够稳健",{"2":{"57":1}}],["不相连的虚假组件",{"2":{"57":1}}],["不然会报错",{"2":{"51":1}}],["不需要进行更改",{"2":{"43":1}}],["不包含外部",{"2":{"42":1}}],["不要对其进行修改",{"2":{"36":1}}],["不怎么好用",{"2":{"36":1}}],["不在本文探讨范围之内",{"2":{"35":1}}],["不过",{"2":{"34":1}}],["不能识别出来在训练集中没有的未知场景",{"2":{"34":1}}],["不同的是",{"2":{"40":1}}],["不同级别括号用不同颜色标注了",{"2":{"35":1}}],["不同模态有效信息不同",{"2":{"28":1}}],["不同成像机制的模态存在异质差距",{"2":{"28":1}}],["不同骨干网络中",{"2":{"23":1}}],["不同骨干网络的性能",{"2":{"23":1}}],["不适合夜间复杂的光照条件",{"2":{"21":1}}],["不足",{"2":{"20":1,"34":1}}],["一般来说",{"2":{"64":1}}],["一些专门的工具可能会比sam表现更好",{"2":{"57":1}}],["一个全新的图像分割任务",{"2":{"57":1}}],["一定要选上",{"2":{"37":1}}],["一定程度上改善了夜间场景表现",{"2":{"21":1}}],["一致",{"2":{"34":1}}],["一方面",{"2":{"28":1}}],["一方面模型可迁移性较弱",{"2":{"27":1}}],["一是特征提取阶段",{"2":{"10":1}}],["虽有nightcity等大规模夜间数据集及相关方法提出",{"2":{"21":1}}],["虽能取得较好性能",{"2":{"20":1}}],["视觉编码器形式的预训练",{"2":{"34":1}}],["视觉",{"2":{"34":1}}],["视觉提示学习应用",{"2":{"29":1}}],["视觉系统近一半时间需在光照不足且复杂的夜间环境下工作",{"2":{"21":1}}],["视觉基础模型",{"2":{"18":2}}],["光照感知解析器",{"2":{"21":1}}],["然后按ctrl+alt+v",{"2":{"46":1}}],["然后按下该快捷键",{"2":{"46":1}}],["然后进行图示操作",{"2":{"46":1}}],["然后输入命令xelatex",{"2":{"36":1}}],["然后手动选择某一镜像网站进行下载",{"2":{"36":1}}],["然后通过自适应融合这两部分信息来进行语义识别",{"2":{"21":1}}],["然而在实际应用中",{"2":{"21":1}}],["然而",{"2":{"18":1,"20":1,"23":2}}],["yield",{"2":{"21":1}}],["未来将探索设计类别注意力策略或使用大规模细粒度数据集来解决该挑战",{"2":{"34":1}}],["未来工作待明确",{"2":{"20":1}}],["未来展望",{"2":{"20":1}}],["低分辨率训练和超高分辨率测试",{"2":{"20":1}}],["低分辨率训练和超高清测试",{"2":{"20":1}}],["目前尚不清楚如何设计简单的提示来实现语义和全景分割",{"2":{"57":1}}],["目前采用",{"2":{"20":2}}],["目标增强模块",{"2":{"9":1,"12":1,"15":1}}],["可学习的上采样",{"2":{"65":1}}],["可直接完整复制文末笔者的个人配置到自己的编译器内",{"2":{"50":1}}],["可选",{"0":{"47":1},"1":{"48":1,"49":1,"50":1,"51":1}}],["可自行通过上文方式设置为您想要的快捷键",{"2":{"46":1}}],["可对其设置快捷键",{"2":{"46":1}}],["可能会导致",{"2":{"43":1}}],["可根据其数字来判断安装所需时间",{"2":{"36":1}}],["可以看成是w×h个分类任务",{"2":{"61":1}}],["可以看到的是",{"2":{"36":1,"43":2,"52":1}}],["可以看到",{"2":{"35":1}}],["可以将较小的",{"2":{"65":1}}],["可以将",{"2":{"52":1}}],["可以实时进行跳转",{"2":{"47":1}}],["可以根据上文进行配置",{"2":{"46":1}}],["可以使用自己的tex文件进行测试",{"2":{"45":1}}],["可以更改的代码为",{"2":{"43":1}}],["可以跳过该小节",{"2":{"43":1}}],["可以直接复制上述代码至",{"2":{"42":1}}],["可以直接按ctrl",{"2":{"40":1}}],["可以点击",{"2":{"39":1}}],["可以返回前一页面",{"2":{"36":1}}],["可以查看此篇文章",{"2":{"36":1}}],["可以这么说",{"2":{"35":1}}],["可视化结果显示",{"2":{"23":1}}],["可视化对比",{"2":{"20":1}}],["可分为优化和度量两类",{"2":{"23":1}}],["可提升现有日间方法在夜间的性能",{"2":{"21":1}}],["可处理低分辨率训练和超高清测试之间的分辨率差距",{"2":{"20":1}}],["泛化能力",{"2":{"20":1}}],["有时会生成小的",{"2":{"57":1}}],["有三个参数变量",{"2":{"51":1}}],["有三个选项",{"2":{"43":1}}],["有三种变量参数",{"2":{"51":1}}],["有的时候",{"2":{"47":1}}],["有的地方需要更改路径",{"2":{"35":1}}],["有以下三种方法",{"2":{"46":1}}],["有两个变量",{"2":{"43":1}}],["有具体说明",{"2":{"35":1}}],["有助于聚合特征以重建高分辨率掩码上的细节",{"2":{"20":1}}],["有助于提高性能直至收敛",{"2":{"20":1}}],["有效提升推理速度",{"2":{"34":1}}],["有效捕捉多模态数据的共有统计规律",{"2":{"27":1}}],["有效降低计算成本",{"2":{"20":1}}],["有效减少了背景干扰",{"2":{"16":1}}],["更多详情可以访问",{"2":{"43":1}}],["更多的语义迁移次数通常能带来更高的分割精度",{"2":{"23":1}}],["更多的缩放比例意味着推理分辨率的连续性更好",{"2":{"20":1}}],["更重要的是",{"2":{"20":1}}],["性能验证",{"2":{"21":1}}],["性能优势",{"2":{"20":1}}],["性能随着采样的缩放比例数量增加而提升",{"2":{"20":1}}],["性能下降2",{"2":{"15":1}}],["推理连续性的影响",{"2":{"20":1}}],["二者协同作用能提升性能",{"2":{"20":1}}],["二是特征匹配阶段",{"2":{"10":1}}],["验证了sed方法的有效性",{"2":{"34":1}}],["验证了该方法的有效性",{"2":{"9":1}}],["验证cam和隐式函数都是crm不可或缺的部分",{"2":{"20":1}}],["消融实验",{"0":{"32":1},"2":{"20":1,"21":1}}],["掩码细节和整体分割效果都有显著改善",{"2":{"20":1}}],["掩码注意力",{"2":{"15":1}}],["并在广泛的数据集上进行预训练",{"2":{"57":1}}],["并在11个基准测试中设立了新的技术标准",{"2":{"23":1}}],["并不影响本文中所说的所有配置",{"2":{"35":1}}],["并有效继承预训练基础模型的先验知识",{"2":{"30":1}}],["并激发未来相关研究聚焦于此",{"2":{"23":1}}],["并且此文主要将",{"2":{"36":1}}],["并且页面不是很美观",{"2":{"35":1}}],["并且计算复杂度与输入的大小成线性关系",{"2":{"34":1}}],["并且具有类别早期拒绝的功能",{"2":{"34":1}}],["并且与基于解码器的方法具有良好的兼容性",{"2":{"23":1}}],["并且能更好地重建粗掩码中缺失的部分",{"2":{"20":1}}],["并结合spt",{"2":{"23":1}}],["并仅微调解码器",{"2":{"23":1}}],["并聚合光照特征",{"2":{"21":1}}],["并得出以下结论",{"2":{"20":1,"21":1}}],["并提出",{"2":{"18":1}}],["定义完成后",{"2":{"43":1}}],["定性评估",{"2":{"23":1}}],["定性结果展示",{"2":{"20":1}}],["定量结果评估",{"2":{"20":1}}],["与上文相同",{"2":{"51":1}}],["与通用软件安装过程一致",{"2":{"48":1}}],["与普通的transformer相比",{"2":{"34":1}}],["与sota方法的对比",{"0":{"31":1}}],["与sota方法的对比实验",{"2":{"21":1}}],["与spt协同工作",{"2":{"23":1}}],["与此不同",{"2":{"23":1}}],["与nightcity",{"2":{"21":1}}],["与以往方法将光照信息与特征混合的做法不同",{"2":{"21":1}}],["与cascadepsp的iou相当",{"2":{"20":1}}],["与基线相比",{"2":{"15":1,"23":1}}],["02",{"2":{"45":1}}],["08",{"2":{"45":1}}],["01",{"2":{"34":1}}],["0",{"2":{"34":1,"65":9}}],["0之间",{"2":{"20":1}}],["000步",{"2":{"20":1}}],["80k",{"2":{"34":1}}],["80",{"2":{"34":1}}],["847",{"2":{"34":1}}],["82",{"2":{"34":1}}],["8",{"0":{"47":1,"48":1,"49":1,"50":1,"51":1},"1":{"48":1,"49":1,"50":2,"51":2},"2":{"20":1,"32":1,"43":1}}],["8×",{"2":{"20":1}}],["随机进入另一镜像网站进行下载尝试",{"2":{"36":1}}],["随机初始化提示",{"2":{"23":1}}],["随机iou阈值在0",{"2":{"20":1}}],["随着传感器技术发展",{"2":{"28":1}}],["随着分辨率增加",{"2":{"20":1}}],["随着相机和显示设备的快速发展",{"2":{"20":1}}],["扰动掩码是在真实掩码上随机扰动得到",{"2":{"20":1}}],["总共有ncl个不同的分类",{"2":{"64":1}}],["总推理时间也不到",{"2":{"20":1}}],["总推理时间不到cascadepsp的一半",{"2":{"20":1}}],["总步数45",{"2":{"20":1}}],["学习率为2",{"2":{"20":1}}],["训练时剪裁图像",{"2":{"34":1}}],["训练集",{"2":{"34":1}}],["训练资源限制",{"2":{"20":1}}],["训练输入是从原始图像及其对应的扰动掩码中裁剪的224×224的图像块",{"2":{"20":1}}],["训练设置",{"2":{"20":1}}],["训练数据集",{"2":{"20":1}}],["xetex",{"2":{"43":1}}],["xelatex",{"2":{"42":9,"43":14,"46":1,"54":9}}],["xb534",{"2":{"34":2}}],["x的resnet",{"2":{"20":1}}],["x3c",{"2":{"0":8}}],["还有基于自注意力机制和transformer的网络被应用",{"2":{"21":1}}],["还能提升现有全景分割模型的性能",{"2":{"20":1}}],["还能提升现有全景分割模型性能",{"2":{"20":1}}],["还在重新标注的pascal",{"2":{"20":1}}],["包含超过10亿个分割掩码和1100万张符合许可且尊重隐私的图像",{"2":{"57":1}}],["包含",{"2":{"34":2}}],["包含大约",{"2":{"34":1}}],["包含2975张训练图像和500张验证图像",{"2":{"21":1}}],["包含36",{"2":{"20":1}}],["包括标准fss",{"2":{"23":1}}],["包括交并比",{"2":{"20":1}}],["包括采用自对齐模块",{"2":{"15":1}}],["遵循cascadepsp的设置",{"2":{"20":1}}],["无论何时",{"2":{"43":1}}],["无论是否编译成功",{"2":{"43":1}}],["无需进行更改",{"2":{"43":1}}],["无需在意",{"2":{"39":1}}],["无需理会",{"2":{"36":1}}],["无需微调",{"2":{"20":1}}],["无法充分利用预训练模型知识获得通用表示",{"2":{"28":1}}],["无法在输出掩码上构建细粒度细节",{"2":{"20":1}}],["适用于低分辨率训练和超高分辨率测试",{"2":{"20":1}}],["利用空间金字塔网络或注意力模块等提取上下文信息",{"2":{"34":1}}],["利用光照中的语义线索实现更精确预测",{"2":{"21":1}}],["利用光照组件作为线索",{"2":{"21":1}}],["利用连续位置信息和特征对齐",{"2":{"20":1}}],["利用查询特征的内在引导",{"2":{"12":1}}],["利用查询特征的语义和空间感知",{"2":{"10":1}}],["隐式函数表示",{"2":{"20":1}}],["级联解码器方法能取得较好效果",{"2":{"20":1}}],["传播方法有计算和内存限制",{"2":{"20":1}}],["传统语义分割方法主要有基于fcn和基于transformer的方法",{"2":{"34":1}}],["传统的方法只能分割训练集的种类",{"2":{"34":1}}],["传统方法聚焦提升模型跨多未见领域的预测准确性",{"2":{"18":1}}],["传统dgss方法的局限",{"2":{"18":1}}],["针对150个类别的miou得分为31",{"2":{"34":1}}],["针对",{"2":{"20":1}}],["分类模型",{"2":{"61":1}}],["分类",{"2":{"60":1}}],["分割的指标主要有两个",{"2":{"64":1}}],["分割",{"2":{"60":1}}],["分割种类的增加也会增加计算资源",{"2":{"34":1}}],["分割性能提升有限",{"2":{"21":1}}],["分割细化",{"2":{"20":1}}],["分析crm和隐式函数对不同分辨率下性能的影响",{"2":{"20":1}}],["分析数据",{"2":{"18":1}}],["分辨率图像的细化技术能提升分割质量",{"2":{"20":1}}],["为w×d×n",{"2":{"61":1}}],["为模型训练提供强大支撑",{"2":{"57":1}}],["为下文解读之用",{"2":{"50":1}}],["为默认选项",{"2":{"43":1}}],["为您添加的其余代码",{"2":{"42":1}}],["为其专属定制编辑器",{"2":{"35":1}}],["为不同个体生成不同但互补的部分提示",{"2":{"23":1}}],["为了出现和内嵌输出具有相同的效果",{"2":{"52":1}}],["为了测试",{"2":{"45":1}}],["为了后面不必要的麻烦",{"2":{"36":1}}],["为了让更多人能够有一个比较清晰的了解",{"2":{"35":1}}],["为了提高推理速度",{"2":{"34":1}}],["为了更方便进行编译",{"2":{"46":1}}],["为了更有效地泛化到未见类别",{"2":{"23":1}}],["为了更高效地在未知领域",{"2":{"23":1}}],["为了增强提示效果",{"2":{"23":1}}],["为了解决这个问题",{"2":{"21":1}}],["为夜间分割提供更可靠基准",{"2":{"21":1}}],["为证明模型的通用性",{"2":{"20":1}}],["为解决超高分辨率图像分割中精度与计算成本的平衡问题",{"2":{"20":1}}],["为该领域建立重要基准",{"2":{"18":1}}],["丢失了细节并破坏了全局上下文",{"2":{"20":1}}],["增加后续解码器分割新类别的负担",{"2":{"23":1}}],["增加了成本",{"2":{"20":1}}],["增强模型的鲁棒性",{"2":{"10":1}}],["增强前景特征",{"2":{"9":1,"12":1}}],["大特征图",{"2":{"65":1}}],["大语言模型在自然语言处理",{"2":{"57":1}}],["大小",{"2":{"34":1,"47":1}}],["大量下游任务实验表明",{"2":{"32":1}}],["大量实验表明",{"2":{"21":1}}],["大量的输入像素在计算上代价高昂",{"2":{"20":1}}],["大多数fss方法直接使用预训练编码器",{"2":{"23":1}}],["大多数少样本分割",{"2":{"23":1}}],["大多数现有的方法尝试使用预训练的视觉",{"2":{"34":1}}],["大多数现有的语义分割方法都是为白天场景设计的",{"2":{"21":1}}],["大多数现有方法通过插值对最终预测进行4到8倍上采样",{"2":{"20":1}}],["大多现存的语义分割方法都是基于白天场景开发的",{"2":{"21":1}}],["大模型易过拟合而浅细化网络细化能力有限等问题",{"2":{"20":1}}],["大幅超越现有方法",{"2":{"18":1}}],["超高清图像",{"2":{"20":1}}],["超高分辨率图像也给经典图像分割方法带来了挑战",{"2":{"20":1}}],["超越现有方法",{"2":{"18":1}}],["工业缺陷检测",{"2":{"20":1}}],["逐步聚合特征",{"2":{"20":1}}],["连续细化模型",{"2":{"20":1}}],["往往会错误地激活与目标类别无关的物体",{"2":{"23":1}}],["往往难以很好地平衡准确性和计算成本",{"2":{"20":1}}],["往往对背景噪声过于敏感",{"2":{"9":1}}],["常用的上采样包括转置卷积",{"2":{"65":1}}],["常用数据集规模远小于imagenet",{"2":{"18":1}}],["常见的分割模型",{"0":{"62":1}}],["常见的策略",{"2":{"20":1}}],["常提供无效的跨模态融合",{"2":{"28":1}}],["等等",{"2":{"62":1}}],["等功能",{"2":{"45":1}}],["等待安装完成",{"2":{"38":1,"39":1}}],["等会儿会消失",{"2":{"36":1}}],["等指标",{"2":{"20":1}}],["等",{"0":{"20":1},"2":{"20":1}}],["香港中文大学",{"0":{"20":1}}],["quot",{"2":{"36":1,"37":1,"38":6,"39":6,"51":4}}],["quantitative",{"2":{"20":1}}],["quality",{"0":{"19":1}}],["query",{"2":{"8":1}}],["写作启发",{"2":{"18":1,"57":1}}],["提高空间信息的适应性",{"2":{"30":1}}],["提高分割精度",{"2":{"23":1}}],["提高训练效率",{"2":{"18":1}}],["提示词分割",{"2":{"57":1}}],["提示编码器和掩码解码器组成",{"2":{"57":1}}],["提示生成",{"2":{"30":1}}],["提示调优作为新范式",{"2":{"29":1}}],["提示增强次数",{"2":{"23":1}}],["提示增强消融实验",{"2":{"23":1}}],["提示初始化消融实验",{"2":{"23":1}}],["提示学习",{"2":{"23":1}}],["提示与迁移",{"2":{"23":1}}],["提升",{"2":{"23":1}}],["提升模型的识别能力",{"2":{"23":1}}],["提升其在夜间的分割效果",{"2":{"21":1}}],["提出可提示分割任务",{"2":{"57":1}}],["提出了一种新颖的动态类别感知提示范式",{"2":{"23":1}}],["提出了一种新颖且高效的基于提示的方案",{"2":{"23":1}}],["提出语义导向的解纠缠",{"2":{"21":1}}],["提出nightcity",{"2":{"21":2}}],["提出连续细化模型",{"2":{"20":1}}],["提出问题",{"2":{"18":1}}],["提出",{"2":{"18":2,"21":1,"23":1}}],["提出的模型",{"0":{"12":1,"30":1},"2":{"23":1}}],["证明其能够自适应地生成不同的部分掩码",{"2":{"23":1}}],["证明了该框架的优越性和泛化性",{"2":{"32":1}}],["证明了gopt已经达到了sota的标准",{"2":{"32":1}}],["证明了动态类别感知提示范式对少样本分割",{"2":{"23":1}}],["证明了vfms在dgss领域的巨大潜力以及rein方法的有效性",{"2":{"18":1}}],["证明了优化类别原型和查询特征的必要性",{"2":{"15":1}}],["证实其强大泛化能力",{"2":{"18":1}}],["领域展现出强大的零样本和少样本泛化能力",{"2":{"57":1}}],["领域",{"2":{"23":1}}],["领域泛化语义分割",{"2":{"18":2}}],["领域广义语义分割",{"2":{"18":1}}],["冻结的vfms性能优于先前dgss方法",{"2":{"18":1}}],["得出以下结论",{"2":{"34":1}}],["得出结论",{"2":{"18":1}}],["得到基于空间分布概率的掩码用于精确的定位",{"2":{"12":1}}],["批量大小等进行训练",{"2":{"18":1}}],["迭代次数",{"2":{"18":1}}],["方法清晰",{"2":{"57":1}}],["方法构成",{"2":{"34":1}}],["方法通常会直接使用预训练的编码器",{"2":{"23":1}}],["方法优势",{"2":{"21":1}}],["方法的性能",{"2":{"18":1}}],["方法",{"2":{"18":1,"23":1}}],["设计segment",{"2":{"57":1}}],["设计相应的模型架构",{"2":{"57":1}}],["设计了类感知单模态提示器",{"2":{"32":1}}],["设计语义提示转移",{"2":{"23":1}}],["设计语义导向解纠缠框架",{"2":{"21":1}}],["设计优化策略",{"2":{"18":1}}],["设计目的",{"2":{"12":3}}],["设置vscode内部查看生成的pdf文件",{"2":{"54":1}}],["设置为onfaild",{"2":{"54":1}}],["设置为true时",{"2":{"43":1}}],["设置是否自动编译",{"2":{"54":1}}],["设置其位置参数",{"2":{"51":1}}],["设置外部查看器启动文件sumatrapdf",{"2":{"51":1}}],["设置快捷键步骤如下",{"2":{"46":1}}],["设置边距",{"2":{"45":1}}],["设置页面交互能力较强",{"2":{"40":1}}],["设置页面和代码设置页面均为设置页面",{"2":{"40":1}}],["设置页面",{"2":{"40":1}}],["设置特定学习率",{"2":{"18":1}}],["设置",{"2":{"18":1}}],["因为网络的设计未必那么完美",{"2":{"61":1}}],["因为sam更侧重于通用性和广泛适用性",{"2":{"57":1}}],["因为如果涉及到",{"2":{"43":1}}],["因为毕竟涉及到代码",{"2":{"43":1}}],["因为这些错误和警告信息能够从终端中获取",{"2":{"43":1}}],["因为它可以通过新的",{"2":{"43":1}}],["因为支持集和查询集之间的相似度掩码在类内差异较大时准确性存在挑战",{"2":{"15":1}}],["因缺乏大规模多模态训练集",{"2":{"29":1}}],["因此它可以零样本迁移到不同的图像类型和任务",{"2":{"57":1}}],["因此在夜间场景中往往表现不佳",{"2":{"21":1}}],["因此",{"2":{"18":1,"20":1,"23":2,"57":1}}],["先按照一定的比例通过补",{"2":{"65":1}}],["先给出效果图",{"2":{"42":1}}],["先利用分层编码器生成像素级图像",{"2":{"34":1}}],["先分离再解析",{"2":{"21":1}}],["先解耦再解析",{"2":{"21":1}}],["先前dgss方法多采用传统骨干网络",{"2":{"18":1}}],["先以支持原型为参考在查询特征中选择匹配置信度高的点",{"2":{"12":1}}],["具有19个语义类别",{"2":{"21":1}}],["具有显著的泛化潜力",{"2":{"20":1}}],["具有显著的跨场景泛化能力",{"2":{"18":1}}],["具体的说",{"2":{"65":1}}],["具体的安装指标已在下图标明",{"2":{"36":1}}],["具体通过定义可提示的分割任务",{"2":{"57":1}}],["具体见下图",{"2":{"53":1}}],["具体看下图",{"2":{"43":1}}],["具体安装过程与常见的软件安装过程一致",{"2":{"37":1}}],["具体而言",{"2":{"32":1}}],["具体来说",{"2":{"21":1}}],["具体如下",{"2":{"18":1}}],["具体方法",{"2":{"12":3}}],["多样化的分割数据集",{"2":{"57":1}}],["多模态图像分割主流方法",{"2":{"29":1}}],["多模态图像分割技术是计算机视觉领域的关键挑战",{"2":{"27":1}}],["多模态方法常采用基于rgb的预训练分割器",{"2":{"28":1}}],["多模态融合用于分割成为图像解释核心问题",{"2":{"28":1}}],["多模态融合的重要性",{"2":{"28":1}}],["多数采用预训练编码器并微调解码器",{"2":{"23":1}}],["多数方法遵循元学习范式",{"2":{"23":1}}],["多使用vggnet",{"2":{"18":1}}],["多尺度自适应局部注意力",{"2":{"15":1}}],["采用无监督域适应技术将白天知识迁移到夜间",{"2":{"21":1}}],["采用层共享mlp权重和低秩token序列",{"2":{"18":1}}],["采用adamw优化器",{"2":{"18":1}}],["采用复杂数据增强和领域不变特征提取策略",{"2":{"18":1}}],["采用多尺度自适应局部注意力增强前景信息",{"2":{"12":1}}],["微调方法",{"2":{"18":2}}],["将图像分割成一个个小的区域",{"2":{"63":1}}],["将synctex转发到外部查看器时要执行的命令",{"2":{"54":1}}],["将完整代码复制到自己的",{"2":{"52":1}}],["将之下载后",{"2":{"45":1}}],["将之添加到环境变量",{"2":{"36":1}}],["将编译方式",{"2":{"43":1}}],["将在下文提及",{"2":{"43":1}}],["将成本图与不同层级骨干网络的特征图进行融合",{"2":{"34":1}}],["将其他数据源的关键模式整合到rgb流中",{"2":{"30":1}}],["将学习到的提示作为残差添加到原始rgb流中",{"2":{"30":1}}],["将rgb图像和辅助模态图像输入到补丁嵌入层",{"2":{"30":1}}],["将额外的类别语义作为初始提示可以调整编码器",{"2":{"23":1}}],["将crm添加到panopticfcn和entityseg后",{"2":{"20":1}}],["将crm作为全景分割和实体分割的扩展进行评估",{"2":{"20":1}}],["将msra",{"2":{"20":1}}],["将vfms用于dgss任务存在挑战",{"2":{"18":1}}],["将分割任务解耦为语义对齐和空间对齐两个子任务",{"2":{"12":1}}],["其插入的",{"2":{"65":1}}],["其过程如下图所示",{"2":{"65":1}}],["其研究背景主要源于自然语言处理",{"2":{"57":1}}],["其研究背景主要源于当前fss方法存在的局限性以及人类视觉感知模式带来的启示",{"2":{"23":1}}],["其操作步骤与内嵌输出",{"2":{"52":1}}],["其安装很简单",{"2":{"48":1}}],["其变量有",{"2":{"43":1}}],["其生成的",{"2":{"43":1}}],["其内部编译命令来自上文latex",{"2":{"43":1}}],["其功能是一样的",{"2":{"40":1}}],["其余如图所示",{"2":{"37":1}}],["其余均为原创内容",{"2":{"35":1}}],["其重要性自不必多说",{"2":{"35":1}}],["其次是对齐引导的跨模态提示器",{"2":{"27":1}}],["其他fss方法的性能有显著提升",{"2":{"23":1}}],["其互补数据集为bdd100k",{"2":{"21":1}}],["其多视图一致性和光滑性有利于分割",{"2":{"20":1}}],["其在不同未知场景下展现出强大泛化能力",{"2":{"18":1}}],["其中侧边栏所展现的就是上文提及的新的",{"2":{"46":1}}],["其中name是标签",{"2":{"43":1}}],["其中的name为这些命令的标签",{"2":{"43":1}}],["其中多出来的第一个选项为进行tex文件的编译",{"2":{"43":1}}],["其中",{"2":{"9":1,"64":1}}],["对这些小区域做分类",{"2":{"63":1}}],["对字体的支持更好",{"2":{"43":1}}],["对应的",{"2":{"43":1}}],["对齐诱导跨模态提示器",{"2":{"30":1}}],["对辅助模态的视觉概念进行分层渐进分组",{"2":{"30":1}}],["对最大的夜间分割数据集nightcity进行细化",{"2":{"21":1}}],["对训练集和验证集中不合理的标注进行了仔细修改",{"2":{"21":1}}],["对比实验+消融实验",{"2":{"34":1}}],["对比实验",{"2":{"20":1}}],["对比方法",{"2":{"20":1}}],["对比rein与现有dgss和参数高效微调",{"2":{"18":1}}],["对于反卷积而言",{"2":{"65":1}}],["对于普通的",{"2":{"65":1}}],["对于理工科",{"2":{"35":1}}],["对于低分辨率的输入",{"2":{"34":1}}],["对于",{"2":{"20":1,"61":1}}],["对4k或6k超高分辨率图像进行分割时",{"2":{"20":1}}],["对vfms大量可训练参数进行微调会导致泛化能力受限",{"2":{"18":1}}],["对更强的vfms在dgss中的效能探索不足",{"2":{"18":1}}],["对dcam中的关键组件进行了全面分析",{"2":{"15":1}}],["但是这个思想一个很重要的问题就是效率低",{"2":{"63":1}}],["但是其编译速度比较慢",{"2":{"35":1}}],["但缺乏大规模",{"2":{"57":1}}],["但计算机视觉问题广泛",{"2":{"57":1}}],["但其只能测试一部分功能",{"2":{"45":1}}],["但笔者不建议这么做",{"2":{"43":1}}],["但却可以对自己想要的功能直接进行代码编写",{"2":{"40":1}}],["但一些设置需要去寻找",{"2":{"40":1}}],["但建议在不明白各个选项的作用时",{"2":{"36":1}}],["但texstudio的代码高亮功能实在是",{"2":{"35":1}}],["但效率低",{"2":{"28":1}}],["但面临诸多挑战",{"2":{"28":1}}],["但这种方法存在明显局限",{"2":{"27":1}}],["但这些数据驱动的技术在标注数据不足时表现不佳",{"2":{"23":1}}],["但这些方法未明确估计光照对语义的影响",{"2":{"21":1}}],["但推理速度具有竞争力",{"2":{"23":1}}],["但综合效率和性能考虑",{"2":{"23":1}}],["但存在标注错误",{"2":{"21":1}}],["但存在图形模型依赖低层次颜色边界",{"2":{"20":1}}],["但大多聚焦白天场景",{"2":{"21":1}}],["但大多不是为dgss设计",{"2":{"18":1}}],["但它们通常基于光照纠缠的表示进行场景解析",{"2":{"21":1}}],["但因夜间缺乏对应标签",{"2":{"21":1}}],["但更注重细节",{"2":{"20":1}}],["但结构复杂",{"2":{"20":1}}],["但直接插值预测结果存在边缘锯齿和细节缺失问题",{"2":{"20":1}}],["但在推理时需要下采样和裁剪补丁",{"2":{"20":1}}],["但在dgss中的性能及利用方式尚不明确",{"2":{"18":1}}],["但在dgss任务中的表现缺乏专门研究",{"2":{"18":1}}],["但多采用vggnet",{"2":{"18":1}}],["但受背景干扰",{"2":{"10":1}}],["本文旨在开发一个可提示的模型",{"2":{"57":1}}],["本文转载自https",{"2":{"54":1}}],["本文使用图片均为笔者自身编辑器截图或笔者朋友的编辑器截图",{"2":{"35":1}}],["本文提出了分组提示调优框架",{"2":{"30":1}}],["本文提出了一种简单的编码器",{"2":{"34":1}}],["本文提出了一种基于提示学习的",{"2":{"23":1}}],["本文提出了一种基于transformer的自适应原型匹配网络",{"2":{"12":1}}],["本文提出了一种全新的夜间语义分割方法",{"2":{"21":1}}],["本文聚焦于构建图像分割基础模型",{"2":{"57":1}}],["本文聚焦于",{"2":{"23":1}}],["本文聚焦于在领域泛化语义分割",{"2":{"18":1}}],["本文重点介绍了三项关键技术",{"2":{"23":1}}],["本文模仿人类的视觉感知方式",{"2":{"23":1}}],["本文的sed方法都表现出较好的效果",{"2":{"34":1}}],["本文的创新点",{"2":{"18":1}}],["本文的研究背景",{"2":{"18":1}}],["​",{"2":{"18":1,"21":1,"23":4}}],["代码解读",{"0":{"51":1}}],["代码展示",{"0":{"50":1}}],["代码进行编译",{"2":{"42":1}}],["代码不算哈哈哈",{"2":{"35":1}}],["代码已发布",{"2":{"18":1}}],["代替多层感知器",{"2":{"15":1}}],["而对于输入的内部插",{"2":{"65":1}}],["而对于我们大部分人来说",{"2":{"36":1}}],["而实例分割不仅要对像素进行分类",{"2":{"60":1}}],["而非高iou的交互式分割",{"2":{"57":1}}],["而不是",{"2":{"51":1}}],["而不是传统的transformer",{"2":{"34":1}}],["而never命令做不到这一点",{"2":{"43":1}}],["而有时候将",{"2":{"43":1}}],["而编译链就解决了这个问题",{"2":{"43":1}}],["而使用",{"2":{"43":1}}],["而",{"2":{"43":1}}],["而command为在该拓展中的编译方式",{"2":{"43":1}}],["而第二个选项为进行正向同步",{"2":{"43":1}}],["而每个代码块儿的最后一句是不需要加上",{"2":{"42":1}}],["而言不那么直观",{"2":{"40":1}}],["而代码设置页面虽然相对",{"2":{"40":1}}],["而visual",{"2":{"35":1}}],["而选择一个比较好的编译器是很重要的",{"2":{"35":1}}],["而是学习内容和光照的纠缠表示",{"2":{"21":1}}],["而且对非拉丁字体的支持更好",{"2":{"43":1}}],["而且",{"2":{"21":1}}],["而且无需使用任何真实的城市场景数据集",{"2":{"18":1}}],["而处理超高分辨率细化的级联解码器方法",{"2":{"20":1}}],["而大规模vfms虽在计算机视觉挑战中表现出色",{"2":{"18":1}}],["而双语义感知注意力机制通过可学习的方式减轻背景干扰",{"2":{"15":1}}],["的数量为stride−1",{"2":{"65":1}}],["的层数为",{"2":{"65":1}}],["的卷积",{"2":{"65":1}}],["的概念与目标检测中的",{"2":{"64":1}}],["的使用",{"0":{"52":1}}],["的窗口位置",{"2":{"47":1}}],["的内部查看器的快捷键绑定",{"2":{"43":1}}],["的标准字体",{"2":{"43":1}}],["的引用",{"2":{"43":1}}],["的",{"2":{"42":1,"43":1,"51":1}}],["的快捷方式",{"2":{"37":1}}],["的编辑器",{"2":{"36":1}}],["的下载与安装说明",{"2":{"36":1}}],["的区别",{"2":{"36":1}}],["的训练集",{"2":{"34":1}}],["的模型参数",{"2":{"30":1,"32":1}}],["的参数",{"2":{"27":1}}],["的共性特征",{"2":{"27":1}}],["的有效性",{"2":{"23":1}}],["的平均交并比",{"2":{"23":1}}],["的夜间语义分割范式",{"2":{"21":1}}],["的配置",{"2":{"20":2,"42":1}}],["的一半",{"2":{"20":1}}],["的miou提升",{"2":{"23":3}}],["的miou",{"2":{"18":1}}],["的可训练参数",{"2":{"18":1}}],["仅训练不到1",{"2":{"32":1}}],["仅更新分组提示器和分割头的梯度值",{"2":{"30":1}}],["仅微调少量视觉提示参数",{"2":{"30":1}}],["仅微调解码器",{"2":{"23":1}}],["仅需微调模型不足",{"2":{"27":1}}],["仅将支持图像或查询图像的目标语义转移到提示中会导致不同程度的性能下降",{"2":{"23":1}}],["仅使用语义分割标注训练就能生成类似抠图的结果",{"2":{"20":1}}],["仅使用基于空间分布概率的分割图时",{"2":{"15":1}}],["仅使用基于语义相似度的掩码可使模型性能提升1",{"2":{"15":1}}],["仅在冻结的骨干网络中增加1",{"2":{"18":1}}],["值得一提的是",{"2":{"18":1}}],["能作为预训练目标",{"2":{"57":1}}],["能否编译参考文献",{"2":{"45":1}}],["能否编译目录",{"2":{"45":1}}],["能否进行引用",{"2":{"45":1}}],["能否插入图片",{"2":{"45":1}}],["能省很多麻烦",{"2":{"37":1}}],["能提前拒绝不存在的类别",{"2":{"34":1}}],["能连续对齐特征图与细化目标",{"2":{"20":1}}],["能生成更多细节",{"2":{"20":1}}],["能够在拥有这些优势的同时",{"2":{"47":1}}],["能够在",{"2":{"43":1}}],["能够针对不同任务激活相应的类别对象",{"2":{"23":1}}],["能够调整编码器专注于当前任务中的目标类别",{"2":{"23":1}}],["能够直接用于现有的白天分割方法",{"2":{"21":1}}],["能够有效弥补低分辨率训练图像与超高分辨率测试图像之间的分辨率差距",{"2":{"20":1}}],["能够精确地细化并将特征图从每一层传递到骨干网络的下一层",{"2":{"18":1}}],["能应对类内差异的敏感性",{"2":{"15":1}}],["获得更好的泛化能力",{"2":{"18":1}}],["4xa6000",{"2":{"34":1}}],["459",{"2":{"34":1}}],["44",{"2":{"23":1}}],["4×或",{"2":{"20":1}}],["4k和6k分辨率变得常见",{"2":{"20":1}}],["4k",{"2":{"20":2}}],["4",{"0":{"39":1,"63":1,"71":1,"79":1,"80":1,"81":1,"82":1},"1":{"80":1,"81":1,"82":1},"2":{"18":2,"23":1,"32":2,"34":1,"40":1,"91":1}}],["1cityscape",{"0":{"74":1}}],["1b数据集",{"2":{"57":1}}],["1b",{"2":{"57":4}}],["1代码解读",{"2":{"51":1}}],["1使用外部查看器时要执行的命令",{"2":{"51":1}}],["1用于反向同步",{"2":{"43":1}}],["1该命令的作用为设置",{"2":{"43":1}}],["1这条命令是设置什么时候对上文设置的辅助文件进行清除",{"2":{"43":1}}],["1设置pdf查看器用于在",{"2":{"51":1}}],["1设置默认的pdf查看器",{"2":{"51":1}}],["1设置为true",{"2":{"43":1}}],["1设置何时使用默认的",{"2":{"43":1}}],["1启用上下文latex菜单",{"2":{"43":1}}],["1后添加上",{"2":{"42":1}}],["1版本",{"2":{"39":1}}],["12此命令是将生成的辅助文件",{"2":{"51":1}}],["1234567",{"2":{"91":1}}],["123456789output",{"2":{"91":1}}],["12345678910设置当",{"2":{"51":1}}],["12345678910111213141516171819output",{"2":{"92":1}}],["123456789101112131415161718192021这串命令则是设置编译完成后要清除掉的辅助文件类型",{"2":{"43":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153写在最后",{"2":{"54":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116注",{"2":{"42":1}}],["1234567891011121314151617181920212223242526272829303132333435363738394041424344此串代码是对编译链进行定义",{"2":{"43":1}}],["1234567891011121314151617181920212223242526272829303132333435363738394041这些代码是定义在下文",{"2":{"43":1}}],["123456789101112131415161718此代码仅为展示所用",{"2":{"50":1}}],["12345678910111213141516",{"2":{"0":1,"45":1}}],["123456789代码解读",{"2":{"51":1}}],["1234此代码是设置使用外部查看器时",{"2":{"51":1}}],["123代码解读",{"2":{"51":1}}],["12",{"2":{"51":1}}],["12这两个命令是设置当文档编译错误时是否弹出显示出错和警告的弹窗",{"2":{"43":1}}],["12其中的",{"2":{"42":1}}],["12656706",{"2":{"36":1}}],["171",{"2":{"34":1}}],["150",{"2":{"34":2}}],["166523064",{"2":{"54":1}}],["16虽然分割性能较差",{"2":{"23":1}}],["16或deit",{"2":{"23":1}}],["16次之",{"2":{"23":1}}],["16骨干网络在所有设置下具有最佳的分割精度",{"2":{"23":1}}],["11m",{"2":{"57":2}}],["118k",{"2":{"34":1}}],["11",{"0":{"54":1},"2":{"23":1,"39":1,"46":1}}],["10mb",{"2":{"47":1}}],["10",{"0":{"53":1},"2":{"45":1}}],["1000合并为训练数据集",{"2":{"20":1}}],["10k",{"2":{"20":1}}],["1k",{"2":{"20":1}}],["1",{"0":{"36":1,"42":1,"45":1,"48":1,"50":1,"60":1,"67":1,"68":2,"69":1,"70":1,"71":1,"73":1,"77":1,"80":1},"1":{"68":1,"69":1,"70":1,"71":1},"2":{"18":1,"20":1,"21":2,"23":2,"26":1,"27":1,"34":2,"35":1,"40":1,"57":1,"65":6}}],["ui界面设置",{"2":{"53":1}}],["ui",{"2":{"40":4}}],["utilizing",{"2":{"34":1}}],["unet",{"0":{"89":1}}],["uni",{"2":{"26":1,"30":1}}],["university",{"0":{"25":1},"2":{"21":1}}],["unseen",{"2":{"23":1}}],["under",{"2":{"21":1}}],["underperforming",{"2":{"21":1}}],["uous",{"2":{"20":1}}],["ultra",{"0":{"19":1},"2":{"20":3}}],["urban",{"2":{"18":1}}],["upon",{"2":{"18":1}}],["usepackage",{"2":{"45":3}}],["used",{"2":{"0":1,"21":1}}],["usedata",{"2":{"0":3}}],["using",{"2":{"8":1,"34":1,"57":1}}],["usage",{"2":{"0":1}}],["gz",{"2":{"51":2}}],["geometry",{"2":{"45":1}}],["generation",{"2":{"34":2}}],["generator",{"2":{"23":1}}],["generate",{"2":{"8":1,"23":1}}],["generalization",{"2":{"20":1,"23":1,"57":1}}],["generaliz",{"2":{"18":1}}],["generalized",{"0":{"17":1},"1":{"18":1},"2":{"18":1}}],["gls",{"2":{"42":1,"43":1,"54":1}}],["glo",{"2":{"42":1,"43":1,"54":1}}],["glg",{"2":{"42":1,"43":1,"54":1}}],["gpu",{"2":{"34":1}}],["gpu内存使用和模型存储要求",{"2":{"18":1}}],["gt",{"2":{"34":3,"46":2,"65":1}}],["gradual",{"2":{"34":3}}],["groups=1",{"2":{"65":1}}],["groups",{"2":{"34":1,"65":1}}],["grouping",{"0":{"24":1},"1":{"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1},"2":{"26":3,"30":1,"32":1}}],["gopt在准确性和效率上达到了最佳平衡",{"2":{"32":1}}],["gopt",{"2":{"26":2,"27":2,"30":1}}],["g",{"2":{"23":1,"50":1,"51":1,"54":1}}],["gap",{"2":{"20":1}}],["git下载",{"2":{"21":1}}],["git访问",{"2":{"18":1}}],["git",{"2":{"18":2,"21":1}}],["github",{"2":{"18":3,"20":2,"21":2,"34":2,"43":1,"45":1}}],["hout=",{"2":{"65":1}}],["however",{"2":{"23":1}}],["hello",{"2":{"45":1}}],["heiti",{"2":{"45":1}}],["here",{"2":{"37":1,"43":1,"45":1,"48":1}}],["http",{"2":{"36":1}}],["https",{"2":{"18":2,"20":1,"21":1,"34":1,"36":1,"57":1}}],["html",{"2":{"36":2}}],["hin−1",{"2":{"65":1}}],["hierarchical",{"2":{"34":5}}],["highlighted",{"2":{"91":2}}],["highlighting",{"0":{"91":1},"2":{"91":2}}],["high",{"0":{"19":2},"2":{"20":3}}],["humans",{"2":{"20":1,"23":1}}],["has",{"2":{"34":1}}],["hard",{"2":{"32":1}}],["harness",{"2":{"18":2}}],["harnessing",{"0":{"17":1},"1":{"18":1}}],["have",{"2":{"8":1,"21":1}}],["缓解空间感知偏差",{"2":{"16":1}}],["缓解骨干网络的固有偏差",{"2":{"12":1}}],["中",{"2":{"43":1}}],["中的",{"2":{"43":1}}],["中文语言环境配置",{"0":{"38":1}}],["中进行泛化",{"2":{"23":1}}],["中科院",{"0":{"23":1}}],["中评估多种vfms",{"2":{"18":1}}],["中利用视觉基础模型",{"2":{"18":1}}],["中国科学技术大学",{"0":{"18":1}}],["中国科学院",{"0":{"7":1}}],["中固有偏差",{"2":{"16":1}}],["结合部分掩码生成器",{"2":{"23":1}}],["结合语义提示转移",{"2":{"23":1}}],["结合编码器",{"2":{"21":1}}],["结论与不足",{"2":{"34":1}}],["结论",{"0":{"16":1},"2":{"20":1,"21":1,"32":1}}],["结果显示",{"2":{"15":1}}],["结果表明gopt仅训练不到1",{"2":{"30":1}}],["结果表明crm性能更好",{"2":{"20":1}}],["结果表明",{"2":{"15":1}}],["这时候需要对边缘进行裁切或者补零",{"2":{"61":1}}],["这时可以使用外部查看器进行查看",{"2":{"47":1}}],["这要我们就可以把每一个像素的预测看成是一个分类任务",{"2":{"61":1}}],["这里的快捷键为默认设置",{"2":{"46":1}}],["这里就不作赘述",{"2":{"37":1}}],["这个模型被特别设计并训练为能够接受简单提示",{"2":{"57":1}}],["这个时候可能就是由于辅助文件没有进行及时更新的缘故",{"2":{"43":1}}],["这个选项",{"2":{"37":1}}],["这个选项一定要选中",{"2":{"36":1}}],["这就意味着",{"2":{"43":1}}],["这项技术的核心难点在于如何有效融合不同模态",{"2":{"27":1}}],["这种固定参数的特征编码器往往对类别不敏感",{"2":{"23":1}}],["这种固定的编码器通常是类别无关的",{"2":{"23":1}}],["这种关系不足以准确匹配",{"2":{"12":1}}],["这是一个自动驾驶数据集",{"2":{"21":1}}],["这是因为仅依赖查询图像本身的前景分布会使模型偏向已知类别的区域",{"2":{"15":1}}],["这些场景光照充足且均匀",{"2":{"21":1}}],["这限制了模型在实际应用中对超高分辨率数据的处理能力",{"2":{"20":1}}],["这在人像照片后期处理",{"2":{"20":1}}],["这样的操作称为上采样",{"2":{"65":1}}],["这样可以帮助网络在复杂多变的光照条件下持续准确地识别语义",{"2":{"21":1}}],["这样",{"2":{"18":1}}],["59",{"2":{"34":1}}],["5k",{"2":{"34":2}}],["500步时将学习率降至十分之一",{"2":{"20":1}}],["500和37",{"2":{"20":1}}],["50作为编码器eθ",{"2":{"20":1}}],["572张具有超过1000个语义类别的图像",{"2":{"20":1}}],["5",{"0":{"40":1,"64":1},"2":{"15":1,"40":1}}],["5i和coco",{"2":{"9":1,"12":1,"16":1,"23":4}}],["5i",{"2":{"8":1,"14":1}}],["和输入内部插",{"2":{"65":1}}],["和区域的交并比",{"2":{"64":1}}],["和计算机视觉领域的发展现状与需求",{"2":{"57":1}}],["和对应的数据集",{"2":{"57":1}}],["和5",{"2":{"23":1}}],["和4",{"2":{"23":1}}],["和3",{"2":{"23":1}}],["和1",{"2":{"23":1}}],["和平均精度",{"2":{"20":1}}],["和",{"2":{"18":1,"34":4,"36":1,"43":1,"52":1}}],["和类内差异表示",{"2":{"15":1}}],["和双分类模块",{"2":{"15":1,"16":1}}],["和双重分类模块",{"2":{"9":1}}],["如交互式分割",{"2":{"57":1}}],["如需写入到",{"2":{"50":1}}],["如上图所示",{"2":{"36":1}}],["如下图所示",{"2":{"38":1}}],["如下图",{"2":{"36":1,"46":1,"52":1}}],["如下采样",{"2":{"20":1}}],["如果bias=true",{"2":{"65":1}}],["如果出现",{"2":{"46":1}}],["如果使用onbuilt命令",{"2":{"43":1}}],["如果说论文中有很多图片或者其他元素没有嵌入字体的话",{"2":{"43":1}}],["如果您对此不感兴趣",{"2":{"43":1}}],["如果您日后需要在上述代码之后再添加其他代码",{"2":{"42":1}}],["如果您需要个性化程度高的话",{"2":{"36":1}}],["如果您想了解",{"2":{"36":1}}],["如果下载速度过慢",{"2":{"36":1}}],["如图像",{"2":{"27":1}}],["如计算机视觉",{"2":{"23":1}}],["如在gan框架中学习跨域不变表示",{"2":{"21":1}}],["如egnet",{"2":{"21":1}}],["如deeplab系列引入空洞空间金字塔池化",{"2":{"21":1}}],["如使用预训练或低分辨率训练测试",{"2":{"20":1}}],["如",{"2":{"20":1}}],["如针对1k",{"2":{"20":1}}],["如clip和align利用对比学习训练文本和图像编码器",{"2":{"57":1}}],["如clip和align利用对比学习训练文本和图像编码器实现零样本泛化",{"2":{"57":1}}],["如clip",{"2":{"18":1}}],["如原始的普通注意力",{"2":{"15":1}}],["如动态调整分类器权重",{"2":{"11":1}}],["且生成的边界不如一些计算密集型的",{"2":{"57":1}}],["且现有模型在泛化能力和处理模糊提示方面存在不足",{"2":{"57":1}}],["且现有方法难以实现强大的泛化能力",{"2":{"57":1}}],["且现有的参数高效微调策略大多不适用于dgss",{"2":{"18":1}}],["且性能随模型规模",{"2":{"57":1}}],["且同样支持双向同步",{"2":{"52":1}}],["且根据需要关闭标签",{"2":{"52":1}}],["且根据笔者使用来看",{"2":{"47":1}}],["且侧面带有书签",{"2":{"52":1}}],["且支持双向同步功能",{"2":{"47":1}}],["且需要为英文路径",{"2":{"43":1}}],["且弹窗弹出比较烦人",{"2":{"43":1}}],["且代码设置可以直接克隆别人的代码到自己的编辑器中",{"2":{"40":1}}],["且所有引用在文中或文末注明了来源",{"2":{"35":1}}],["且",{"2":{"35":1}}],["且因样本标注有限",{"2":{"28":1}}],["且可扩展到跨领域",{"2":{"23":1}}],["且这一问题未得到实质性解决",{"2":{"23":1}}],["且flops和参数更少",{"2":{"20":1}}],["且对gpu内存需求大",{"2":{"20":1}}],["且依赖复杂数据增强和领域不变特征提取策略",{"2":{"18":1}}],["且前馈网络在略微增加计算成本的情况下保留了更多特征细节",{"2":{"15":1}}],["且参数数量较少",{"2":{"12":1}}],["作为外部查看器",{"2":{"47":1}}],["作为",{"2":{"36":1}}],["作为一种强大的排版系统",{"2":{"35":1}}],["作为前馈网络",{"2":{"15":1}}],["作者希望这项工作能为小样本场景下的编码器设计提供新视角",{"2":{"23":1}}],["作者在摒弃以往冻结编码器以泛化到未见类别的小样本分割",{"2":{"23":1}}],["作者认为理想的fss特征编码器应具有类别感知能力",{"2":{"23":1}}],["作者引入rein微调方法",{"2":{"18":1}}],["作者评估并利用vfms进行dgss研究",{"2":{"18":1}}],["作者提出了用于开放词汇语义分割的sed方法",{"2":{"34":1}}],["作者提出了用于多模态图像分割的参数高效视觉调优框架gopt",{"2":{"32":1}}],["作者提出了用于超高清图像分割细化的连续细化模型",{"2":{"20":1}}],["作者提出了一种新颖的夜间语义分割范式",{"2":{"21":1}}],["作者提出了一种基于transformer的自适应原型匹配网络",{"2":{"16":1}}],["作者提出了nightcity",{"2":{"21":1}}],["作者提出了连续细化模型",{"2":{"20":1}}],["作者提出评估vfms在dgss中的性能以及如何有效利用vfms的问题",{"2":{"18":1}}],["作者提出一种基于transformer的自适应原型匹配网络",{"2":{"10":1}}],["+outputpadding",{"2":{"65":2}}],["+kernelsize",{"2":{"65":2}}],["+点击",{"2":{"54":1}}],["+",{"2":{"15":2,"36":1,"40":1}}],["实例分割模型",{"2":{"62":1}}],["实例分割",{"2":{"60":1}}],["实例分割等",{"2":{"57":1}}],["实时计算且能处理歧义",{"2":{"57":1}}],["实现",{"2":{"65":1}}],["实现零样本泛化",{"2":{"57":1}}],["实现最多4",{"2":{"34":1}}],["实现更精确的分割",{"2":{"23":1}}],["实现更精准预测",{"2":{"21":1}}],["实现类别感知增强",{"2":{"23":1}}],["实现细节",{"2":{"20":1}}],["实现了精确分割",{"2":{"15":1,"16":1}}],["实验结果",{"2":{"34":1}}],["实验结果表明",{"2":{"12":1,"23":1}}],["实验设定",{"2":{"34":1}}],["实验过程",{"0":{"31":1,"32":1}}],["实验验证",{"2":{"30":1}}],["实验数据显示",{"2":{"27":1}}],["实验步骤",{"2":{"20":1}}],["实验表明其在超高清图像上的分割效果最佳",{"2":{"20":1}}],["实验表明",{"2":{"16":1,"18":1,"20":1}}],["实验",{"0":{"13":1},"1":{"14":1,"15":1},"2":{"21":1,"23":1}}],["减少参数冗余",{"2":{"18":1}}],["减少了背景干扰",{"2":{"15":1}}],["减轻背景干扰",{"2":{"12":1}}],["减轻fss中的背景干扰",{"2":{"10":1}}],["31",{"2":{"34":1}}],["36",{"2":{"23":1}}],["38",{"2":{"23":1}}],["3",{"0":{"38":1,"62":1,"70":1,"75":1,"76":1,"77":1,"78":1,"82":1},"1":{"77":1,"78":1},"2":{"15":2,"23":3,"35":1,"65":4}}],["61",{"2":{"23":1}}],["6k",{"2":{"20":3}}],["6",{"0":{"41":1,"42":1,"43":1},"1":{"42":1,"43":1},"2":{"15":1,"32":1,"34":2,"42":1}}],["2编译链",{"2":{"46":1}}],["2k",{"2":{"34":1}}],["2k分辨率图像的方法",{"2":{"20":1}}],["27",{"2":{"23":1}}],["25×10⁻⁴",{"2":{"20":1}}],["2020",{"2":{"45":1}}],["20",{"2":{"34":1}}],["20k",{"2":{"34":1}}],["2012数据集上",{"2":{"20":1}}],["2012数据集上进行评估",{"2":{"20":1}}],["20i数据集上分别实现了4",{"2":{"23":1}}],["20i数据集上分别实现了3",{"2":{"23":1}}],["20i数据集上分别实现了2",{"2":{"23":1}}],["20i数据集上分别实现了0",{"2":{"23":1}}],["20i数据集上以最少的参数达到了最先进的性能",{"2":{"16":1}}],["20i数据集上进行了大量实验",{"2":{"9":1}}],["20i两个基准数据集上取得了优于现有方法的性能",{"2":{"12":1}}],["20i",{"2":{"8":1,"14":1}}],["2",{"0":{"37":1,"43":1,"46":1,"49":1,"50":1,"51":2,"61":1,"69":1,"72":1,"73":1,"74":1,"75":1,"78":1,"81":1},"1":{"50":1,"51":1,"73":1,"74":1,"75":1},"2":{"15":1,"21":2,"23":2,"35":1,"42":2,"43":2,"45":2,"54":2,"65":2}}],["91",{"2":{"23":1}}],["96",{"2":{"23":1}}],["9",{"0":{"52":1},"2":{"15":2,"43":1}}],["三通道的图像",{"2":{"61":1}}],["三种deit变体在11个块时效果最佳",{"2":{"23":1}}],["三个主要模块",{"2":{"15":1}}],["三是分类阶段",{"2":{"10":1}}],["该数据集包括10亿个掩码和1100万张图像",{"2":{"57":1}}],["该软件的优点在于在具有",{"2":{"47":1}}],["该快捷键为默认设置",{"2":{"46":1}}],["该框架包含两大创新模块",{"2":{"27":1}}],["该范式模仿人类视觉感知模式",{"2":{"23":1}}],["该方案构建了一种动态的类别感知提示机制",{"2":{"23":1}}],["该方法能够以参数高效的方式利用vfm来解决dgss任务",{"2":{"18":1}}],["该方法在pascal",{"2":{"16":1}}],["该方法在降低计算复杂度的同时保持了较高的准确性",{"2":{"15":1}}],["该方法包含目标增强模块",{"2":{"15":1}}],["该子集包含314张夜间训练图像和31张验证图像",{"2":{"21":1}}],["该模块能够学习语义与光照之间的关系",{"2":{"21":1}}],["该模型在pascal",{"2":{"12":1}}],["该模型主要包含以下三个模块",{"2":{"12":1}}],["该模型包含三个模块",{"2":{"9":1}}],["该网络包含目标增强模块",{"2":{"16":1}}],["组件分析",{"2":{"15":1,"23":1}}],["导致路径已经是中文了",{"2":{"43":1}}],["导致模态间知识共享和模态内信息处理失衡",{"2":{"28":1}}],["导致物体外观随光照变化",{"2":{"21":1}}],["导致对未知类别的分割失败",{"2":{"15":1}}],["导致难以准确定位目标类别",{"2":{"12":1}}],["导致注意力偏差",{"2":{"12":1}}],["忽略了目标对象的空间一致性",{"2":{"12":1}}],["忽略空间信息",{"2":{"10":1}}],["由图像编码器",{"2":{"57":1}}],["由内转外操作相同",{"2":{"53":1}}],["由编辑器根据情况自动设置",{"2":{"51":1}}],["由于想要看到",{"2":{"47":1}}],["由于进行测试的文件中涉及参考文献的引用",{"2":{"46":1}}],["由于",{"2":{"36":1,"43":1}}],["由于深度学习在计算机视觉领域的快速发展",{"2":{"10":1}}],["由类内差异表示和双语义感知注意力机制两个关键部分组成",{"2":{"12":1}}],["双语义感知注意力",{"2":{"15":1}}],["双语义感知注意力机制通过两层约束",{"2":{"12":1}}],["双分类模块",{"2":{"12":1,"15":1}}],["双约束聚合模块",{"2":{"12":1,"15":2,"16":1}}],["双重约束聚合模块",{"2":{"9":1}}],["替代标准多层感知器",{"2":{"12":1}}],["用一句话来解释",{"2":{"65":1}}],["用作下文",{"2":{"43":1}}],["用渐进式融合解码器生成高分辨率特征图进行分割",{"2":{"34":1}}],["用于自动驾驶场景",{"0":{"74":1}}],["用于反向同步的内部查看器的键绑定",{"2":{"54":1}}],["用于配置编译链",{"2":{"54":1}}],["用于开放词汇语义分割",{"2":{"34":1}}],["用于多模态图像分割任务",{"2":{"30":1}}],["用于调整编码器以聚焦不同fss任务中的特定对象",{"2":{"23":1}}],["用于更有效的训练和验证评估",{"2":{"21":1}}],["用于少样本语义分割",{"2":{"12":1}}],["用可逆神经网络",{"2":{"12":1}}],["倾向于提取与当前任务无关的特征",{"2":{"12":1}}],["存在图形模型依赖低级别颜色边界",{"2":{"20":1}}],["存在固有偏差",{"2":{"12":1}}],["存在三方面问题",{"2":{"10":1}}],["任务创新",{"2":{"57":1}}],["任务中",{"2":{"18":1}}],["任务",{"2":{"12":1}}],["研究结论",{"2":{"23":1}}],["研究方法",{"2":{"20":1,"34":1}}],["研究思路清晰",{"2":{"18":1}}],["研究思路",{"2":{"18":1}}],["研究动机",{"2":{"18":1}}],["研究现状",{"0":{"11":1,"29":1},"2":{"18":1,"20":1,"21":1,"23":1,"34":1,"57":1}}],["研究背景",{"0":{"10":1,"28":1},"2":{"20":1,"21":1,"23":1,"34":1,"57":1}}],["以解决新数据分布下的一系列下游分割问题",{"2":{"57":1}}],["以解决现有方法在整合模态间信息和保留各模态特定模式方面的挑战",{"2":{"30":1}}],["以解决现有fss模型存在的固有偏差",{"2":{"12":1}}],["以解决现有fss模型存在的问题",{"2":{"10":1}}],["以下展示由外部查看转为内部查看的操作",{"2":{"53":1}}],["以下为具体操作",{"2":{"52":1}}],["以下是该模型的详细介绍",{"2":{"30":1}}],["以此来进行更多更好的文字编写",{"2":{"54":1}}],["以此来选中",{"2":{"46":1}}],["以此测试其是否支持中英文",{"2":{"45":1}}],["以此可以随时对自己的配置代码进行更改",{"2":{"35":1}}],["以免后期使用产生奇怪的问题",{"2":{"36":1}}],["以少量提示参数促进模型快速收敛",{"2":{"30":1}}],["以深度多模态融合为主",{"2":{"29":1}}],["以继承基础模型的强大特征提取能力",{"2":{"27":1}}],["以生成类别感知特征",{"2":{"23":1}}],["以动态驱动编码器关注特定对象",{"2":{"23":1}}],["以极少额外参数助力现有方法提升性能",{"2":{"21":1}}],["以实现高效",{"2":{"20":1}}],["以较少可训练参数有效利用vfms",{"2":{"18":1}}],["以及构建数据引擎收集大规模数据集",{"2":{"57":1}}],["以及训练速度",{"2":{"18":1}}],["以及用可逆神经网络",{"2":{"15":1}}],["以有效利用vfms的强大能力",{"2":{"18":1}}],["以利用更强预训练模型和更少可训练参数实现更优泛化能力为动机",{"2":{"18":1}}],["以高效利用vfms解决dgss问题",{"2":{"18":1}}],["以应对少样本语义分割",{"2":{"16":1}}],["以往的分割细化方法",{"2":{"20":1}}],["以往的fss方法由于固有偏差",{"2":{"9":1}}],["以往dgss方法着重提升模型在多未见领域的预测准确性",{"2":{"18":1}}],["以往工作依赖预训练骨干网络直接提取的特征",{"2":{"12":1}}],["易优先提取无关特征",{"2":{"10":1}}],["匹配和分类三个阶段",{"2":{"10":1}}],["执行过程分特征提取",{"2":{"10":1}}],["被提出用于模拟有限数据和多类别的真实世界场景",{"2":{"10":1}}],["在分割任务中",{"2":{"64":1}}],["在语义分割而言",{"2":{"61":1}}],["在特定领域",{"2":{"57":1}}],["在特征提取阶段",{"2":{"12":1}}],["在提供多个提示点时",{"2":{"57":1}}],["在提示调优过程中",{"2":{"30":1}}],["在图像分割方面",{"2":{"57":1}}],["在nlp中",{"2":{"57":1}}],["在构建失败后清除辅助文件",{"2":{"54":1}}],["在编译生成的",{"2":{"46":1}}],["在编译链中定义的命令出现在了vscode右侧的工具栏中",{"2":{"43":1}}],["在编辑器页面上端进行编译链选择",{"2":{"46":1}}],["在检测任何依赖项中的文件更改",{"2":{"43":1}}],["在打开方式中选择",{"2":{"36":1}}],["在对语义相近的类别进行分类和分割时存在困难",{"2":{"34":1}}],["在解码器中引入类别早期拒绝方案",{"2":{"34":1}}],["在零样本任务上表现出色",{"2":{"34":1}}],["在自然语言处理中表现出色",{"2":{"29":1}}],["在自然语言处理领域取得成功",{"2":{"18":1}}],["在保留模态内独特空间信息的同时",{"2":{"27":1}}],["在使用一致的特征编码器设置下",{"2":{"23":1}}],["在变压器编码器的最后l个块中进行提示增强",{"2":{"23":1}}],["在没有spt和pmg持续增强其类别感知能力的情况下",{"2":{"23":1}}],["在pascal",{"2":{"23":4}}],["在多个数据集",{"2":{"34":1}}],["在多个数据集和三种泛化设置下进行实验",{"2":{"18":1}}],["在多个下游多模态图像分割任务",{"2":{"30":1}}],["在多个任务和基准上取得新的最优性能",{"2":{"23":1}}],["在白天场景下从50个不同城市采集",{"2":{"21":1}}],["在各种夜间分割任务的实验中",{"2":{"21":1}}],["在性能和速度方面表现出色",{"2":{"20":1}}],["在重新标注的pascal",{"2":{"20":1}}],["在全景分割和实体分割实验中",{"2":{"20":1}}],["在高分辨率图像上运行速度更快",{"2":{"20":1}}],["在big数据集上对比crm",{"2":{"20":1}}],["在实验中从连续范围中选择4个缩放比例进行细化",{"2":{"20":1}}],["在22",{"2":{"20":1}}],["在神经网络中用于表示对象或场景",{"2":{"20":1}}],["在骨干网络层间嵌入该机制",{"2":{"18":1}}],["在本文中",{"2":{"18":1}}],["在本研究中",{"2":{"9":1}}],["在目标类别存在显著类内差异时",{"2":{"12":1}}],["在前馈过程中保留更细粒度的特征",{"2":{"12":1}}],["在fss中得到应用",{"2":{"11":1}}],["在这种情况下",{"2":{"10":1}}],["我们可以发现",{"2":{"65":1}}],["我们假设模型的分类数量为",{"2":{"61":1}}],["我们先要对模型有一个大的了解",{"2":{"61":1}}],["我们将在segment",{"2":{"57":1}}],["我们成功构建了迄今为止最大的图像分割数据集",{"2":{"57":1}}],["我们推出了segment",{"2":{"57":1}}],["我们的源代码可以通过https",{"2":{"34":1}}],["我们的逐渐融合解码器采用自上而下的结构",{"2":{"34":1}}],["我们在多个任务中测试了该模型",{"2":{"57":1}}],["我们在多个开放词汇语义分割数据集上进行了实验",{"2":{"34":1}}],["我们在解码器中引入了类别早期拒绝方案",{"2":{"34":1}}],["我们在pascal",{"2":{"9":1}}],["我们研发了分组提示调优框架",{"2":{"27":1}}],["我们引入了",{"2":{"21":1}}],["我们通过定量的性能评估和可视化结果",{"2":{"20":1}}],["我们提出的",{"2":{"21":1}}],["我们提出的动机是",{"2":{"18":1}}],["我们提出了",{"2":{"20":1}}],["我们提出了一种高效的微调方法",{"2":{"18":1}}],["我们提出了一种基于transformer的自适应原型匹配网络",{"2":{"9":1}}],["我们首先在领域泛化语义分割",{"2":{"18":1}}],["帮助缓解空间感知偏差",{"2":{"9":1}}],["强化了约束效果",{"2":{"9":1}}],["建立更为稳定的匹配关系",{"2":{"9":1}}],["翻译",{"0":{"9":1,"27":1},"2":{"18":1,"20":1,"21":1,"23":1,"34":1,"57":1}}],["lt",{"2":{"26":1}}],["l",{"2":{"23":1,"34":1,"50":1,"51":1,"54":1}}],["learning",{"2":{"26":1}}],["learn",{"2":{"21":1,"26":1}}],["level",{"2":{"34":3}}],["levels",{"2":{"20":1,"34":1}}],["leveraging",{"2":{"18":1}}],["lastused",{"2":{"42":1,"43":2,"54":1}}],["latex配置代码解读",{"0":{"43":1}}],["latex配置代码展示",{"0":{"42":1}}],["latexmk",{"2":{"42":5,"43":6,"54":5}}],["latex环境的代码配置",{"0":{"41":1},"1":{"42":1,"43":1}}],["latex的支持插件",{"0":{"39":1}}],["latex",{"0":{"39":1},"2":{"35":1,"36":1,"39":1,"42":22,"43":23,"45":1,"46":1,"50":6,"51":8,"54":26}}],["language",{"2":{"26":1,"34":1,"38":1}}],["label",{"2":{"23":1}}],["laboratory",{"2":{"21":1}}],["largest",{"2":{"57":1}}],["large",{"2":{"23":1}}],["layer",{"2":{"18":2,"34":1}}],["loop",{"2":{"57":1}}],["loner",{"2":{"45":1}}],["lot",{"2":{"42":1,"43":1,"54":1}}],["lof",{"2":{"42":1,"43":1,"54":1}}],["log",{"2":{"39":1,"42":1,"43":1,"54":1}}],["low",{"2":{"20":1}}],["local",{"2":{"8":1,"34":1}}],["like",{"2":{"91":1}}],["licensed",{"2":{"57":1}}],["lipsum",{"2":{"45":2}}],["liuliang1999",{"2":{"36":1}}],["live",{"0":{"36":1},"2":{"36":5}}],["lies",{"2":{"26":1}}],["linguistic",{"2":{"23":1}}],["linear",{"2":{"34":1}}],["line",{"2":{"23":1,"42":3,"43":3,"50":1,"51":2,"54":5,"91":1}}],["linked",{"2":{"18":1}}],["light",{"2":{"21":2}}],["lighting",{"2":{"21":5}}],["limited",{"2":{"8":1}}],["list",{"2":{"5":1,"36":1,"93":1}}],["even",{"2":{"57":1}}],["evaluate",{"2":{"57":1}}],["evaluation",{"2":{"20":1}}],["eva02和dinov2等五种不同训练策略和数据集的vfms进行评估",{"2":{"18":1}}],["error",{"2":{"42":4,"43":4,"54":4}}],["era",{"2":{"23":1}}],["employs",{"2":{"34":2}}],["early",{"2":{"34":4}}],["each",{"2":{"18":2,"23":1,"26":1}}],["elaborated",{"2":{"23":1}}],["especially",{"2":{"23":1}}],["establish",{"2":{"8":1}}],["e",{"2":{"21":1,"23":1}}],["ec",{"2":{"20":1}}],["engine",{"2":{"57":1}}],["end",{"2":{"45":2}}],["enable",{"2":{"57":1}}],["enabled",{"2":{"42":1,"43":1,"54":1}}],["enables",{"2":{"21":1}}],["encoder",{"0":{"33":1},"1":{"34":1},"2":{"23":1,"34":4}}],["encoders",{"2":{"23":2}}],["entangled",{"2":{"21":1}}],["entity",{"2":{"20":2}}],["enhance",{"2":{"8":1,"23":1}}],["enhancement",{"0":{"22":1},"1":{"23":1},"2":{"8":1,"12":1}}],["efficacy",{"2":{"34":1}}],["efficient",{"2":{"23":1,"57":1}}],["efficiently",{"2":{"18":2}}],["effortlessly",{"2":{"23":1}}],["effective",{"2":{"20":1,"26":1}}],["effectiveness",{"2":{"8":1,"32":1}}],["exe文件所在位置",{"2":{"51":1}}],["exe",{"2":{"50":2,"51":3,"54":2}}],["existing",{"2":{"21":1,"26":1,"34":2}}],["extensions",{"2":{"90":1,"93":1}}],["extension",{"0":{"90":1},"1":{"91":1,"92":1,"93":1}}],["extensive",{"2":{"8":1,"18":1,"21":1,"26":1}}],["external",{"2":{"50":5,"51":10,"54":7}}],["extraction",{"2":{"21":1}}],["extra",{"2":{"18":1,"20":1}}],["export",{"2":{"91":1}}],["explicit",{"2":{"26":1}}],["explicitly",{"2":{"21":2}}],["explore",{"2":{"34":1}}],["exploring",{"2":{"8":1}}],["exploit",{"2":{"23":1}}],["experiments",{"0":{"13":1,"15":1},"1":{"14":1,"15":1},"2":{"8":1,"18":1,"21":1,"23":2,"26":1,"34":1,"57":1}}],["examples",{"0":{"0":1,"90":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1,"91":1,"92":1,"93":1}}],["warning",{"2":{"42":1,"43":1,"54":1,"92":6}}],["win−1",{"2":{"65":1}}],["windows",{"2":{"36":2}}],["will",{"2":{"57":1}}],["wiki",{"2":{"43":1}}],["withspt",{"2":{"23":1}}],["without",{"2":{"18":1,"21":1,"34":1}}],["within",{"2":{"18":3,"23":1}}],["with",{"0":{"13":1,"14":1,"21":1,"24":1},"1":{"14":1,"15":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1},"2":{"18":2,"20":1,"21":2,"23":2,"34":3,"57":2,"91":1}}],["www",{"2":{"36":1}}],["what",{"2":{"57":3}}],["when",{"2":{"34":1}}],["whu",{"2":{"31":1}}],["which",{"2":{"23":1,"26":2,"34":3}}],["while",{"2":{"21":1,"26":1}}],["wout=",{"2":{"65":1}}],["would",{"2":{"23":1}}],["world",{"2":{"45":1}}],["work",{"2":{"21":1}}],["workshop插件",{"2":{"39":1}}],["workshop",{"2":{"39":1,"42":13,"43":14,"50":6,"51":8,"54":19}}],["workshop安装",{"0":{"39":1}}],["works",{"2":{"0":1,"21":1}}],["w1oves",{"2":{"18":3,"21":2}}],["weak",{"2":{"23":1,"26":1}}],["well",{"2":{"20":1}}],["we",{"2":{"8":1,"18":2,"20":2,"21":2,"26":1,"34":2,"57":4}}],["nn",{"2":{"65":1}}],["nij表示像素点属于分类i被预测为分类j的像素点数量",{"2":{"64":1}}],["night进行补充实验",{"2":{"21":1}}],["nightcity",{"2":{"21":3}}],["nightlab等",{"2":{"21":1}}],["night",{"0":{"21":1},"2":{"21":6}}],["n",{"2":{"61":4}}],["nlp",{"2":{"57":2}}],["numerous",{"2":{"57":1}}],["number",{"2":{"8":1,"32":1}}],["name",{"2":{"42":10,"43":10,"54":10}}],["named",{"2":{"34":1}}],["namely",{"2":{"18":1}}],["nyudv2",{"2":{"31":1}}],["np",{"2":{"23":1}}],["never",{"2":{"42":1,"43":3,"54":1}}],["new",{"2":{"23":1,"57":2}}],["negligible",{"2":{"21":1}}],["nerf",{"2":{"20":1}}],["needs",{"2":{"20":1}}],["next",{"2":{"18":1}}],["network",{"0":{"6":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1},"2":{"8":1,"12":1,"21":1}}],["now",{"2":{"38":1}}],["no",{"2":{"34":1}}],["not",{"2":{"26":1}}],["noise",{"2":{"8":1}}],["novel",{"2":{"8":1,"21":1,"23":1}}],["摘要",{"0":{"8":1,"26":1},"2":{"18":1,"20":1,"21":1,"23":1,"34":1,"57":1}}],["💯",{"0":{"7":1},"2":{"59":1}}],["澳门大学",{"0":{"7":1}}],["青海师范大学",{"0":{"7":1}}],["南京信息工程大学",{"0":{"7":1}}],["over",{"2":{"57":1}}],["optional",{"2":{"65":6}}],["optimal",{"2":{"26":1}}],["open",{"0":{"33":1},"1":{"34":1},"2":{"34":4}}],["os",{"2":{"31":1}}],["object",{"2":{"23":1}}],["objects",{"2":{"20":1,"23":2}}],["observation",{"2":{"21":1}}],["omron",{"2":{"20":1}}],["org",{"2":{"36":1}}],["oriented",{"2":{"21":1}}],["or",{"2":{"20":1,"57":1,"65":5}}],["ously",{"2":{"20":1}}],["our",{"2":{"8":1,"20":2,"21":1,"26":1,"34":3,"57":1}}],["output",{"2":{"65":2}}],["outperforms",{"2":{"18":1,"21":1}}],["outdir",{"2":{"42":1,"43":1,"54":1}}],["outdir=",{"2":{"42":1,"43":1,"54":1}}],["out",{"2":{"5":1,"42":1,"43":1,"50":1,"51":1,"54":2,"65":2,"93":1}}],["onbuilt",{"2":{"43":1}}],["onsave",{"2":{"43":1}}],["onfilechange",{"2":{"43":1}}],["onfailed",{"2":{"42":1,"43":2,"54":1}}],["one",{"2":{"26":1}}],["ones",{"2":{"20":1}}],["only",{"2":{"23":1,"26":1}}],["on",{"2":{"8":1,"18":1,"20":1,"21":3,"23":4,"26":2,"34":3,"51":1,"54":1,"57":2}}],["often",{"2":{"57":1}}],["ofour",{"2":{"34":1}}],["ofdecoder",{"2":{"34":1}}],["ofplain",{"2":{"34":1}}],["ofhumanbeings",{"2":{"23":1}}],["of78",{"2":{"18":1}}],["of",{"0":{"13":1,"14":1,"25":2},"1":{"14":1,"15":1},"2":{"0":2,"5":1,"8":4,"18":4,"21":6,"23":5,"26":5,"32":3,"34":3,"57":1,"90":1,"93":1}}],["rcnn",{"2":{"62":1}}],["run",{"2":{"42":2,"43":2,"54":2}}],["runtime",{"0":{"0":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1},"2":{"0":1,"5":1}}],["r",{"2":{"36":1,"50":1,"51":1,"54":1}}],["row",{"2":{"32":2}}],["robust",{"2":{"8":1,"18":1}}],["rgb",{"2":{"26":1,"27":1,"30":3,"31":1,"61":1}}],["return",{"2":{"91":2}}],["retinanet",{"2":{"62":1}}],["retaining",{"2":{"26":1}}],["reuse",{"2":{"50":1,"51":1,"54":1}}],["rejects",{"2":{"34":1}}],["rejection",{"2":{"34":3}}],["recipe",{"2":{"42":1,"43":1,"54":1}}],["recipes中的第一条编译链",{"2":{"43":1}}],["recipes中内容",{"2":{"43":1}}],["recipes",{"2":{"42":1,"43":3,"54":1}}],["recent",{"2":{"26":1}}],["recognize",{"2":{"21":1}}],["recognizes",{"2":{"21":1}}],["reconstruct",{"2":{"20":1}}],["representations",{"2":{"26":1}}],["representation",{"2":{"26":1}}],["remote",{"2":{"23":1}}],["remarkably",{"2":{"18":1}}],["regions",{"2":{"21":1}}],["re",{"2":{"21":1}}],["ref上的",{"2":{"54":1}}],["ref",{"2":{"50":1,"51":3,"54":1}}],["reflectance",{"2":{"21":1}}],["refinenet",{"2":{"62":1}}],["refinement",{"2":{"20":4}}],["refinements",{"2":{"18":1}}],["refines",{"2":{"18":1}}],["responsible",{"2":{"57":1}}],["responding",{"2":{"57":1}}],["respecting",{"2":{"57":1}}],["respect",{"2":{"34":1}}],["resources",{"2":{"50":1,"51":1,"54":1}}],["resolu",{"2":{"20":1}}],["resolution",{"0":{"19":1},"2":{"20":4}}],["restart",{"2":{"38":1}}],["resulting",{"2":{"34":1}}],["results",{"0":{"1":1},"1":{"2":1,"3":1,"4":1},"2":{"0":1,"57":1}}],["research",{"2":{"20":2,"57":1}}],["real",{"2":{"18":1}}],["rein以更少可训练参数显著增强vfms的泛化能力",{"2":{"18":1}}],["rein便在cityscapes数据集上达到了78",{"2":{"18":1}}],["rein显著超越了现有的最先进方法",{"2":{"18":1}}],["rein在微调vfm时",{"2":{"18":1}}],["rein能够在单张图像中为不同的类别生成多样化的细化结果",{"2":{"18":1}}],["rein方法依赖于一组可训练的标记",{"2":{"18":1}}],["rein",{"2":{"18":12}}],["release",{"2":{"57":1}}],["releasing",{"2":{"57":1}}],["relevance",{"2":{"8":1}}],["related",{"2":{"26":1}}],["relationships",{"2":{"8":1}}],["=",{"2":{"0":1,"23":1,"34":3}}],["f",{"2":{"50":4,"51":4,"54":4}}],["fdb",{"2":{"42":1,"43":1,"54":1}}],["fls",{"2":{"42":1,"43":1,"54":1}}],["flectance",{"2":{"21":1}}],["fg",{"2":{"23":1}}],["fsl",{"2":{"23":2}}],["fss旨在用少量标注样本为新类别生成分割模型",{"2":{"11":1}}],["fss遵循元学习框架",{"2":{"10":1}}],["fss",{"2":{"8":2,"9":1,"10":1,"11":1,"12":1,"16":1,"23":9}}],["furthermore",{"2":{"21":1,"26":1}}],["further",{"2":{"21":1}}],["fusion",{"2":{"21":1,"34":3}}],["fully",{"2":{"57":1}}],["full",{"2":{"5":1,"18":2,"26":1,"93":1}}],["fcn结果",{"0":{"86":1}}],["fcn细节",{"0":{"85":1}}],["fcn基本原理",{"0":{"84":1}}],["fcn",{"0":{"83":1},"1":{"84":1,"85":1,"86":1},"2":{"20":1,"21":1,"62":1}}],["far",{"2":{"57":1}}],["false",{"2":{"42":2,"43":2,"54":2}}],["fast",{"2":{"20":1}}],["fact",{"2":{"20":1}}],["framework",{"2":{"21":1,"26":1,"30":1}}],["freeze",{"2":{"18":1}}],["frozen",{"2":{"18":1,"26":1}}],["frontmatter",{"0":{"4":1},"2":{"0":3,"4":1}}],["from",{"2":{"0":1,"18":1,"20":1,"34":1}}],["foster",{"2":{"57":1}}],["focusing",{"2":{"23":1}}],["focus",{"2":{"23":1}}],["foundation",{"0":{"17":1},"1":{"18":1},"2":{"18":1,"26":2,"57":2}}],["forward",{"2":{"50":1,"51":1,"54":1}}],["forwards",{"2":{"18":1}}],["formance",{"2":{"20":1}}],["foreground",{"2":{"8":1}}],["for",{"0":{"6":1,"17":1,"19":1,"22":1,"33":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"18":1,"23":1,"34":1},"2":{"0":1,"5":1,"8":1,"18":4,"20":1,"21":3,"23":4,"26":1,"34":3,"38":1,"43":1,"45":2,"57":2,"93":1}}],["figure",{"2":{"32":2}}],["fixed",{"2":{"23":1}}],["filetypes",{"2":{"42":1,"43":1,"54":1}}],["file",{"2":{"42":3,"43":3,"54":3}}],["files",{"2":{"0":1}}],["fill",{"2":{"20":1}}],["find",{"2":{"57":1}}],["fine一起为夜间分割提供了更优的基准",{"2":{"21":1}}],["fine",{"2":{"18":3,"21":5,"23":1,"26":1}}],["finally",{"2":{"8":1}}],["first",{"2":{"18":1,"43":1}}],["fea",{"2":{"20":1}}],["feature",{"2":{"18":1,"20":1,"23":1,"34":1,"65":2}}],["features",{"2":{"8":2,"21":2,"91":1}}],["fewer",{"0":{"17":1},"1":{"18":1},"2":{"18":2}}],["few",{"0":{"6":1,"22":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"23":1},"2":{"8":1,"9":1,"10":1,"11":1,"12":1,"23":2}}],["v",{"2":{"36":1}}],["vscode的中文环境需要下载插件来进行支持",{"2":{"38":1}}],["vscode下载与安装",{"0":{"37":1}}],["vscode",{"2":{"35":3,"36":1,"37":2,"38":1,"39":1,"43":2,"45":3,"47":1,"51":1,"52":1}}],["vs",{"2":{"32":1,"50":1,"51":2,"54":1}}],["vocabulary",{"0":{"33":1},"1":{"34":1},"2":{"34":3}}],["voc",{"2":{"20":2,"34":3}}],["vfm",{"2":{"18":1}}],["vfms的潜力与挑战",{"2":{"18":1}}],["vfms",{"2":{"18":7}}],["viewer",{"2":{"50":4,"51":4,"54":4}}],["view",{"2":{"42":3,"43":1,"50":6,"51":10,"54":11}}],["visual",{"2":{"23":1,"37":1,"38":1}}],["visualization",{"2":{"20":1}}],["vision",{"0":{"17":1},"1":{"18":1},"2":{"18":1,"26":1,"34":1,"57":1}}],["vitepress",{"2":{"0":2,"90":1,"91":1}}],["validation",{"2":{"34":2}}],["varying",{"2":{"21":1}}],["various",{"2":{"18":2,"21":1,"26":2}}],["va",{"2":{"15":1}}],["vue",{"2":{"0":1}}],["msg",{"2":{"91":2}}],["ms",{"2":{"34":2}}],["msla",{"2":{"15":2}}],["mfnet",{"2":{"31":1}}],["mba提高",{"2":{"20":1}}],["mba",{"2":{"20":1}}],["microsoft",{"2":{"50":1,"51":2,"54":1}}],["mirror",{"2":{"36":1}}],["miktex",{"2":{"36":1}}],["millisecond",{"2":{"34":1}}],["mimics",{"2":{"23":1}}],["miou=1ncl∑inii",{"2":{"64":1}}],["miou精度反而下降",{"2":{"23":1}}],["miou精度随之增加",{"2":{"23":1}}],["miou",{"2":{"18":1,"23":1,"34":1}}],["mitigates",{"2":{"8":1}}],["mlp",{"2":{"12":1,"15":2}}],["mean",{"2":{"64":2}}],["meta",{"0":{"57":1}}],["method",{"2":{"20":1,"34":2}}],["methods",{"2":{"8":1,"18":1,"21":3,"26":1,"34":1}}],["message",{"2":{"39":1,"42":2,"43":2,"54":2}}],["medical",{"2":{"23":1}}],["mechanism",{"2":{"8":1}}],["multiple",{"2":{"34":1}}],["multi",{"0":{"24":1},"1":{"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1},"2":{"8":1,"26":3,"32":1}}],["most",{"2":{"21":1,"23":1,"34":2}}],["motivated",{"2":{"20":1}}],["motivation",{"2":{"18":1}}],["mobilenetv2等旧骨干网络",{"2":{"18":1}}],["mobilenetv2和resnet等经典骨干网络",{"2":{"18":1}}],["modality",{"2":{"26":2}}],["modalities",{"2":{"26":2}}],["modal",{"0":{"24":1},"1":{"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1},"2":{"23":1,"26":7,"30":2,"32":1}}],["module",{"2":{"8":4,"12":3}}],["modules",{"2":{"8":1}}],["modeling",{"2":{"26":1}}],["models",{"0":{"13":1,"17":1},"1":{"14":1,"15":1,"18":1},"2":{"18":2,"23":2,"26":1,"34":1,"57":2}}],["model",{"2":{"8":2,"20":2,"26":3,"34":1,"57":10}}],["more",{"0":{"5":1,"93":1},"2":{"21":1,"23":1,"43":1}}],["markdown",{"0":{"90":1},"1":{"91":1,"92":1,"93":1},"2":{"90":1,"93":1}}],["margin=1in",{"2":{"45":1}}],["macc=1nc1∑iniiti计算每一类分类正确的像素点数和该类的所有像素点数的比例然后求平均",{"2":{"64":1}}],["maketitle",{"2":{"45":1}}],["many",{"2":{"34":1}}],["masks",{"2":{"57":2}}],["mask",{"2":{"23":1,"62":1}}],["map",{"2":{"20":1,"34":5,"65":1}}],["maps",{"2":{"18":1,"34":1}}],["mae",{"2":{"18":3}}],["ma",{"2":{"15":1}}],["matching",{"0":{"6":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1},"2":{"8":2,"12":1}}],["main",{"2":{"0":1,"20":2,"26":1}}],["md```js",{"2":{"91":1}}],["md",{"2":{"0":2,"92":1}}],["id",{"2":{"60":1}}],["idx",{"2":{"42":1,"43":1,"54":1}}],["idr",{"2":{"15":1}}],["irrelevant",{"2":{"23":1}}],["iaparser",{"2":{"21":4}}],["i",{"2":{"21":1}}],["illumination",{"0":{"21":1},"2":{"21":4}}],["iou",{"2":{"20":1,"64":4}}],["ist",{"2":{"42":1,"43":1,"54":1}}],["iso",{"2":{"36":2}}],["issues",{"2":{"26":1}}],["issue",{"2":{"20":1}}],["is",{"2":{"18":1,"20":2,"23":1,"26":4,"34":2,"45":2,"57":3,"92":10}}],["images",{"0":{"19":1},"2":{"20":2,"21":1,"23":1,"57":2}}],["image",{"0":{"24":1},"1":{"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1},"2":{"18":1,"20":3,"26":2,"34":3,"57":2}}],["impressive",{"2":{"57":1}}],["improving",{"2":{"8":1,"26":1}}],["impact",{"2":{"32":1}}],["impeded",{"2":{"21":1}}],["import",{"2":{"0":1}}],["inverse",{"2":{"50":1,"51":1,"54":1}}],["invariant",{"2":{"21":1}}],["info",{"2":{"92":4}}],["information",{"2":{"23":1,"26":2,"32":1,"34":1}}],["inference",{"2":{"34":1}}],["input",{"2":{"34":1,"91":1,"92":1}}],["ind",{"2":{"42":1,"43":1,"54":1}}],["induced",{"2":{"26":1,"30":1}}],["individuals",{"2":{"23":1}}],["inherit",{"2":{"26":1}}],["inherent",{"2":{"8":2}}],["including",{"2":{"23":1}}],["includes",{"2":{"8":1}}],["initialize",{"2":{"23":1}}],["inevitably",{"2":{"23":1}}],["inspired",{"2":{"26":1}}],["instance",{"2":{"50":1,"51":1,"54":1}}],["instances",{"2":{"18":1}}],["install",{"2":{"36":1,"38":1,"39":1}}],["instead",{"2":{"21":1,"34":1}}],["insufficient",{"2":{"21":1}}],["int",{"2":{"65":8}}],["intra",{"2":{"26":1}}],["introduces",{"2":{"26":1}}],["introduced",{"2":{"23":1,"26":1}}],["introduce",{"2":{"18":1,"21":1,"34":1,"57":1}}],["intellisense",{"2":{"42":1,"43":1,"54":1}}],["internal",{"2":{"42":3,"43":1,"54":1}}],["interaction=nonstopmode",{"2":{"42":3,"43":3,"54":3}}],["inter",{"2":{"26":1}}],["interested",{"2":{"23":1}}],["integrating",{"2":{"26":1}}],["into",{"2":{"8":1,"21":1,"34":1,"57":1}}],["inn",{"2":{"12":1,"15":2}}],["in",{"2":{"0":1,"8":2,"18":2,"20":1,"21":3,"23":5,"26":4,"34":4,"57":1,"65":2,"90":1}}],["its",{"2":{"20":1,"57":2}}],["it",{"2":{"0":1,"57":1}}],["cmd",{"2":{"54":1}}],["cmd+鼠标左键单击",{"2":{"43":1}}],["c",{"2":{"46":1}}],["ct照片等",{"2":{"69":1}}],["ctex",{"2":{"45":1}}],["ctrl",{"2":{"43":1,"54":1}}],["cnblogs",{"2":{"36":1}}],["cv",{"2":{"23":1}}],["custom",{"0":{"92":1}}],["cup",{"2":{"30":1,"32":1}}],["cue",{"2":{"21":1}}],["current",{"2":{"0":1,"23":2}}],["channels",{"2":{"65":4}}],["change",{"2":{"39":1}}],["challenge",{"2":{"21":1,"26":1}}],["chinese",{"0":{"25":1},"2":{"38":1}}],["china",{"2":{"21":1}}],["check",{"2":{"5":1,"93":1}}],["cross",{"2":{"23":2,"26":1,"30":1}}],["crop",{"2":{"20":1}}],["crm在低分辨率下能细化出较好的通用掩码",{"2":{"20":1}}],["crm在超高分辨率图像上取得最佳分割结果",{"2":{"20":1}}],["crm和推理分辨率",{"2":{"20":1}}],["crm的细化结果包含更多细节",{"2":{"20":1}}],["crm的总推理时间仍不到cascadepsp的一半",{"2":{"20":1}}],["crm比segfix表现更好",{"2":{"20":1}}],["crm采用多分辨率推理策略",{"2":{"20":1}}],["crm找到",{"2":{"20":1}}],["crm展现出了很强的泛化能力",{"2":{"20":1}}],["crm通过不断地对齐特征图和细化目标",{"2":{"20":1}}],["crm",{"2":{"20":10}}],["clean",{"2":{"42":1,"43":1,"54":1}}],["cli",{"2":{"50":1,"51":1,"54":1}}],["click",{"2":{"37":1,"42":3,"43":5,"45":1,"48":1,"54":1}}],["clip成功后",{"2":{"34":1}}],["clip",{"2":{"18":1,"34":1}}],["class",{"0":{"22":1},"1":{"23":1},"2":{"23":5,"26":3,"30":1}}],["classification",{"2":{"8":1,"12":1}}],["classes",{"2":{"8":1,"23":1}}],["cityscapes",{"2":{"18":1,"21":1}}],["capabilities",{"2":{"57":1}}],["captures",{"2":{"34":1}}],["cat",{"2":{"34":1}}],["category",{"2":{"34":3}}],["categories",{"2":{"18":1,"34":3}}],["called",{"2":{"23":1}}],["cam和隐式函数",{"2":{"20":1}}],["cascadepsp",{"2":{"20":2}}],["cascade",{"2":{"20":1}}],["cannot",{"2":{"20":1}}],["can",{"2":{"0":1,"21":2,"23":1,"57":2}}],["collection",{"2":{"57":1}}],["corresponding",{"2":{"57":1}}],["correlation",{"2":{"21":1}}],["cor",{"2":{"57":1}}],["core",{"2":{"26":1}}],["cover",{"2":{"21":1}}],["coarse",{"2":{"20":1}}],["cost",{"2":{"20":1,"34":5}}],["code插件",{"2":{"38":1}}],["code呢",{"2":{"35":1}}],["code",{"2":{"18":1,"20":1,"21":1,"34":1,"37":1,"50":2,"51":3,"54":2}}],["com网站发布segment",{"2":{"57":1}}],["command的参数",{"2":{"51":1,"54":1}}],["command",{"2":{"42":4,"43":4,"50":2,"51":2,"54":6}}],["common",{"2":{"20":1,"26":2}}],["computer",{"2":{"26":1,"57":1}}],["computational",{"2":{"34":1}}],["computation",{"2":{"20":2}}],["competitive",{"2":{"23":1,"57":1}}],["complexity",{"2":{"34":1}}],["complementary",{"2":{"23":1}}],["complicated",{"2":{"21":2}}],["component",{"2":{"21":2}}],["components",{"2":{"21":2}}],["comprises",{"2":{"21":1,"34":1}}],["comparison",{"0":{"14":1},"2":{"23":1}}],["compared",{"0":{"13":1},"1":{"14":1,"15":1},"2":{"23":1,"34":1}}],["com",{"2":{"18":3,"20":2,"21":2,"34":3,"36":1,"54":1,"57":2}}],["coco数据集",{"0":{"75":1}}],["coco",{"2":{"8":1,"14":1,"34":1}}],["convtranspose2d",{"2":{"65":1}}],["convnext",{"2":{"34":2}}],["conjunction",{"2":{"23":1}}],["confused",{"2":{"21":1}}],["confirm",{"2":{"8":1}}],["concretely",{"2":{"21":1}}],["conditions",{"2":{"21":2}}],["containers",{"0":{"92":1}}],["contrast",{"2":{"23":1}}],["contin",{"2":{"20":1}}],["continuously",{"2":{"20":1}}],["continu",{"2":{"20":1}}],["context",{"2":{"8":1,"18":1,"34":2}}],["consistently",{"2":{"21":1}}],["consideration",{"2":{"20":1}}],["constructs",{"2":{"23":1}}],["constraints",{"2":{"8":1}}],["constraint",{"2":{"8":1,"12":1}}],["const",{"2":{"0":1}}],["d",{"2":{"30":1,"31":1}}],["dynamic",{"0":{"22":1},"1":{"23":1},"2":{"23":1}}],["dtp显著优于现有技术",{"2":{"21":1}}],["dtp显著超越了现有的先进方法",{"2":{"21":1}}],["dtp可作为即插即用范式",{"2":{"21":1}}],["dtp几乎不增加额外的参数",{"2":{"21":1}}],["dtp包含两个关键技术",{"2":{"21":1}}],["dtp方法首先将夜间图像分解为不受光照影响的反射成分和与光照相关的光照成分",{"2":{"21":1}}],["dtp",{"2":{"21":10}}],["dangerous",{"2":{"92":2}}],["danger",{"2":{"92":2}}],["date",{"2":{"45":1,"57":1}}],["dataset",{"2":{"21":1,"57":4}}],["datasets",{"2":{"18":1,"34":1}}],["data",{"0":{"2":1,"3":1},"2":{"0":3,"26":1,"57":4,"91":2}}],["day",{"2":{"21":3}}],["dvlab",{"2":{"20":2}}],["dilation",{"2":{"65":1}}],["dilation=1",{"2":{"65":1}}],["directly",{"2":{"21":1,"23":1}}],["distributions",{"2":{"57":1}}],["distinguish",{"2":{"20":1,"34":1}}],["distinct",{"2":{"18":1}}],["disable",{"2":{"39":1}}],["disentangles",{"2":{"21":1}}],["disentanglement",{"0":{"21":1},"2":{"21":1}}],["disentangle",{"0":{"21":1},"2":{"21":2}}],["different",{"2":{"18":1,"23":3,"26":1,"34":2}}],["diverse",{"2":{"18":1}}],["driven",{"2":{"18":1,"23":1}}],["dgss",{"0":{"17":1},"1":{"18":1},"2":{"18":8}}],["double",{"2":{"42":3,"43":2,"54":1}}],["document",{"2":{"45":2}}],["documentclass",{"2":{"45":1}}],["documentation",{"2":{"5":1,"93":1}}],["doc表明编译器访问的是没有扩展名的根文件完整路径",{"2":{"43":1}}],["doc",{"2":{"43":1}}],["docfile仅是因为之前使用",{"2":{"43":1}}],["docfile可以将文件所在路径设置为中文",{"2":{"43":1}}],["docfile表明编译器访问没有扩展名的根文件名",{"2":{"43":1}}],["docfile更改为",{"2":{"43":1}}],["docfile",{"2":{"42":4,"43":4,"54":4}}],["download",{"2":{"37":1,"45":1,"48":1}}],["downstream",{"2":{"26":3}}],["down",{"2":{"20":1,"34":1}}],["domains",{"2":{"23":2}}],["domain",{"0":{"17":1},"1":{"18":1},"2":{"18":1,"23":1}}],["dsaa",{"2":{"15":1}}],["deepmask等等",{"2":{"62":1}}],["deeplab",{"2":{"20":1,"62":1}}],["default",{"2":{"42":1,"43":1,"54":1,"91":2}}],["degradation",{"2":{"34":1}}],["designed",{"2":{"26":1,"57":1}}],["deit",{"2":{"23":1}}],["decoder",{"0":{"33":1},"1":{"34":1},"2":{"23":1,"34":5}}],["decouples",{"2":{"8":1}}],["developed",{"2":{"21":1}}],["details",{"2":{"20":1,"43":1,"92":4}}],["demonstrate",{"2":{"18":1,"21":1}}],["demonstrates",{"2":{"0":1,"34":1,"90":1}}],["dcm将分割任务解耦为语义对齐和空间对齐",{"2":{"16":1}}],["dcm模块将分割任务拆解为语义对齐和空间对齐",{"2":{"9":1}}],["dcm",{"2":{"8":2,"9":1,"12":1,"15":2,"16":1}}],["dcam利用双语义感知注意力机制加强约束",{"2":{"16":1}}],["dcam通过双重语义感知注意力机制解决了注意力偏差问题",{"2":{"9":1}}],["dcam",{"2":{"8":2,"9":1,"12":1,"15":2,"16":1}}],["dut",{"2":{"20":1}}],["dual",{"2":{"8":3,"12":2}}],["due",{"2":{"8":1,"21":1,"26":1}}],["syntax",{"0":{"91":1},"2":{"91":1}}],["synctex的参数",{"2":{"51":1,"54":1}}],["synctex",{"2":{"42":3,"43":1,"50":2,"51":4,"54":3}}],["synctex=1",{"2":{"42":3,"43":3,"54":3}}],["s",{"2":{"23":2}}],["so",{"2":{"57":1}}],["songti",{"2":{"45":1}}],["source",{"2":{"34":1}}],["soft",{"2":{"32":1}}],["sota",{"2":{"26":1}}],["sod",{"2":{"21":4}}],["some",{"2":{"0":1,"21":1,"90":1}}],["speed",{"2":{"34":1}}],["specifically",{"2":{"26":1}}],["specific",{"2":{"21":1,"23":2,"26":2}}],["spt中的高斯抑制通过调整注意力分布",{"2":{"23":1}}],["spt",{"2":{"23":5}}],["spatial",{"2":{"8":4,"26":1,"34":1}}],["shiki",{"2":{"91":1}}],["shape",{"2":{"61":1}}],["share",{"2":{"26":1}}],["shanghai",{"2":{"21":1}}],["showcontextmenu",{"2":{"42":1,"43":1,"54":1}}],["show",{"2":{"20":1,"26":1,"42":2,"43":2,"54":2}}],["shows",{"2":{"20":1}}],["shown",{"2":{"8":1}}],["shot分割",{"2":{"23":1}}],["shot语义分割",{"2":{"9":1}}],["shot",{"0":{"6":1,"22":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"23":1},"2":{"8":1,"10":1,"11":1,"12":1,"23":3,"57":3}}],["ssd和fss",{"2":{"20":1}}],["supervised",{"2":{"57":1}}],["superiority",{"2":{"26":1}}],["superior",{"0":{"17":1},"1":{"18":1},"2":{"18":1,"57":1}}],["sumatrapdf作为自己的",{"2":{"52":1}}],["sumatrapdf下载与安装",{"0":{"48":1}}],["sumatrapdf",{"0":{"47":1,"52":1},"1":{"48":1,"49":1,"50":1,"51":1},"2":{"47":1,"48":1,"50":4,"51":5,"52":2,"54":5}}],["sun",{"2":{"31":1}}],["success",{"2":{"26":1}}],["such",{"2":{"20":1,"23":1,"26":1}}],["surpassing",{"2":{"18":1}}],["surprisingly",{"2":{"18":1,"23":1}}],["simplified",{"2":{"38":1}}],["simple",{"0":{"33":1},"1":{"34":1},"2":{"34":1}}],["size",{"2":{"34":1,"65":2}}],["sight",{"2":{"23":1}}],["significant",{"2":{"20":1}}],["significantly",{"2":{"18":1,"21":1}}],["single",{"2":{"18":1,"34":1}}],["site",{"2":{"0":1}}],["sar分割",{"2":{"30":1}}],["sam可能会遗漏图像中的精细结构",{"2":{"57":1}}],["sampling",{"2":{"20":1}}],["samples",{"2":{"8":1}}],["sam等在计算机视觉挑战中表现出色",{"2":{"18":1}}],["sam等大规模vfms显著提升了计算机视觉任务的性能",{"2":{"18":1}}],["sam",{"2":{"15":1,"18":1,"57":4}}],["sa",{"2":{"15":1,"57":5}}],["studio",{"2":{"35":1,"37":1,"38":1}}],["study",{"2":{"8":1}}],["stuff",{"2":{"34":1}}],["statistics",{"2":{"26":1}}],["state",{"0":{"13":1,"14":1},"1":{"14":1,"15":1},"2":{"18":1,"21":1,"23":3}}],["standard",{"2":{"23":1}}],["stride=1",{"2":{"65":1}}],["strides=",{"2":{"65":2}}],["stride",{"2":{"65":2}}],["strives",{"2":{"34":1}}],["structure",{"2":{"32":1,"34":1}}],["strategies",{"2":{"20":1}}],["stronger",{"0":{"17":1},"1":{"18":1},"2":{"18":1}}],["strengthen",{"2":{"8":1}}],["score",{"2":{"34":1}}],["scarce",{"2":{"26":1}}],["scale",{"2":{"8":1}}],["scheme",{"2":{"23":1,"34":1}}],["sciences",{"0":{"25":1}}],["science",{"2":{"21":1}}],["scenes",{"2":{"21":2}}],["scene",{"2":{"18":1}}],["script>",{"2":{"0":1}}],["script",{"2":{"0":1}}],["search",{"2":{"50":2,"51":2,"54":2}}],["searchpath",{"2":{"36":1}}],["section",{"2":{"45":2}}],["sed在准确性和速度方面均有效",{"2":{"34":1}}],["sed由基于分层编码器的代价图生成和带有类别早期拒绝的渐进式融合解码器组成",{"2":{"34":1}}],["sed下载",{"2":{"34":1}}],["sed方法在ade20k数据集上",{"2":{"34":1}}],["sed包含两部分",{"2":{"34":1}}],["sed",{"0":{"33":1},"1":{"34":1},"2":{"34":4}}],["sensing",{"2":{"23":1}}],["sensitivity",{"2":{"8":1}}],["serve",{"2":{"21":1}}],["segnet的基本原理",{"0":{"88":1}}],["segnet",{"0":{"87":1},"1":{"88":1}}],["seg",{"2":{"34":1}}],["segfix和crm的细化结果对比",{"2":{"20":1}}],["segfix和mgmatting的性能",{"2":{"20":1}}],["segfix作为高分辨率分割细化方法",{"2":{"20":1}}],["segmentor作为全景和实体分割的基准方法",{"2":{"20":1}}],["segment",{"0":{"56":1},"1":{"57":1},"2":{"20":1,"57":5}}],["segmenting",{"2":{"8":1}}],["segmentation",{"0":{"6":1,"17":1,"19":1,"21":1,"22":1,"24":1,"33":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"18":1,"23":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"34":1},"2":{"8":2,"10":1,"11":1,"12":1,"18":1,"20":3,"21":4,"23":3,"26":3,"34":5,"57":2}}],["setting",{"2":{"23":1}}],["settings",{"2":{"18":1,"21":1}}],["set",{"2":{"18":1,"34":1}}],["setup>",{"2":{"0":1}}],["semantically",{"2":{"21":1}}],["semantics",{"2":{"21":3,"23":1}}],["semantic",{"0":{"6":1,"17":1,"21":1,"24":1,"33":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"18":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"34":1},"2":{"8":4,"11":1,"12":1,"18":1,"21":3,"23":1,"26":2,"34":4}}],["a4paper",{"2":{"45":1}}],["author",{"2":{"45":1}}],["auto",{"2":{"50":1,"51":2,"54":1}}],["autoclean",{"2":{"42":1,"43":1,"54":1}}],["autobuild",{"2":{"42":1,"43":1,"54":1}}],["aux",{"2":{"42":1,"43":1,"54":1}}],["a6000",{"2":{"34":1}}],["agnostic",{"2":{"23":1}}],["aggregate",{"2":{"21":1,"26":1}}],["aggregates",{"2":{"20":1}}],["aggregation",{"2":{"8":1,"12":1}}],["architecture",{"2":{"57":1}}],["args",{"2":{"42":4,"43":4,"50":2,"51":2,"54":6}}],["are",{"2":{"21":1,"23":2,"34":1,"57":1}}],["article",{"2":{"45":1}}],["arts",{"0":{"14":1},"2":{"23":2}}],["art",{"0":{"13":1},"1":{"14":1,"15":1},"2":{"18":1,"21":1,"23":1}}],["ai",{"0":{"57":1},"2":{"21":1,"57":1}}],["aims",{"2":{"8":1}}],["among",{"2":{"20":1,"26":1}}],["amp",{"0":{"17":1},"1":{"18":1}}],["assignment",{"2":{"32":1}}],["assist",{"2":{"26":1}}],["assess",{"2":{"18":1}}],["aspp",{"2":{"21":1}}],["as",{"2":{"20":1,"21":2}}],["at",{"2":{"18":1,"20":1,"21":1,"34":4,"57":1}}],["attention",{"2":{"8":3}}],["available",{"2":{"18":1,"20":1,"21":1,"34":1}}],["acr",{"2":{"42":1,"43":1,"54":1}}],["across",{"2":{"18":1}}],["acn",{"2":{"42":1,"43":1,"54":1}}],["acquire",{"2":{"36":1}}],["acp",{"2":{"30":1,"32":1}}],["academy",{"0":{"25":1}}],["activating",{"2":{"23":1}}],["accurarcy",{"2":{"64":1}}],["accuracy",{"2":{"20":1,"34":1,"64":2}}],["acceleration",{"2":{"34":1}}],["accelerate",{"2":{"34":1}}],["accessing",{"2":{"18":1}}],["access",{"2":{"0":1}}],["achieves",{"2":{"18":1,"23":1,"26":1,"34":1}}],["abstract",{"2":{"45":2}}],["about",{"2":{"43":1}}],["ability",{"2":{"18":1,"20":1}}],["ablation",{"0":{"13":1,"15":1},"1":{"14":1,"15":1},"2":{"23":2}}],["app",{"2":{"50":1,"51":1,"54":1}}],["approach",{"2":{"8":1,"18":1}}],["ap",{"2":{"20":1}}],["apis",{"2":{"0":1,"5":1}}],["api",{"0":{"0":1},"1":{"1":1,"2":1,"3":1,"4":1,"5":1},"2":{"0":1}}],["ali",{"2":{"45":1}}],["align从噪声图像",{"2":{"34":1}}],["aligns",{"2":{"20":1}}],["alignment",{"2":{"8":2,"26":1,"30":1}}],["alg",{"2":{"42":1,"43":1,"54":1}}],["although",{"2":{"26":1}}],["allowing",{"2":{"21":1}}],["alleviate",{"2":{"8":1}}],["adjust",{"2":{"36":1}}],["advancde",{"2":{"36":1}}],["ade20k",{"2":{"34":3}}],["adapt",{"2":{"34":1}}],["adaptability",{"2":{"26":1}}],["adapting",{"2":{"26":1}}],["adaptively",{"2":{"23":1}}],["adaptive",{"0":{"6":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1},"2":{"8":1,"12":1,"21":1}}],["additional",{"2":{"21":1,"91":1}}],["address",{"2":{"20":1}}],["addresses",{"2":{"8":1}}],["adobe",{"0":{"20":1}}],["aware",{"0":{"22":1},"1":{"23":1},"2":{"8":3,"21":1,"23":1,"26":2,"30":1}}],["anything",{"0":{"56":1},"1":{"57":1},"2":{"57":8}}],["any",{"2":{"18":1}}],["an",{"2":{"18":1,"21":1,"26":1,"34":1,"92":2}}],["annotated",{"2":{"8":1}}],["and",{"0":{"13":1,"22":1},"1":{"14":1,"15":1,"23":1},"2":{"0":2,"8":5,"18":3,"20":6,"21":9,"23":9,"26":3,"32":1,"34":3,"57":8}}],["a",{"0":{"6":1,"33":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"34":1},"2":{"8":3,"18":4,"21":2,"23":2,"26":1,"34":8,"45":2,"46":2,"57":2,"92":8}}],["txt",{"2":{"42":3,"43":10,"45":1,"50":1,"51":6,"54":1}}],["tl",{"2":{"36":1}}],["t",{"2":{"23":1,"30":1}}],["two",{"2":{"21":1}}],["typically",{"2":{"21":1,"26":1}}],["tip",{"2":{"92":4}}],["ti+∑jnji−nii",{"2":{"64":1}}],["ti=∑jnij表示标签中所有分类为i的像素点数量",{"2":{"64":1}}],["title",{"2":{"45":1}}],["times",{"2":{"34":1}}],["time",{"0":{"21":1},"2":{"21":7}}],["tion",{"2":{"20":1,"26":1}}],["true",{"2":{"42":2,"43":2,"54":2}}],["tree",{"2":{"20":2}}],["transferability",{"2":{"26":1}}],["transfers",{"2":{"23":1}}],["transfer",{"0":{"22":1},"1":{"23":1},"2":{"23":4,"57":1}}],["transformer因能捕捉长距离相关性",{"2":{"11":1}}],["transformer应用",{"2":{"11":1}}],["transformer",{"0":{"6":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1},"2":{"8":1,"12":1,"34":2}}],["training",{"2":{"20":1,"26":1,"34":2}}],["trainable",{"2":{"18":4}}],["trained",{"2":{"18":1,"26":2,"34":1,"57":1}}],["test",{"2":{"45":1}}],["testfile",{"2":{"45":1}}],["testing",{"2":{"20":1}}],["tex的latex文件路径",{"2":{"54":1}}],["tex测试文件下载",{"0":{"45":1}}],["tex文件编译",{"0":{"44":1},"1":{"45":1,"46":1}}],["texstudio",{"2":{"43":1}}],["texworks",{"2":{"36":2}}],["texlive",{"2":{"36":1}}],["tex",{"0":{"36":1,"46":1},"2":{"36":6,"43":7,"45":2,"46":4,"50":1,"51":3,"52":1,"54":2}}],["text",{"2":{"34":1}}],["tend",{"2":{"23":1}}],["technology",{"2":{"21":1}}],["tem通过多尺度局部上下文相关性增强前景特征",{"2":{"16":1}}],["tem通过探索多尺度局部上下文的相关性",{"2":{"9":1}}],["tem旨在减轻骨干网络的固有偏差并增强查询前景区域",{"2":{"15":1}}],["tem和dcam协同作用可提升2",{"2":{"15":1}}],["tem",{"2":{"8":2,"9":1,"12":1,"15":2,"16":1}}],["tuple",{"2":{"65":5}}],["tug",{"2":{"36":1}}],["tures",{"2":{"20":1}}],["tune",{"2":{"23":2}}],["tunes",{"2":{"18":1}}],["tuning",{"2":{"18":2,"26":2,"30":1}}],["taborbrowser",{"2":{"51":1}}],["tab",{"2":{"51":1}}],["tableofcontents",{"2":{"45":1}}],["table",{"2":{"32":2}}],["tackle",{"2":{"21":1}}],["tasks",{"2":{"18":1,"23":1,"26":2,"57":2}}],["task",{"2":{"8":1,"20":1,"21":1,"23":2,"34":1,"57":5}}],["target",{"2":{"8":1,"12":1,"20":1,"23":2}}],["torch",{"2":{"65":1}}],["tool是name标签所对应的编译顺序",{"2":{"43":1}}],["tools",{"2":{"42":7,"43":7,"54":7}}],["toc",{"2":{"42":1,"43":1,"54":1}}],["top",{"2":{"34":1}}],["tokens",{"2":{"18":1,"26":1}}],["to",{"2":{"0":1,"8":7,"18":3,"20":5,"21":5,"23":8,"26":7,"34":7,"37":1,"45":1,"48":1,"57":5}}],["things和stuff",{"2":{"70":1}}],["this",{"2":{"0":1,"8":1,"18":2,"21":2,"23":1,"34":1,"39":1,"43":1,"45":2,"57":1,"90":1,"92":10}}],["thatworks",{"2":{"23":1}}],["that",{"2":{"18":2,"20":2,"21":2,"23":2,"34":1,"57":1}}],["through",{"2":{"8":1}}],["three",{"2":{"8":1,"23":1}}],["thereby",{"2":{"26":1}}],["their",{"2":{"21":1}}],["these",{"2":{"20":1}}],["then",{"0":{"21":1},"2":{"8":1,"21":3}}],["theme",{"0":{"2":1},"2":{"0":4,"2":1}}],["the",{"0":{"13":2,"14":2},"1":{"14":2,"15":2},"2":{"0":3,"5":2,"8":7,"18":8,"20":7,"21":10,"23":16,"26":9,"34":7,"45":1,"57":5,"90":1,"93":2}}],["block",{"2":{"92":2}}],["blg",{"2":{"42":1,"43":1,"54":1}}],["box",{"2":{"92":2}}],["bool",{"2":{"65":1}}],["both",{"2":{"0":1}}],["browser",{"2":{"51":1}}],["bbl",{"2":{"42":1,"43":1,"54":1}}],["b时",{"2":{"34":1}}],["billion",{"2":{"57":1}}],["bib的编译",{"2":{"46":1}}],["bib",{"2":{"43":1}}],["bibtex",{"2":{"42":8,"43":8,"46":1,"54":8}}],["bine",{"2":{"34":1}}],["bias=true",{"2":{"65":1}}],["bias",{"2":{"8":6,"65":1}}],["b",{"2":{"23":1,"34":2,"46":2}}],["bg",{"2":{"23":1}}],["but",{"2":{"23":1}}],["built",{"2":{"18":1,"57":1,"90":1}}],["bdd100k",{"2":{"21":2}}],["balance",{"2":{"20":1,"26":1}}],["backbone",{"2":{"18":2,"34":3}}],["background",{"2":{"8":1}}],["based",{"0":{"6":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1},"2":{"8":1,"12":1,"21":2,"26":1,"34":3}}],["begin",{"2":{"45":2}}],["better",{"2":{"34":1}}],["between",{"2":{"20":2,"21":1,"26":1}}],["benchmarks",{"2":{"23":1}}],["benefit",{"2":{"21":1}}],["being",{"2":{"21":1}}],["been",{"2":{"21":1}}],["besides",{"2":{"20":1}}],["be",{"2":{"0":1,"21":1,"23":1,"57":1}}],["by",{"2":{"0":1,"8":2,"18":1,"20":1,"21":2,"26":3,"57":1,"90":1,"91":1}}],["pytorch",{"2":{"58":1}}],["pytorch笔记",{"0":{"58":1}}],["pdf查看器用于在",{"2":{"54":1}}],["pdflatex",{"2":{"42":9,"43":13,"54":9}}],["pdf",{"0":{"53":1},"2":{"42":5,"43":7,"46":4,"47":5,"50":8,"51":16,"52":4,"54":15}}],["pp",{"2":{"34":1}}],["p",{"2":{"34":1,"36":1,"54":1}}],["pc",{"2":{"34":2}}],["plain",{"2":{"34":1}}],["pst900",{"2":{"31":1}}],["pspnet",{"2":{"20":1}}],["pmg可以将目标对象清晰地划分为不同的互补部分区域",{"2":{"23":1}}],["pmg",{"2":{"23":5}}],["powered",{"2":{"91":1}}],["power",{"2":{"57":1}}],["powerful",{"2":{"23":1,"26":1}}],["points",{"2":{"23":1}}],["posed",{"2":{"20":1}}],["pq",{"2":{"20":1}}],["pixel",{"2":{"34":2,"64":1}}],["pixels",{"2":{"34":1}}],["pixelnerf",{"2":{"20":1}}],["ping",{"2":{"20":1}}],["performed",{"2":{"34":1}}],["perform",{"2":{"26":1}}],["performance",{"2":{"23":1,"26":1,"57":1}}],["per",{"2":{"20":1,"34":1}}],["perception",{"2":{"8":1,"23":1}}],["peft",{"2":{"18":3}}],["padding=0",{"2":{"65":2}}],["padding",{"2":{"65":6}}],["pacc=∑inii∑iti该指标表示所有像素中分类正确的比例",{"2":{"64":1}}],["package",{"2":{"42":1,"43":1,"54":1}}],["pack",{"2":{"38":1}}],["pasca",{"2":{"34":1}}],["pascal数据集",{"0":{"73":1}}],["pascal",{"2":{"8":1,"14":1,"34":4}}],["pas",{"2":{"34":1}}],["pat在三个流行的fss基准测试中创造了新的最优性能",{"2":{"23":1}}],["pat在四个任务中表现优异",{"2":{"23":1}}],["pat与其他fss方法的结合",{"2":{"23":1}}],["pat取得了最佳的分割性能",{"2":{"23":1}}],["pat",{"2":{"23":6}}],["patterns",{"2":{"26":1}}],["pattern",{"2":{"23":1}}],["patch",{"2":{"20":1}}],["part",{"2":{"23":2}}],["particular",{"2":{"8":1}}],["paradigm",{"2":{"21":1,"23":1,"26":1}}],["parameter",{"2":{"18":2}}],["parameters",{"2":{"18":3,"21":1,"26":3}}],["parser",{"2":{"21":1}}],["parse",{"0":{"21":1},"2":{"21":2}}],["paper",{"2":{"18":1,"23":1,"34":1}}],["page",{"0":{"3":1,"4":1},"2":{"0":7,"3":1,"90":1}}],["privacy",{"2":{"57":1}}],["prior",{"2":{"21":2,"57":1}}],["predict",{"2":{"34":1}}],["predictions",{"2":{"21":1}}],["pretrained",{"2":{"23":1}}],["present",{"2":{"20":1}}],["precise",{"2":{"20":1,"21":1}}],["precisely",{"2":{"18":1,"23":1}}],["pre",{"2":{"18":1,"26":2,"34":1}}],["previous",{"2":{"8":1}}],["pre>",{"2":{"0":6}}],["provides",{"2":{"91":1}}],["provided",{"2":{"0":1,"90":1}}],["project",{"2":{"57":1}}],["propaga",{"2":{"26":1}}],["proposing",{"2":{"21":1}}],["proposes",{"2":{"23":1}}],["proposed",{"2":{"21":1}}],["propose",{"2":{"8":1,"20":1,"26":1,"34":1}}],["promptable",{"2":{"57":2}}],["prompter",{"2":{"26":2,"30":2,"32":2}}],["prompts",{"2":{"23":3,"26":1}}],["prompting",{"0":{"24":1},"1":{"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1},"2":{"23":2}}],["prompt",{"0":{"22":1},"1":{"23":1},"2":{"23":5,"26":3,"30":1}}],["pro",{"2":{"20":1}}],["produces",{"2":{"18":1}}],["processing",{"2":{"21":1}}],["process",{"2":{"18":1}}],["prototype",{"0":{"6":1},"1":{"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1},"2":{"8":1,"12":1}}]],"serializationVersion":2}';export{e as default};
