import{_ as k,c as n,j as s,a as i,a5 as a,o as h}from"./chunks/framework.DGMnJK1L.js";const o=JSON.parse('{"title":"多尺度空洞注意力 （💯）","description":"","frontmatter":{},"headers":[],"relativePath":"column/YOLOv8_attention/article_3.md","filePath":"column/YOLOv8_attention/article_3.md","lastUpdated":1717557257000}'),l={name:"column/YOLOv8_attention/article_3.md"},p=a("",10),t=s("strong",null,"多尺度扩张注意力",-1),e=s("strong",null,"MSDA",-1),E={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},r={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.043ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 903 851.8","aria-hidden":"true"},d=a("",1),g=[d],y=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mrow",{"data-mjx-texclass":"ORD"},[s("msub",null,[s("mi",null,"h"),s("mi",null,"i")])])])],-1),F=a("",48);function C(c,b,m,A,B,D){return h(),n("div",null,[p,s("p",null,[i("在DilateFormer论文中，"),t,i("（"),e,i("）模块是为了利用自注意机制在不同尺度上的稀疏性。MSDA通过线性投影得到特征图X的相应查询、键和值。然后，将特征图的通道分成n个不同的头部，并在不同的头部中以不同的扩张率执行多尺度SWDA。具体来说，MSDA被公式化如下：对于每个头部i，进行SWDA操作，并且对所有的输出"),s("mjx-container",E,[(h(),n("svg",r,g)),y]),i("进行连接后送入一个线性层进行特征聚合。通过为不同的头部设置不同的扩张率，MSDA能够在被关注的接受域内有效地聚合不同尺度的语义信息，并在不需要复杂操作和额外计算成本的情况下有效地减少自注意机制的冗余")]),F])}const _=k(l,[["render",C]]);export{o as __pageData,_ as default};
