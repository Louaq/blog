import{_ as s,c as a,o as i,a3 as t}from"./chunks/framework.C296BEqQ.js";const y=JSON.parse('{"title":"训练结果","description":"","frontmatter":{},"headers":[],"relativePath":"column/Algorithm/Tree.md","filePath":"column/Algorithm/Tree.md","lastUpdated":1716725883000}'),n={name:"column/Algorithm/Tree.md"},e=t(`<h1 id="训练结果" tabindex="-1">训练结果 <a class="header-anchor" href="#训练结果" aria-label="Permalink to &quot;训练结果&quot;">​</a></h1><blockquote><p>训练结果会保存在runs/train目录下，exp1,exp2,exp3的顺序，表示每一次的训练结果。</p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-04-37.png" alt=""></p><p>上图就是训练完成后目录的结构，weights目录里面就是我们需要的模型：best.pts是效果最好的，最后也是需要这个，last.pt是最后一次的训练结果。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-05-47.png" alt=""></p><h1 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h1><p><strong>整个项目的改进工作我已经做好，复现的话只需装好对应的环境，修改train.py的参数，运行train.py就可以开始训练；修改Detect.py的参数，就可以检测。目前项目只针对检测任务，对于分割和分类没有做改进。</strong></p><h1 id="经验之谈" tabindex="-1">经验之谈 <a class="header-anchor" href="#经验之谈" aria-label="Permalink to &quot;经验之谈&quot;">​</a></h1><p><strong>（1）以下为两个重要库的版本，必须对应下载，否则会报错</strong></p><blockquote><p>python == 3.9.7 pytorch == 1.12.1 timm == 0.9.12 # 此安装包必须要 mmcv-full == 1.6.2 # 不安装此包部分关于dyhead的代码运行不了以及Gold-YOLO</p></blockquote><p><strong>（2）mmcv-full会安装失败是因为自身系统的编译工具有问题，也有可能是环境之间安装的有冲突</strong></p><pre><code>推荐大家离线安装的形式,下面的地址中大家可以找找自己的版本,下载到本地进行安装。
https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html
https://download.openmmlab.com/mmcv/dist/index.html
</code></pre><p><strong>（3）basicsr安装失败原因,通过pip install basicsr 下载如果失败,大家可以去百度搜一下如何换下载镜像源就可以修复</strong></p><h2 id="针对一些报错的解决办法在这里说一下" tabindex="-1">针对一些报错的解决办法在这里说一下 <a class="header-anchor" href="#针对一些报错的解决办法在这里说一下" aria-label="Permalink to &quot;针对一些报错的解决办法在这里说一下&quot;">​</a></h2><p><strong>(1)训练过程中loss出现Nan值.</strong> 可以尝试关闭AMP混合精度训练.</p><p><strong>(2)多卡训练问题,修改模型以后不能支持多卡训练可以尝试下面的两行命令行操作，两个是不同的操作，是代表不同的版本现尝试第一个不行用第二个</strong></p><pre><code>python -m torch.distributed.run --nproc_per_node 2 train.py
python -m torch.distributed.launch --nproc_per_node 2 train.py
</code></pre><p><strong>(3) 针对运行过程中的一些报错解决</strong> 1.如果训练的过程中验证报错了(主要是一些形状不匹配的错误这是因为验证集的一些特殊图片导致) 找到ultralytics/models/yolo/detect/train.py的DetectionTrainer class中的build_dataset函数中的rect=mode == &#39;val&#39;改为rect=False</p><div class="language-py vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">py</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">推理的时候运行detect.py文件报了形状不匹配的错误</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">找到ultralytics</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">engine</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">predictor.py找到函数def pre_transform(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, im),在LetterBox中的auto改为False</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">训练的过程中报错类型不匹配的问题</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">找到</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;ultralytics/engine/validator.py&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">文件找到 </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;class BaseValidator:&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 然后在其</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;__call__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">中</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.args.half </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.device.type </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;cpu&#39;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # force FP16 val during training的一行代码下面加上self.args.half = False</span></span></code></pre></div><p><strong>(4) 针对yaml文件中的nc修改</strong> 不用修改，模型会自动根据你数据集的配置文件获取。 这也是模型打印两次的区别，第一次打印出来的就是你选择模型的yaml文件结构，第二次打印的就是替换了你数据集的yaml文件，模型使用的是第二种。</p><p><strong>(5) 针对环境的问题</strong> 环境的问题每个人遇见的都不一样，可自行上网查找。</p>`,21),p=[e];function l(r,h,o,d,c,k){return i(),a("div",null,p)}const m=s(n,[["render",l]]);export{y as __pageData,m as default};
